# Portf√≥lio: Resolvendo Problemas por Busca em Intelig√™ncia Artificial

## 1. Introdu√ß√£o: Import√¢ncia e Impacto da Resolu√ß√£o de Problemas por Busca na IA e na Sociedade

A Intelig√™ncia Artificial (IA) envolve o estudo de agentes que recebem percep√ß√µes do ambiente e realizam a√ß√µes. Definimos IA como o estudo da a√ß√£o racional e, nesse contexto, o planejamento ‚Äî elaborar um plano de a√ß√£o para alcan√ßar objetivos ‚Äî √© uma parte crucial da IA.

A resolu√ß√£o de problemas por busca √© uma t√©cnica central em IA para encontrar uma sequ√™ncia de a√ß√µes que leve um agente a atingir um objetivo. Newell e Simon argumentaram que esta √© a base essencial da resolu√ß√£o de problemas humanos, como um jogador de xadrez examinando movimentos ou um m√©dico considerando diagn√≥sticos alternativos. Embora as primeiras abordagens pudessem ser ineficientes sem orienta√ß√£o adequada, a busca, juntamente com a representa√ß√£o do conhecimento, permanece no cerne da maioria dos trabalhos modernos em IA.

A busca √© uma metodologia de resolu√ß√£o de problemas que explora sistematicamente um espa√ßo de estados, que representa os est√°gios sucessivos e alternativos no processo de busca pela solu√ß√£o. Exemplos pr√°ticos de aplica√ß√£o da busca incluem layout VLSI (circuitos integrados de larga escala), navega√ß√£o rob√≥tica, sequenciamento de montagem autom√°tica e problemas de roteamento. Al√©m disso, a busca tem sido aplicada em √°reas como diagn√≥stico de falhas mec√¢nicas e mesmo no racioc√≠nio baseado em l√≥gica.

A capacidade de um agente de resolver problemas atrav√©s da busca permite que ele navegue por ambientes complexos, tome decis√µes sequenciais e encontre caminhos para atingir metas, tornando-se uma ferramenta indispens√°vel para a cria√ß√£o de sistemas inteligentes.

## 2. Apresenta√ß√£o dos Conceitos Principais

A abordagem de resolu√ß√£o de problemas por busca se baseia na ideia de que um agente pode adotar um objetivo e trabalhar para satisfaz√™-lo. Um agente de solu√ß√£o de problemas √© um tipo de agente baseado em objetivos.

Os principais conceitos envolvidos s√£o:

*   **Formula√ßƒÅo de Objetivo:** O agente adota um ou mais objetivos que deseja alcan√ßar.
*   **Formula√ßƒÅo de Problema:** O agente descreve os estados poss√≠veis do "mundo" e as a√ß√µes que pode realizar para transitar entre esses estados, visando atingir o objetivo. Estados do mundo podem ser considerados como totalidades sem estrutura interna vis√≠vel (representa√ß√£o at√¥mica), que √© a representa√ß√£o considerada na busca b√°sica.
*   **Espa√ßo de Estados (State Space):** √â uma representa√ß√£o formal do problema. √â definido por uma qu√°drupla `[N, A, S, GD]`, onde:
    *   `N` √© o conjunto de n√≥s ou estados do grafo, correspondendo aos estados no processo de resolu√ß√£o do problema.
    *   `A` √© o conjunto de arcos que conectam pares de n√≥s, representando conex√µes diretas ou a√ß√µes que levam de um estado a outro.
    *   `S` √© o estado inicial.
    *   `GD` √© a descri√ß√£o dos estados objetivo, ou seja, a condi√ß√£o que define que o problema foi resolvido.
    Uma solu√ß√£o para um problema √© representada como um caminho no grafo do estado inicial a um estado objetivo.
*   **Busca (Search):** Antes de agir, o agente simula sequ√™ncias de a√ß√µes em seu modelo (o espa√ßo de estados) para encontrar um caminho que leve ao objetivo. Isso envolve testar sistematicamente caminhos alternativos.
*   **Execu√ß√£o:** Uma vez encontrado um caminho (solu√ß√£o) pela busca, o agente executa as a√ß√µes correspondentes no ambiente real.
*   **Agentes de Solu√ß√£o de Problemas:** S√£o agentes baseados em objetivos que utilizam a busca em representa√ß√µes at√¥micas de estados para encontrar solu√ß√µes.
*   **Estrat√©gias de Busca:** S√£o os algoritmos usados para explorar o espa√ßo de estados. Elas podem ser:
    *   **Busca Cega (Uninformed Search):** Algoritmos que n√£o utilizam nenhuma informa√ß√£o sobre o qu√£o pr√≥ximo um estado est√° do(s) objetivo(s) al√©m da defini√ß√£o do problema.
    *   **Busca Informada (Informed Search):** Algoritmos que utilizam dicas espec√≠ficas do dom√≠nio (heur√≠sticas) sobre a localiza√ß√£o dos objetivos para guiar a busca de forma mais eficiente.
*   **Heur√≠sticas:** S√£o fun√ß√µes, denotadas como `h(n)`, que fornecem uma estimativa do custo do caminho mais econ√¥mico do estado no n√≥ `n` para um estado objetivo. Elas s√£o informa√ß√µes espec√≠ficas do dom√≠nio que podem melhorar significativamente a efici√™ncia da busca.
*   **Medidas de Performance:** Crit√©rios para avaliar algoritmos de busca:
    *   **Completude (Completeness):** O algoritmo garante encontrar uma solu√ß√£o quando existe uma, ou reportar a falha corretamente.
    *   **Otimiza√ß√£o de Custos (Cost Optimization):** O algoritmo garante encontrar a solu√ß√£o com o menor custo.
    *   **Complexidade de Tempo (Time Complexity):** Quanto tempo leva para encontrar a solu√ß√£o.
    *   **Complexidade de Espa√ßo (Space Complexity):** Quanta mem√≥ria √© necess√°ria para a busca.
*   **Filas:** Estruturas de dados usadas para gerenciar a ordem em que os n√≥s s√£o explorados pelos algoritmos de busca: fila FIFO (First-In, First-Out) para busca em largura, pilha LIFO (Last-In, First-Out) para busca em profundidade, e fila de prioridade para busca *best-first*. O uso dessas estruturas permite que os algoritmos explorem estados n√£o testados (lista *open*) e evitem repetir caminhos infrut√≠feros (lista *closed*).

# An√°lise de Algoritmos para Portf√≥lio 2 de IA (Baseado em Russell & Norvig)



## 1. Algoritmos de Busca Cega (Uninformed Search)

Os algoritmos de busca cega, tamb√©m conhecidos como busca n√£o informada, exploram o espa√ßo de estados sem utilizar qualquer conhecimento espec√≠fico sobre a proximidade de um estado ao objetivo, baseando-se unicamente na estrutura do problema. Conforme apresentado por Russell e Norvig (2013), as principais estrat√©gias dentro desta categoria incluem:

*   **Busca em Largura (Breadth-First Search - BFS):** Expande sistematicamente os n√≥s mais rasos e n√£o expandidos primeiro. Garante encontrar a solu√ß√£o mais rasa (√≥tima em termos de n√∫mero de passos se os custos forem uniformes), mas pode exigir muita mem√≥ria.
*   **Busca de Custo Uniforme (Uniform-Cost Search - UCS):** Expande o n√≥ n√£o expandido com o menor custo de caminho acumulado (`g(n)`). √â √≥tima e completa, desde que os custos dos passos sejam n√£o negativos. √â essencialmente uma generaliza√ß√£o da BFS para custos de passo vari√°veis.
*   **Busca em Profundidade (Depth-First Search - DFS):** Expande sempre o n√≥ mais profundo na fronteira da √°rvore de busca. Usa menos mem√≥ria que a BFS (ordem linear em rela√ß√£o √† profundidade m√°xima), mas n√£o √© completa (pode se perder em caminhos infinitos) nem √≥tima por si s√≥.
*   **Busca com Aprofundamento Iterativo (Iterative Deepening Depth-First Search - IDDFS ou IDS):** Combina os benef√≠cios da BFS (completude e otimalidade para custos uniformes) e da DFS (requisitos modestos de mem√≥ria). Realiza buscas em profundidade com limites de profundidade crescentes (1, 2, 3, ...), at√© encontrar a solu√ß√£o. Embora pare√ßa redundante por repetir expans√µes, √© geralmente o m√©todo de busca cega preferido quando o espa√ßo de busca √© grande e a profundidade da solu√ß√£o √© desconhecida.
*   **Busca Bidirecional (Bidirectional Search):** Executa duas buscas simult√¢neas, uma partindo do estado inicial e outra partindo do estado objetivo (se as a√ß√µes forem revers√≠veis), parando quando as duas buscas se encontram no meio. Pode reduzir drasticamente a complexidade de tempo e espa√ßo, explorando uma √°rea muito menor do espa√ßo de estados em compara√ß√£o com buscas unidirecionais.

*Refer√™ncia:* RUSSELL, S. J.; NORVIG, P. *Intelig√™ncia artificial*. 3. ed. Rio de Janeiro: Elsevier Campus, 2013. Cap√≠tulo 3.

---



## 2. Algoritmos de Busca Informada (Heur√≠stica)

Os algoritmos de busca informada, ou busca heur√≠stica, utilizam conhecimento espec√≠fico do problema, na forma de uma fun√ß√£o heur√≠stica `h(n)`, para estimar a dist√¢ncia (ou custo) de um estado `n` at√© o objetivo. Essa informa√ß√£o guia a busca de forma mais eficiente, priorizando caminhos que parecem mais promissores. Russell e Norvig (2013) destacam as seguintes abordagens:

*   **Busca Best-First Gen√©rica (Generic Best-First Search):** √â um paradigma de busca que seleciona o pr√≥ximo n√≥ a ser expandido com base em uma fun√ß√£o de avalia√ß√£o `f(n)`. Diferentes algoritmos best-first surgem da escolha de diferentes fun√ß√µes `f`.
*   **Busca Best-First Gulosa (Greedy Best-First Search):** Uma inst√¢ncia da busca best-first que tenta expandir o n√≥ que est√° estimado como o mais pr√≥ximo do objetivo, usando a fun√ß√£o heur√≠stica diretamente como fun√ß√£o de avalia√ß√£o: `f(n) = h(n)`. Embora possa ser r√°pida, n√£o √© √≥tima nem completa.
*   **Busca A* (A* Search):** Considerado o algoritmo de busca heur√≠stica mais conhecido, A* combina o custo do caminho percorrido desde o in√≠cio (`g(n)`) com a estimativa heur√≠stica do custo restante at√© o objetivo (`h(n)`), utilizando a fun√ß√£o de avalia√ß√£o `f(n) = g(n) + h(n)`. A* √© completo e √≥timo, desde que a heur√≠stica `h(n)` seja admiss√≠vel (nunca superestima o custo real) e, para efici√™ncia √≥tima, consistente. √â amplamente utilizado em problemas de planejamento de caminhos e outros.
*   **Buscas Heur√≠sticas com Mem√≥ria Limitada:** Como A* pode consumir muita mem√≥ria, foram desenvolvidas variantes que operam com restri√ß√µes de espa√ßo:
    *   **Busca Recursiva Best-First (Recursive Best-First Search - RBFS):** Simula a opera√ß√£o de A* usando apenas espa√ßo linear. Faz isso explorando um caminho e mantendo o valor `f` do melhor caminho alternativo a partir de seus ancestrais. Se o custo do caminho atual exceder esse valor limite, ele retrocede e explora o caminho alternativo. Pode sofrer de recomputa√ß√£o excessiva.
    *   **SMA* (Simplified Memory-Bounded A*):** Utiliza toda a mem√≥ria dispon√≠vel. Expande os melhores n√≥s folha at√© que a mem√≥ria esteja cheia. Nesse ponto, remove o n√≥ folha com o maior valor `f` (o pior) para liberar espa√ßo para um novo n√≥. √â completo se houver mem√≥ria suficiente para armazenar o caminho da solu√ß√£o mais rasa e √≥timo se encontrar uma solu√ß√£o.
*   **Aprendizado de Heur√≠sticas (Learning Heuristics):** Abordagens onde a fun√ß√£o heur√≠stica n√£o √© dada a priori, mas aprendida a partir da experi√™ncia ou de exemplos do problema, como resolver subproblemas mais simples (bases de dados de padr√µes) ou atrav√©s de aprendizado indutivo.

*Refer√™ncia:* RUSSELL, S. J.; NORVIG, P. *Intelig√™ncia artificial*. 3. ed. Rio de Janeiro: Elsevier Campus, 2013. Cap√≠tulo 3.

---



## 3. Algoritmos de Busca em Ambientes Complexos

Ambientes complexos apresentam desafios adicionais em rela√ß√£o √† busca cl√°ssica, como a necessidade de otimizar uma fun√ß√£o objetivo sem se preocupar com o caminho, lidar com m√∫ltiplos agentes com objetivos conflitantes, agir sob incerteza ou com informa√ß√µes parciais. Russell e Norvig (2013) abordam diversas t√©cnicas para esses cen√°rios:

*   **Busca Local (Local Search):** Utilizada principalmente em problemas de otimiza√ß√£o, onde o objetivo √© encontrar o estado com o melhor valor de uma fun√ß√£o objetivo, e o caminho at√© ele n√£o importa. Esses algoritmos mant√™m apenas um estado atual (ou um pequeno conjunto) e tentam melhor√°-lo movendo-se para estados vizinhos.
    *   *Subida de Encosta (Hill Climbing):* Move-se continuamente em dire√ß√£o a um valor crescente da fun√ß√£o objetivo. √â simples e eficiente em mem√≥ria, mas suscet√≠vel a m√°ximos locais, plat√¥s e cumeeiras.
    *   *Subida de Encosta com Rein√≠cio Aleat√≥rio (Random-Restart Hill Climbing):* Executa a subida de encosta m√∫ltiplas vezes a partir de estados iniciais aleat√≥rios para aumentar a chance de encontrar o √≥timo global.
    *   *Recozimento Simulado (Simulated Annealing):* Permite movimentos para estados piores com uma probabilidade que diminui ao longo do tempo (controlada por uma "temperatura"), ajudando a escapar de m√°ximos locais.
    *   *Busca de Feixe Local (Local Beam Search):* Mant√©m `k` estados em paralelo. Em cada passo, gera todos os sucessores dos `k` estados e seleciona os `k` melhores sucessores para a pr√≥xima itera√ß√£o. √â menos suscet√≠vel a m√°ximos locais que a subida de encosta simples.
    *   *Busca de Feixe Local Estoc√°stica (Stochastic Beam Search):* Similar √† busca de feixe local, mas escolhe os `k` sucessores com probabilidade proporcional √† sua qualidade, introduzindo aleatoriedade.
*   **Busca Advers√°ria (Adversarial Search - Jogos):** Projetada para ambientes competitivos com dois ou mais agentes (jogadores) com objetivos opostos. O objetivo √© encontrar a melhor estrat√©gia (sequ√™ncia de movimentos) considerando as poss√≠veis respostas do advers√°rio.
    *   *Algoritmo Minimax:* Para jogos de soma zero com informa√ß√£o perfeita, calcula o movimento √≥timo assumindo que o advers√°rio tamb√©m jogar√° otimamente para minimizar a utilidade do jogador.
    *   *Poda Alfa-Beta (Alpha-Beta Pruning):* Otimiza√ß√£o do Minimax que descarta ramos da √°rvore de busca que n√£o influenciar√£o a decis√£o final, reduzindo drasticamente o n√∫mero de n√≥s a serem explorados.
    *   *Fun√ß√µes de Avalia√ß√£o Heur√≠stica:* Usadas em jogos complexos (como xadrez) onde a √°rvore completa √© intrat√°vel. Estimam a utilidade esperada de um estado sem explorar at√© o final do jogo.
    *   *Busca em √Årvore Monte Carlo (Monte Carlo Tree Search - MCTS):* Abordagem probabil√≠stica que equilibra explora√ß√£o e explota√ß√£o, realizando simula√ß√µes aleat√≥rias (playouts) a partir do estado atual para estimar o valor dos movimentos. Muito eficaz em jogos como Go.
*   **Busca Online (Online Search):** Aplicada quando o agente precisa agir em um ambiente antes de conhecer completamente o espa√ßo de estados ou os resultados das a√ß√µes. O agente intercala computa√ß√£o (planejamento) e execu√ß√£o, aprendendo sobre o ambiente √† medida que se move.
    *   *Agentes de Busca Online:* Precisam tomar decis√µes com informa√ß√µes limitadas, explorando o ambiente e atualizando seu conhecimento.
    *   *LRTA* (Learning Real-Time A*):* Um exemplo de algoritmo de busca online que aprende custos heur√≠sticos √† medida que explora o ambiente.
*   **Busca com A√ß√µes N√£o Determin√≠sticas ou Observa√ß√µes Parciais:** Lida com incerteza nos resultados das a√ß√µes ou na percep√ß√£o do estado atual.
    *   *Busca AND-OR:* Utilizada para encontrar planos de conting√™ncia que funcionam independentemente do resultado de a√ß√µes n√£o determin√≠sticas.
    *   *Busca no Espa√ßo de Cren√ßas (Belief State Search):* Quando o ambiente √© parcialmente observ√°vel, o agente mant√©m um estado de cren√ßa (uma distribui√ß√£o de probabilidade sobre os estados poss√≠veis) e busca no espa√ßo desses estados de cren√ßa. Relevante para POMDPs (Processos de Decis√£o de Markov Parcialmente Observ√°veis).

*Refer√™ncias:* RUSSELL, S. J.; NORVIG, P. *Intelig√™ncia artificial*. 3. ed. Rio de Janeiro: Elsevier Campus, 2013. Cap√≠tulos 4 (Busca Local, Otimiza√ß√£o), 5 (Busca Advers√°ria), partes dos Cap√≠tulos 4 e 12 (Busca Online, Incerteza).

---



## 4. Algoritmos Gen√©ticos e Evolucion√°rios

Os Algoritmos Gen√©ticos (AGs) pertencem a uma classe mais ampla de algoritmos evolucion√°rios, que se inspiram na evolu√ß√£o biol√≥gica para resolver problemas de busca e otimiza√ß√£o. Eles operam sobre uma popula√ß√£o de solu√ß√µes candidatas, aplicando operadores como sele√ß√£o, recombina√ß√£o (cruzamento) e muta√ß√£o para gerar novas popula√ß√µes com aptid√£o progressivamente maior. Russell e Norvig (2013) discutem essas abordagens no contexto da busca local estoc√°stica e otimiza√ß√£o:

*   **Algoritmos Gen√©ticos (Genetic Algorithms - GAs):** Os AGs mant√™m uma popula√ß√£o de estados candidatos (representados como strings ou cromossomos) e geram a pr√≥xima gera√ß√£o combinando pares de indiv√≠duos (cruzamento) e introduzindo pequenas altera√ß√µes aleat√≥rias (muta√ß√£o). A sele√ß√£o dos pais geralmente favorece indiv√≠duos com maior aptid√£o (fitness), que mede a qualidade da solu√ß√£o representada pelo indiv√≠duo.
*   **Programa√ß√£o Gen√©tica (Genetic Programming - GP):** Uma variante dos AGs onde os indiv√≠duos na popula√ß√£o s√£o programas de computador (geralmente representados como √°rvores de express√£o) em vez de strings. O objetivo √© evoluir um programa que resolva uma tarefa espec√≠fica. Os operadores de cruzamento e muta√ß√£o s√£o adaptados para manipular essas estruturas de programa.
*   **Estrat√©gias de Evolu√ß√£o (Evolution Strategies - ES):** Outra abordagem evolucion√°ria, frequentemente usada para otimiza√ß√£o de par√¢metros em espa√ßos cont√≠nuos. Diferentemente dos AGs cl√°ssicos que operam em representa√ß√µes bin√°rias ou discretas e enfatizam o cruzamento, as ES geralmente trabalham com vetores de n√∫meros reais e focam mais na muta√ß√£o (frequentemente usando distribui√ß√µes gaussianas) e na sele√ß√£o determin√≠stica ou probabil√≠stica dos melhores indiv√≠duos (pais e/ou filhos) para formar a pr√≥xima gera√ß√£o.

Esses algoritmos s√£o considerados "disruptivos" ou estoc√°sticos porque introduzem aleatoriedade e operam em popula√ß√µes, permitindo-lhes explorar diferentes regi√µes do espa√ßo de busca simultaneamente e escapar de √≥timos locais onde algoritmos mais determin√≠sticos como a subida de encosta poderiam ficar presos.

*Refer√™ncia:* RUSSELL, S. J.; NORVIG, P. *Intelig√™ncia artificial*. 3. ed. Rio de Janeiro: Elsevier Campus, 2013. Cap√≠tulo 4 (particularmente a se√ß√£o sobre algoritmos gen√©ticos).

<!-- coment√°rio 
## 5. Sugest√µes de Algoritmos Alternativos

Considerando os algoritmos j√° presentes em seu portf√≥lio (BFS, A*, Hill Climbing e GA) e a lista de algoritmos dispon√≠veis em Russell e Norvig (2013), sugiro as seguintes alternativas interessantes para cada categoria, que provavelmente diferem dos exemplos dados em sala:

*   **Para Busca Cega:** Em vez de BFS, sugiro a **Busca com Aprofundamento Iterativo (Iterative Deepening Depth-First Search - IDDFS)**. Este algoritmo combina a completude e otimalidade (para custos uniformes) da BFS com a efici√™ncia de mem√≥ria da DFS, sendo uma escolha robusta quando a profundidade da solu√ß√£o √© desconhecida.
*   **Para Busca Informada:** Como alternativa ao A*, proponho a **Busca Recursiva Best-First (Recursive Best-First Search - RBFS)**. Ela tenta emular a A* usando espa√ßo de mem√≥ria linear, o que a torna √∫til em problemas onde a mem√≥ria √© uma restri√ß√£o significativa, embora possa recomputar n√≥s.
*   **Para Busca em Ambientes Complexos:** No lugar da Subida de Encosta, sugiro o **Recozimento Simulado (Simulated Annealing)**. √â um algoritmo de busca local estoc√°stico que permite movimentos para estados piores com uma probabilidade decrescente, o que o ajuda a escapar de √≥timos locais onde a Subida de Encosta poderia ficar presa.
*   **Para Algoritmos Gen√©ticos/Disruptivos:** Como alternativa ao Algoritmo Gen√©tico cl√°ssico, sugiro as **Estrat√©gias de Evolu√ß√£o (Evolution Strategies - ES)**. Embora compartilhem a inspira√ß√£o evolucion√°ria, as ES frequentemente operam em espa√ßos cont√≠nuos e utilizam mecanismos de muta√ß√£o e sele√ß√£o distintos dos AGs tradicionais, focando mais na otimiza√ß√£o de par√¢metros.

A seguir, apresentarei uma explica√ß√£o detalhada para cada um desses algoritmos selecionados.

---
-->



### 5.1. Busca Cega Alternativa: Busca com Aprofundamento Iterativo (IDDFS)

A Busca com Aprofundamento Iterativo (Iterative Deepening Depth-First Search - IDDFS), conforme descrita por Russell e Norvig (2013), representa uma engenhosa combina√ß√£o das vantagens da Busca em Largura (BFS) e da Busca em Profundidade (DFS). Enquanto a BFS garante encontrar a solu√ß√£o mais rasa (√≥tima em termos de n√∫mero de passos para custos uniformes) e √© completa, ela sofre com altos requisitos de mem√≥ria, que podem crescer exponencialmente com a profundidade. Por outro lado, a DFS possui requisitos de mem√≥ria modestos (lineares em rela√ß√£o √† profundidade m√°xima), mas n√£o √© completa em espa√ßos de estados infinitos ou com ciclos, e n√£o garante otimalidade.

A IDDFS supera essas limita√ß√µes realizando repetidas buscas em profundidade, mas com um limite de profundidade crescente. Ela come√ßa com uma busca em profundidade limitada √† profundidade 0 (apenas o n√≥ inicial). Se a solu√ß√£o n√£o for encontrada, ela descarta os n√≥s gerados e inicia uma nova busca em profundidade, desta vez com limite 1. Esse processo continua, incrementando o limite de profundidade (2, 3, 4, ...) a cada itera√ß√£o, at√© que uma solu√ß√£o seja encontrada no limite de profundidade atual `d`. Como ela explora todos os n√≥s at√© a profundidade `d-1` antes de explorar qualquer n√≥ na profundidade `d`, ela efetivamente simula a ordem de expans√£o da BFS, garantindo que a primeira solu√ß√£o encontrada seja a mais rasa (e, portanto, √≥tima se os custos dos passos forem uniformes).

A principal preocupa√ß√£o com a IDDFS √© a aparente redund√¢ncia, j√° que os n√≥s nos n√≠veis superiores da √°rvore de busca s√£o gerados m√∫ltiplas vezes em diferentes itera√ß√µes. No entanto, Russell e Norvig (2013) demonstram que, para √°rvores de busca onde a maioria dos n√≥s est√° no n√≠vel mais baixo (o que √© comum em muitos problemas, especialmente com fatores de ramifica√ß√£o maiores que 1), o custo adicional de regenerar os n√≥s superiores √© relativamente pequeno em compara√ß√£o com o custo de explorar o √∫ltimo n√≠vel. A complexidade de tempo da IDDFS acaba sendo da mesma ordem de magnitude que a da BFS (O(b^d)), enquanto sua complexidade de espa√ßo √© a mesma da DFS (O(bd)), onde `b` √© o fator de ramifica√ß√£o e `d` √© a profundidade da solu√ß√£o mais rasa. Essa combina√ß√£o de completude, otimalidade (para custos uniformes) e efici√™ncia de mem√≥ria torna a IDDFS a estrat√©gia de busca cega preferida em muitas situa√ß√µes onde o espa√ßo de estados √© grande e a profundidade da solu√ß√£o √© desconhecida.

```python


# Representa√ß√£o de um grafo simples como dicion√°rio

grafo = {
    'A': ['B', 'C', 'D'],
    'B': ['E'],
    'C': [],
    'D': ['F'],
    'E': [],
    'F': []
}

def dfs_limitado(grafo, no_atual, objetivo, limite):
    """
    Busca em profundidade limitada a um certo n√≠vel.
    
    :param grafo: Dicion√°rio representando o grafo
    :param no_atual: N√≥ atual na busca
    :param objetivo: N√≥ que queremos encontrar
    :param limite: Profundidade m√°xima permitida
    :return: True se o objetivo for encontrado, False caso contr√°rio
    """
    print(f"Visitando {no_atual}, limite restante: {limite}")
    
    if no_atual == objetivo:
        return True
    if limite == 0:
        return False

    for vizinho in grafo.get(no_atual, []):
        if dfs_limitado(grafo, vizinho, objetivo, limite - 1):
            return True
    return False

def iddfs(grafo, inicio, objetivo, limite_maximo):
    """
    Busca com Aprofundamento Iterativo (IDDFS).
    
    :param grafo: Dicion√°rio com os n√≥s e vizinhos
    :param inicio: N√≥ inicial da busca
    :param objetivo: N√≥ que queremos encontrar
    :param limite_maximo: Profundidade m√°xima de busca
    :return: True se encontrou o objetivo, False caso contr√°rio
    """
    for profundidade in range(limite_maximo + 1):
        print(f"\nüîÅ Profundidade atual: {profundidade}")
        if dfs_limitado(grafo, inicio, objetivo, profundidade):
            print(f"\n‚úÖ Objetivo '{objetivo}' encontrado na profundidade {profundidade}.")
            return True
    print(f"\n‚ùå Objetivo '{objetivo}' n√£o encontrado at√© a profundidade {limite_maximo}.")
    return False

# Executa o algoritmo procurando o n√≥ 'F' a partir do n√≥ 'A' com profundidade m√°xima 3
iddfs(grafo, 'A', 'F', 3)
```


*Refer√™ncia:* RUSSELL, S. J.; NORVIG, P. *Intelig√™ncia artificial*. 3. ed. Rio de Janeiro: Elsevier Campus, 2013. Cap√≠tulo 3.

---



### 5.2. Busca Informada Alternativa: Busca Recursiva Best-First (RBFS)

A Busca A* √© renomada por sua otimalidade e completude quando usada com heur√≠sticas admiss√≠veis, mas sua principal desvantagem reside na potencial necessidade exponencial de mem√≥ria para armazenar a fronteira (n√≥s abertos). Para contornar essa limita√ß√£o, Russell e Norvig (2013) apresentam a Busca Recursiva Best-First (Recursive Best-First Search - RBFS), um algoritmo que visa mimetizar a opera√ß√£o da A* utilizando apenas espa√ßo linear, similar √† busca em profundidade.

A RBFS opera de forma recursiva. Ela mant√©m o controle do valor `f` (custo `g` + heur√≠stica `h`) do melhor caminho alternativo dispon√≠vel a partir do ancestral do n√≥ atual (um limite superior, `f_limit`). A fun√ß√£o recursiva explora um caminho enquanto o valor `f` dos n√≥s nesse caminho n√£o excede esse limite. Se um n√≥ folha √© alcan√ßado e representa uma solu√ß√£o, a busca termina com sucesso. Se todos os caminhos a partir de um n√≥ excedem o `f_limit`, a recurs√£o retrocede (backtracks) para o n√≥ ancestral. Crucialmente, ao retroceder, a RBFS atualiza o valor `f` do n√≥ que acabou de explorar para refletir o melhor valor `f` encontrado em seus descendentes (incluindo aqueles que excederam o limite). Esse valor atualizado pode ent√£o guiar a busca futura, potencialmente fazendo com que a RBFS decida explorar um caminho diferente que antes parecia menos promissor, mas cujo valor `f` agora √© o melhor abaixo do limite.

A principal vantagem da RBFS √© sua efici√™ncia de espa√ßo, que √© linear em rela√ß√£o √† profundidade da solu√ß√£o mais rasa (`O(bd)`). Ela tamb√©m √© √≥tima e completa, assim como A*, *se* conseguir encontrar a solu√ß√£o (o que depende de ter mem√≥ria suficiente para o caminho em si e a pilha de recurs√£o). No entanto, sua maior desvantagem √© a potencial re-gera√ß√£o excessiva de n√≥s. Como ela descarta sub√°rvores ao retroceder para economizar mem√≥ria, pode ser que precise re-explorar a mesma sub√°rvore m√∫ltiplas vezes se os limites `f` mudarem favoravelmente para ela novamente. Esse comportamento pode tornar a RBFS significativamente mais lenta que a A* em termos de tempo, especialmente se os valores `f` dos n√≥s forem muito pr√≥ximos entre si, levando a muitas mudan√ßas de foco entre diferentes caminhos. Apesar disso, a RBFS √© uma alternativa valiosa quando a mem√≥ria √© o principal gargalo para a aplica√ß√£o da A*.

```python
import math

# Representa√ß√£o do grafo com custos reais (g) e heur√≠sticas (h)
grafo = {
    'A': [('B', 1), ('C', 4)],
    'B': [('D', 5), ('E', 2)],
    'C': [('F', 3)],
    'D': [],
    'E': [('G', 2)],
    'F': [('G', 2)],
    'G': []
}

# Heur√≠stica h(n) estimando a dist√¢ncia de n at√© o objetivo G
heuristica = {
    'A': 7,
    'B': 6,
    'C': 5,
    'D': 7,
    'E': 4,
    'F': 2,
    'G': 0  # objetivo
}

def rbfs(no, objetivo, g, f_limit):
    """
    Implementa a Busca Recursiva Best-First Search (RBFS).
    
    :param no: N√≥ atual
    :param objetivo: N√≥ alvo
    :param g: Custo acumulado at√© aqui
    :param f_limit: Limite superior de f(n) aceito at√© o momento
    :return: (solu√ß√£o encontrada?, novo f(n) m√≠nimo entre as op√ß√µes seguintes)
    """
    print(f"üîç Explorando {no} com f_limit={f_limit}")

    if no == objetivo:
        print(f"‚úÖ Objetivo {objetivo} alcan√ßado!")
        return True, g + heuristica[no]

    # Gerar sucessores com seus valores f(n) = g + custo + h
    sucessores = []
    for vizinho, custo in grafo.get(no, []):
        f_n = g + custo + heuristica[vizinho]
        sucessores.append((vizinho, g + custo, f_n))

    if not sucessores:
        return False, math.inf  # sem sucessores = caminho morto

    while True:
        # Ordenar sucessores pelo menor f(n)
        sucessores.sort(key=lambda x: x[2])
        melhor = sucessores[0]
        print(f"‚û°Ô∏è Melhor: {melhor[0]} com f={melhor[2]}")

        if melhor[2] > f_limit:
            return False, melhor[2]  # excede o limite permitido

        # Escolha alternativa mais promissora caso a atual falhe
        alternativa = sucessores[1][2] if len(sucessores) > 1 else math.inf
        resultado, novo_f = rbfs(melhor[0], objetivo, melhor[1], min(f_limit, alternativa))
        sucessores[0] = (melhor[0], melhor[1], novo_f)

        if resultado:
            return True, novo_f

def iniciar_rbfs(inicio, objetivo):
    print(f"üöÄ Iniciando RBFS de {inicio} at√© {objetivo}")
    sucesso, _ = rbfs(inicio, objetivo, 0, math.inf)
    if sucesso:
        print("üèÅ Caminho encontrado com sucesso!")
    else:
        print("‚ùå Caminho n√£o encontrado.")



```



*Refer√™ncia:* RUSSELL, S. J.; NORVIG, P. *Intelig√™ncia artificial*. 3. ed. Rio de Janeiro: Elsevier Campus, 2013. Cap√≠tulo 3.

---



### 5.3. Busca em Ambientes Complexos Alternativa: Recozimento Simulado (Simulated Annealing)

Enquanto a Subida de Encosta (Hill Climbing) √© uma t√©cnica de busca local direta que sempre busca melhorias imediatas, ela frequentemente falha ao ficar presa em √≥timos locais. O Recozimento Simulado (Simulated Annealing), apresentado por Russell e Norvig (2013) como uma melhoria sobre a subida de encosta, oferece uma solu√ß√£o probabil√≠stica para este problema. Inspirado no processo f√≠sico de recozimento (annealing) em metalurgia, onde um material √© aquecido e depois resfriado lentamente para aumentar o tamanho de seus cristais e reduzir seus defeitos, o algoritmo permite movimentos ocasionais para estados piores, diminuindo a probabilidade desses movimentos ao longo do tempo.

O algoritmo come√ßa em um estado inicial aleat√≥rio e, a cada itera√ß√£o, considera um movimento para um vizinho aleat√≥rio. Se o vizinho for melhor (maior valor na fun√ß√£o objetivo para maximiza√ß√£o, ou menor para minimiza√ß√£o), o movimento √© sempre aceito. Se o vizinho for pior, ele ainda pode ser aceito com uma certa probabilidade, que depende de dois fatores: qu√£o pior √© o vizinho (a diferen√ßa de valor, `ŒîE`) e um par√¢metro chamado "temperatura" (`T`). A probabilidade de aceitar um movimento pior √© tipicamente dada por `exp(ŒîE / T)` (para maximiza√ß√£o, onde `ŒîE` seria negativo e menor; para minimiza√ß√£o, seria `exp(-ŒîE / T)` com `ŒîE` positivo). No in√≠cio, a temperatura `T` √© alta, permitindo que muitos movimentos ruins sejam aceitos, o que possibilita ao algoritmo explorar amplamente o espa√ßo de busca e escapar de √≥timos locais iniciais. Gradualmente, a temperatura √© reduzida de acordo com um "cronograma de resfriamento" (cooling schedule). √Ä medida que `T` diminui, a probabilidade de aceitar movimentos ruins tamb√©m diminui, fazendo com que o algoritmo se concentre cada vez mais em melhorias locais, convergindo eventualmente para um estado de baixa energia (alta qualidade).

A grande vantagem do Recozimento Simulado √© sua capacidade de encontrar √≥timos globais (ou solu√ß√µes muito pr√≥ximas a eles) com maior probabilidade do que a Subida de Encosta, justamente por permitir escapar de √≥timos locais. No entanto, seu desempenho √© muito sens√≠vel √† escolha do cronograma de resfriamento (como a temperatura inicial, a taxa de decaimento e o crit√©rio de parada). Um resfriamento muito r√°pido pode fazer com que ele se comporte como a Subida de Encosta e fique preso; um resfriamento muito lento pode torn√°-lo computacionalmente caro. Apesar dessa necessidade de ajuste de par√¢metros, o Recozimento Simulado √© uma t√©cnica robusta e amplamente utilizada para problemas de otimiza√ß√£o combinat√≥ria complexos, como o problema do caixeiro viajante, projeto de circuitos e aloca√ß√£o de recursos.

```python


import math
import random

# Fun√ß√£o objetivo que queremos maximizar
def funcao_objetivo(x):
    return x * math.sin(x)

# Gera um novo vizinho com uma pequena perturba√ß√£o
def vizinho(x, intervalo=0.5):
    return x + random.uniform(-intervalo, intervalo)

# Cronograma de resfriamento simples: temperatura decai lentamente
def simulated_annealing():
    # Par√¢metros iniciais
    temperatura_inicial = 1000
    temperatura_final = 1e-3
    fator_resfriamento = 0.95
    max_iter_por_temp = 100

    # Estado inicial aleat√≥rio dentro do intervalo [0, 10]
    estado_atual = random.uniform(0, 10)
    valor_atual = funcao_objetivo(estado_atual)

    temperatura = temperatura_inicial

    print(f"üöÄ In√≠cio: x = {estado_atual:.4f}, f(x) = {valor_atual:.4f}")

    while temperatura > temperatura_final:
        for _ in range(max_iter_por_temp):
            candidato = vizinho(estado_atual)
            # Garantir que o candidato continue dentro do intervalo
            candidato = max(0, min(10, candidato))

            valor_candidato = funcao_objetivo(candidato)
            delta = valor_candidato - valor_atual

            if delta > 0:
                # Melhor movimento: sempre aceita
                estado_atual, valor_atual = candidato, valor_candidato
            else:
                # Movimento pior: aceita com probabilidade exp(ŒîE / T)
                probabilidade = math.exp(delta / temperatura)
                if random.random() < probabilidade:
                    estado_atual, valor_atual = candidato, valor_candidato

        print(f"üå°Ô∏è T = {temperatura:.4f} | Melhor x = {estado_atual:.4f}, f(x) = {valor_atual:.4f}")
        temperatura *= fator_resfriamento  # Resfriamento

    print(f"\nüèÅ Melhor solu√ß√£o encontrada: x = {estado_atual:.4f}, f(x) = {valor_atual:.4f}")
```



*Refer√™ncia:* RUSSELL, S. J.; NORVIG, P. *Intelig√™ncia artificial*. 3. ed. Rio de Janeiro: Elsevier Campus, 2013. Cap√≠tulo 4.

---



### 5.4. Algoritmo Gen√©tico/Disruptivo Alternativo: Estrat√©gias de Evolu√ß√£o (ES)

Dentro do campo da computa√ß√£o evolucion√°ria, os Algoritmos Gen√©ticos (GAs) s√£o talvez os mais conhecidos, mas as Estrat√©gias de Evolu√ß√£o (Evolution Strategies - ES), tamb√©m mencionadas por Russell e Norvig (2013) no contexto de otimiza√ß√£o, representam uma linha de desenvolvimento paralela e distinta, particularmente adequada para problemas de otimiza√ß√£o em espa√ßos de par√¢metros cont√≠nuos. Enquanto os GAs cl√°ssicos frequentemente operam sobre representa√ß√µes bin√°rias ou discretas (cromossomos) e d√£o grande √™nfase ao operador de cruzamento (recombina√ß√£o) para gerar novos indiv√≠duos, as ES tipicamente trabalham diretamente com vetores de n√∫meros reais que representam as solu√ß√µes candidatas.

A principal for√ßa motriz da evolu√ß√£o nas ES √©, muitas vezes, a muta√ß√£o, e n√£o o cruzamento (embora a recombina√ß√£o tamb√©m possa ser usada). A muta√ß√£o em ES √© geralmente implementada adicionando um vetor de ru√≠do gaussiano (normalmente distribu√≠do) ao vetor de par√¢metros do indiv√≠duo pai para criar um descendente. Um aspecto sofisticado de muitas ES modernas √© a capacidade de adaptar os par√¢metros da pr√≥pria muta√ß√£o (como as vari√¢ncias ou covari√¢ncias da distribui√ß√£o gaussiana) ao longo do processo evolutivo. Isso permite que o algoritmo ajuste a "for√ßa" e a "dire√ß√£o" da muta√ß√£o dinamicamente, explorando mais amplamente no in√≠cio e focando em regi√µes promissoras mais tarde.

Os mecanismos de sele√ß√£o nas ES tamb√©m podem diferir dos GAs. Duas nota√ß√µes comuns s√£o (Œº, Œª)-ES e (Œº + Œª)-ES. Na (Œº, Œª)-ES, Œº pais geram Œª descendentes (Œª ‚â• Œº), e os Œº melhores *descendentes* formam a popula√ß√£o da pr√≥xima gera√ß√£o, descartando completamente os pais. Isso permite que a ES escape de √≥timos locais mais facilmente. Na (Œº + Œª)-ES, os Œº melhores indiv√≠duos s√£o selecionados a partir da uni√£o dos Œº pais *e* dos Œª descendentes, garantindo que a melhor solu√ß√£o encontrada at√© o momento nunca seja perdida (elitismo). A escolha entre essas estrat√©gias depende das caracter√≠sticas do problema.

Devido √† sua afinidade com espa√ßos cont√≠nuos e √† adapta√ß√£o de par√¢metros de muta√ß√£o, as Estrat√©gias de Evolu√ß√£o tornaram-se uma ferramenta poderosa para a otimiza√ß√£o de par√¢metros em aprendizado de m√°quina (por exemplo, ajuste de hiperpar√¢metros ou treinamento direto de redes neurais), rob√≥tica, controle e outros dom√≠nios onde as solu√ß√µes s√£o naturalmente representadas por vetores de n√∫meros reais. Elas oferecem uma alternativa robusta aos GAs quando a representa√ß√£o bin√°ria ou o cruzamento tradicional n√£o s√£o os mais adequados.

```python


import random

# Fun√ß√£o objetivo: queremos minimizar f(x) = x^2
def funcao_objetivo(x):
    return x ** 2

# Estrat√©gia de muta√ß√£o: x' = x + N(0, sigma)
def mutacao(x, sigma):
    return x + random.gauss(0, sigma)

def evolution_strategy(mu=10, lamb=40, geracoes=100, sigma_inicial=1.0):
    # Gera√ß√£o inicial: n√∫meros reais aleat√≥rios
    populacao = [random.uniform(-5, 5) for _ in range(mu)]
    sigma = sigma_inicial

    for geracao in range(geracoes):
        descendentes = []

        # Cada pai gera Œª/mu descendentes
        for _ in range(lamb):
            pai = random.choice(populacao)
            filho = mutacao(pai, sigma)
            descendentes.append(filho)

        # Combinar pais e descendentes
        combinados = populacao + descendentes

        # Selecionar os Œº melhores
        populacao = sorted(combinados, key=funcao_objetivo)[:mu]

        # Opcional: adaptar sigma (ex: diminuir ao longo do tempo)
        sigma *= 0.99

        # Diagn√≥stico
        melhor = populacao[0]
        print(f"üß¨ Gera√ß√£o {geracao+1}: Melhor x = {melhor:.4f}, f(x) = {funcao_objetivo(melhor):.4f}, œÉ = {sigma:.4f}")

    print(f"\nüèÅ Solu√ß√£o final: x = {melhor:.4f}, f(x) = {funcao_objetivo(melhor):.4f}")


```



*Refer√™ncia:* RUSSELL, S. J.; NORVIG, P. *Intelig√™ncia artificial*. 3. ed. Rio de Janeiro: Elsevier Campus, 2013. Cap√≠tulo 4 (mencionado brevemente no contexto de otimiza√ß√£o estoc√°stica).

---




## 4. Conclus√£o: Principais Aprendizados, Vantagens e Limita√ß√µes

A resolu√ß√£o de problemas por busca √© um dos pilares da Intelig√™ncia Artificial, fornecendo uma estrutura formal para abordar uma ampla gama de tarefas, desde jogos simples at√© problemas complexos do mundo real. O conceito central envolve a explora√ß√£o de um espa√ßo de estados para encontrar uma sequ√™ncia de a√ß√µes que leve a um estado objetivo.

**Principais Aprendizados:**

*   **Diversidade de Estrat√©gias:** Aprendemos que existe uma vasta gama de estrat√©gias de busca, cada uma com suas pr√≥prias caracter√≠sticas. As buscas cegas, como a Busca em Largura (BFS), s√£o sistem√°ticas e podem garantir completude e otimalidade (em certos casos), mas frequentemente sofrem com alta complexidade de tempo e espa√ßo. Por outro lado, as buscas informadas, como A*, utilizam heur√≠sticas para guiar a explora√ß√£o de forma mais eficiente, reduzindo drasticamente o esfor√ßo computacional quando a heur√≠stica √© bem projetada. A A* se destaca por sua capacidade de encontrar o caminho de menor custo de forma completa e √≥tima, desde que sua heur√≠stica seja admiss√≠vel.
*   **Import√¢ncia das Heur√≠sticas:** A qualidade da fun√ß√£o heur√≠stica √© crucial para o desempenho das buscas informadas. Uma boa heur√≠stica pode transformar um problema intrat√°vel em um solucion√°vel, enquanto uma heur√≠stica ruim pode levar a um desempenho pior que o da busca cega.
*   **Busca em Ambientes Complexos:** Para problemas onde o espa√ßo de estados √© muito grande ou as solu√ß√µes √≥timas n√£o s√£o estritamente necess√°rias, algoritmos de busca local como o Hill Climbing oferecem uma alternativa eficiente em termos de mem√≥ria. Embora possam ficar presos em m√°ximos locais, t√©cnicas como rein√≠cio aleat√≥rio podem mitigar esse problema. Eles s√£o √∫teis para otimiza√ß√£o cont√≠nua.
*   **Abordagens Evolutivas:** Algoritmos Gen√©ticos representam uma classe de busca estoc√°stica inspirada na evolu√ß√£o natural. Eles s√£o robustos para lidar com espa√ßos de busca complexos, multimodais e ruidosos. Atrav√©s da manuten√ß√£o de uma popula√ß√£o de solu√ß√µes e da aplica√ß√£o de operadores gen√©ticos (sele√ß√£o, cruzamento, muta√ß√£o), os AGs podem explorar globalmente o espa√ßo de busca e encontrar solu√ß√µes de alta qualidade, embora n√£o garantam a otimalidade em tempo finito.
*   **Trade-offs:** A escolha do algoritmo de busca ideal envolve uma an√°lise cuidadosa dos trade-offs entre completude, otimalidade, complexidade de tempo e complexidade de espa√ßo, al√©m da natureza do problema e da disponibilidade de informa√ß√µes heur√≠sticas.

**Vantagens Gerais da Resolu√ß√£o de Problemas por Busca:**

*   **Generalidade:** A formula√ß√£o de problemas como busca em um espa√ßo de estados √© uma abordagem muito geral, aplic√°vel a diversos dom√≠nios.
*   **Fundamenta√ß√£o Te√≥rica:** Muitos algoritmos de busca possuem uma base te√≥rica s√≥lida que permite analisar seu comportamento e garantias.
*   **Automatiza√ß√£o do Racioc√≠nio:** Permitem que agentes encontrem solu√ß√µes para problemas sem interven√ß√£o humana direta, simulando formas de racioc√≠nio.

**Limita√ß√µes Gerais da Resolu√ß√£o de Problemas por Busca:**

*   **Explos√£o Combinat√≥ria:** Para muitos problemas, o tamanho do espa√ßo de estados cresce exponencialmente com o tamanho do problema, tornando a busca exaustiva invi√°vel (a "maldi√ß√£o da dimensionalidade").
*   **Representa√ß√£o do Problema:** A efic√°cia da busca depende criticamente de como o problema √© formulado (defini√ß√£o de estados, a√ß√µes, custos).
*   **Necessidade de Heur√≠sticas (para efici√™ncia):** Para problemas complexos, buscas cegas s√£o frequentemente ineficientes, e o desenvolvimento de boas heur√≠sticas pode ser um desafio em si.
*   **M√°ximos Locais e Plat√¥s:** Algoritmos de busca local e alguns outros podem ficar presos em solu√ß√µes sub√≥timas devido √† topografia do espa√ßo de busca.

Em suma, as t√©cnicas de resolu√ß√£o de problemas por busca s√£o ferramentas essenciais no arsenal da Intelig√™ncia Artificial. A compreens√£o de suas diversas formas, vantagens e limita√ß√µes permite aos desenvolvedores escolher e adaptar a abordagem mais adequada para construir sistemas inteligentes capazes de resolver problemas de forma eficaz e eficiente.

## 5. Refer√™ncias Bibliogr√°ficas

LUGER, G. F. *Artificial Intelligence: Structures and Strategies for Complex Problem Solving*. 6. ed. Boston, MA: Pearson, 2009.

MARSLAND, S. *Machine Learning: An Algorithmic Perspective*. 2. ed. Boca Raton, FL: CRC Press, 2014.

RUSSELL, S. J.; NORVIG, P. *Artificial Intelligence: A Modern Approach*. 3. ed. Upper Saddle River, NJ: Prentice Hall, 2010.

SUTTON, R. S.; BARTO, A. G. *Reinforcement Learning: An Introduction*. 2. ed. Cambridge, MA: MIT Press, 2018.

DATACAMP. *Implementing the Hill Climbing Algorithm for AI in Python*. [S.l.]: DataCamp, [s.d.]. Dispon√≠vel em: https://www.datacamp.com/tutorial/hill-climbing-algorithm-for-ai-in-python. Acesso em: 16 maio 2025.

**Materiais de Aula (Slides da Disciplina):**

FGA0221 ‚Äì IA - 06. Material de aula da disciplina de Intelig√™ncia Artificial. [S.l.: s.n., s.d.].

FGA0221 ‚Äì IA - 07. Material de aula da disciplina de Intelig√™ncia Artificial. [S.l.: s.n., s.d.].

FGA0221 ‚Äì IA - 08. Material de aula da disciplina de Intelig√™ncia Artificial. [S.l.: s.n., s.d.].

FGA0221 ‚Äì IA - 09. Material de aula da disciplina de Intelig√™ncia Artificial. [S.l.: s.n., s.d.].

*   Russell, S., & Norvig, P. (2010). *Artificial Intelligence: A Modern Approach* (3rd ed.). Prentice Hall.
*   Material da disciplina FGA0221 ‚Äì IA - Slides 06.
*   Material da disciplina FGA0221 ‚Äì IA - Slides 07.
*   Material da disciplina FGA0221 ‚Äì IA - Slides 08.
*   Material da disciplina FGA0221 ‚Äì IA - Slides 09.
*   Marsland, S. (2014). *Machine Learning: An Algorithmic Perspective* (2nd ed.). Chapman and Hall/CRC.
*   Sutton, R. S., & Barto, A. G. (2018). *Reinforcement Learning: An Introduction* (2nd ed.). MIT Press.
*   Luger, G. F. (2009). *Artificial Intelligence: Structures and Strategies for Complex Problem Solving* (6th ed.). Pearson.

