# Portf√≥lio: Resolvendo Problemas por Busca em Intelig√™ncia Artificial

## 1. Introdu√ß√£o: Import√¢ncia e Impacto da Resolu√ß√£o de Problemas por Busca na IA e na Sociedade

A Intelig√™ncia Artificial (IA) envolve o estudo de agentes que recebem percep√ß√µes do ambiente e realizam a√ß√µes. Definimos IA como o estudo da a√ß√£o racional e, nesse contexto, o planejamento ‚Äî elaborar um plano de a√ß√£o para alcan√ßar objetivos ‚Äî √© uma parte crucial da IA.

A resolu√ß√£o de problemas por busca √© uma t√©cnica central em IA para encontrar uma sequ√™ncia de a√ß√µes que leve um agente a atingir um objetivo. Newell e Simon argumentaram que esta √© a base essencial da resolu√ß√£o de problemas humanos, como um jogador de xadrez examinando movimentos ou um m√©dico considerando diagn√≥sticos alternativos. Embora as primeiras abordagens pudessem ser ineficientes sem orienta√ß√£o adequada, a busca, juntamente com a representa√ß√£o do conhecimento, permanece no cerne da maioria dos trabalhos modernos em IA.

A busca √© uma metodologia de resolu√ß√£o de problemas que explora sistematicamente um espa√ßo de estados, que representa os est√°gios sucessivos e alternativos no processo de busca pela solu√ß√£o. Exemplos pr√°ticos de aplica√ß√£o da busca incluem layout VLSI (circuitos integrados de larga escala), navega√ß√£o rob√≥tica, sequenciamento de montagem autom√°tica e problemas de roteamento. Al√©m disso, a busca tem sido aplicada em √°reas como diagn√≥stico de falhas mec√¢nicas e mesmo no racioc√≠nio baseado em l√≥gica.

A capacidade de um agente de resolver problemas atrav√©s da busca permite que ele navegue por ambientes complexos, tome decis√µes sequenciais e encontre caminhos para atingir metas, tornando-se uma ferramenta indispens√°vel para a cria√ß√£o de sistemas inteligentes.

### 1.1 Hist√≥rico e Evolu√ß√£o da Busca em IA

A hist√≥ria da busca em IA remonta aos prim√≥rdios da disciplina nos anos 1950, quando pesquisadores como Allen Newell e Herbert Simon desenvolveram os primeiros programas de resolu√ß√£o de problemas, como o Logic Theorist e o General Problem Solver (GPS). Estes sistemas pioneiros utilizavam t√©cnicas de busca para provar teoremas matem√°ticos e resolver quebra-cabe√ßas, respectivamente.

Durante os anos 1960 e 1970, houve avan√ßos significativos com o desenvolvimento de algoritmos como A* por Peter Hart, Nils Nilsson e Bertram Raphael em 1968, que introduziu o conceito de busca heur√≠stica eficiente. Este per√≠odo tamb√©m viu o surgimento de t√©cnicas como a busca em profundidade iterativa (IDDFS) e a busca bidirecional.

Nos anos 1980 e 1990, com o aumento do poder computacional, as t√©cnicas de busca foram aplicadas a problemas mais complexos, incluindo jogos como xadrez, culminando na vit√≥ria do Deep Blue da IBM sobre o campe√£o mundial Garry Kasparov em 1997. Este per√≠odo tamb√©m viu a integra√ß√£o de t√©cnicas de busca com m√©todos probabil√≠sticos e de aprendizado de m√°quina, incluindo o desenvolvimento e refinamento de algoritmos evolucion√°rios e de busca local como Recozimento Simulado e Estrat√©gias de Evolu√ß√£o.

Atualmente, os algoritmos de busca continuam sendo fundamentais em IA, formando a base de sistemas de navega√ß√£o, planejamento de rotas, diagn√≥stico m√©dico, otimiza√ß√£o de par√¢metros e muitas outras aplica√ß√µes que impactam diretamente nossa sociedade.

## 2. Apresenta√ß√£o dos Conceitos Principais

A abordagem de resolu√ß√£o de problemas por busca se baseia na ideia de que um agente pode adotar um objetivo e trabalhar para satisfaz√™-lo. Um agente de solu√ß√£o de problemas √© um tipo de agente baseado em objetivos.

Os principais conceitos envolvidos s√£o:

*   **Formula√ß√£o de Objetivo:** O agente adota um ou mais objetivos que deseja alcan√ßar.
*   **Formula√ß√£o de Problema:** O agente descreve os estados poss√≠veis do "mundo" e as a√ß√µes que pode realizar para transitar entre esses estados, visando atingir o objetivo. Estados do mundo podem ser considerados como totalidades sem estrutura interna vis√≠vel (representa√ß√£o at√¥mica), que √© a representa√ß√£o considerada na busca b√°sica.
*   **Espa√ßo de Estados (State Space):** √â uma representa√ß√£o formal do problema. √â definido por uma qu√°drupla `[N, A, S, GD]`, onde:
    *   `N` √© o conjunto de n√≥s ou estados do grafo, correspondendo aos estados no processo de resolu√ß√£o do problema.
    *   `A` √© o conjunto de arcos que conectam pares de n√≥s, representando conex√µes diretas ou a√ß√µes que levam de um estado a outro.
    *   `S` √© o estado inicial.
    *   `GD` √© a descri√ß√£o dos estados objetivo, ou seja, a condi√ß√£o que define que o problema foi resolvido.
    Uma solu√ß√£o para um problema √© representada como um caminho no grafo do estado inicial a um estado objetivo.
*   **Busca (Search):** Antes de agir, o agente simula sequ√™ncias de a√ß√µes em seu modelo (o espa√ßo de estados) para encontrar um caminho que leve ao objetivo. Isso envolve testar sistematicamente caminhos alternativos.
*   **Execu√ß√£o:** Uma vez encontrado um caminho (solu√ß√£o) pela busca, o agente executa as a√ß√µes correspondentes no ambiente real.
*   **Agentes de Solu√ß√£o de Problemas:** S√£o agentes baseados em objetivos que utilizam a busca em representa√ß√µes at√¥micas de estados para encontrar solu√ß√µes.
*   **Estrat√©gias de Busca:** S√£o os algoritmos usados para explorar o espa√ßo de estados. Elas podem ser:
    *   **Busca Cega (Uninformed Search):** Algoritmos que n√£o utilizam nenhuma informa√ß√£o sobre o qu√£o pr√≥ximo um estado est√° do(s) objetivo(s) al√©m da defini√ß√£o do problema.
    *   **Busca Informada (Informed Search):** Algoritmos que utilizam dicas espec√≠ficas do dom√≠nio (heur√≠sticas) sobre a localiza√ß√£o dos objetivos para guiar a busca de forma mais eficiente.
*   **Heur√≠sticas:** S√£o fun√ß√µes, denotadas como `h(n)`, que fornecem uma estimativa do custo do caminho mais econ√¥mico do estado no n√≥ `n` para um estado objetivo. Elas s√£o informa√ß√µes espec√≠ficas do dom√≠nio que podem melhorar significativamente a efici√™ncia da busca.
*   **Medidas de Performance:** Crit√©rios para avaliar algoritmos de busca:
    *   **Completude (Completeness):** O algoritmo garante encontrar uma solu√ß√£o quando existe uma, ou reportar a falha corretamente.
    *   **Otimiza√ß√£o de Custos (Cost Optimization):** O algoritmo garante encontrar a solu√ß√£o com o menor custo.
    *   **Complexidade de Tempo (Time Complexity):** Quanto tempo leva para encontrar a solu√ß√£o.
    *   **Complexidade de Espa√ßo (Space Complexity):** Quanta mem√≥ria √© necess√°ria para a busca.
*   **Filas:** Estruturas de dados usadas para gerenciar a ordem em que os n√≥s s√£o explorados pelos algoritmos de busca: fila FIFO (First-In, First-Out) para busca em largura, pilha LIFO (Last-In, First-Out) para busca em profundidade, e fila de prioridade para busca *best-first*. O uso dessas estruturas permite que os algoritmos explorem estados n√£o testados (lista *open*) e evitem repetir caminhos infrut√≠feros (lista *closed*).

### 2.1 Discuss√£o PEAS para Problema de Otimiza√ß√£o de Par√¢metros de Antena

Para ilustrar a aplica√ß√£o do modelo PEAS (Performance, Environment, Actuators, Sensors) em um contexto de otimiza√ß√£o, analisaremos o problema de ajustar os par√¢metros de uma antena de phased array para maximizar a intensidade do sinal em uma dire√ß√£o espec√≠fica:

**Performance (Medida de Desempenho):**
- Maximizar a diretividade (ganho) na dire√ß√£o desejada.
- Minimizar a pot√™ncia nos l√≥bulos laterais (sidelobes).
- Manter a imped√¢ncia de entrada dentro de limites aceit√°veis.
- Convergir para uma boa solu√ß√£o em tempo computacional razo√°vel.

**Environment (Ambiente):**
- Espa√ßo de par√¢metros da antena (fases e amplitudes dos elementos).
- Modelo eletromagn√©tico que simula o padr√£o de radia√ß√£o da antena para um dado conjunto de par√¢metros.
- Restri√ß√µes f√≠sicas ou de design nos par√¢metros.
- O ambiente √© tipicamente est√°tico (o modelo n√£o muda durante a otimiza√ß√£o) e totalmente observ√°vel (podemos calcular o desempenho para qualquer conjunto de par√¢metros).

**Actuators (Atuadores):**
- O algoritmo de otimiza√ß√£o (ex: Estrat√©gias de Evolu√ß√£o) que modifica os par√¢metros da antena (fases/amplitudes) a cada itera√ß√£o.

**Sensors (Sensores):**
- A fun√ß√£o objetivo (ou fun√ß√£o de fitness) que avalia a qualidade de um conjunto de par√¢metros, calculando a diretividade, n√≠veis de l√≥bulos laterais, etc., com base no modelo eletromagn√©tico.

### 2.2 Descri√ß√£o do Ambiente do Problema

O ambiente de otimiza√ß√£o de par√¢metros de antena possui as seguintes propriedades:

- **Totalmente Observ√°vel:** Podemos calcular o desempenho exato para qualquer conjunto de par√¢metros usando o modelo.
- **Determin√≠stico:** A avalia√ß√£o de um conjunto de par√¢metros sempre produz o mesmo resultado.
- **Est√°tico:** O modelo da antena e a fun√ß√£o objetivo n√£o mudam durante a busca.
- **Cont√≠nuo (ou Discreto):** Os par√¢metros (fases, amplitudes) podem ser cont√≠nuos ou discretizados.
- **Agente √önico:** O algoritmo de otimiza√ß√£o √© o √∫nico agente agindo no ambiente.

Compreender estas propriedades ajuda a escolher algoritmos de busca apropriados. A natureza cont√≠nua e potencialmente multimodal (com m√∫ltiplos √≥timos locais) do espa√ßo de par√¢metros torna algoritmos como Estrat√©gias de Evolu√ß√£o e Recozimento Simulado candidatos adequados.

## 3. An√°lise e Implementa√ß√£o de Algoritmos de Busca Selecionados

Nesta se√ß√£o, detalharemos quatro algoritmos de busca que representam diferentes estrat√©gias e s√£o aplic√°veis a diversos tipos de problemas, evitando aqueles j√° explorados em sala de aula: Busca com Aprofundamento Iterativo (IDDFS), Busca Recursiva Best-First (RBFS), Recozimento Simulado (Simulated Annealing) e Estrat√©gias de Evolu√ß√£o (ES).

### 3.1 Busca Cega: Busca com Aprofundamento Iterativo (IDDFS)

A Busca com Aprofundamento Iterativo (Iterative Deepening Depth-First Search - IDDFS), conforme descrita por Russell e Norvig (2013), representa uma engenhosa combina√ß√£o das vantagens da Busca em Largura (BFS) e da Busca em Profundidade (DFS). Enquanto a BFS garante encontrar a solu√ß√£o mais rasa (√≥tima em termos de n√∫mero de passos para custos uniformes) e √© completa, ela sofre com altos requisitos de mem√≥ria, que podem crescer exponencialmente com a profundidade. Por outro lado, a DFS possui requisitos de mem√≥ria modestos (lineares em rela√ß√£o √† profundidade m√°xima), mas n√£o √© completa em espa√ßos de estados infinitos ou com ciclos, e n√£o garante otimalidade.

A IDDFS supera essas limita√ß√µes realizando repetidas buscas em profundidade, mas com um limite de profundidade crescente. Ela come√ßa com uma busca em profundidade limitada √† profundidade 0 (apenas o n√≥ inicial). Se a solu√ß√£o n√£o for encontrada, ela descarta os n√≥s gerados e inicia uma nova busca em profundidade, desta vez com limite 1. Esse processo continua, incrementando o limite de profundidade (2, 3, 4, ...) a cada itera√ß√£o, at√© que uma solu√ß√£o seja encontrada no limite de profundidade atual `d`. Como ela explora todos os n√≥s at√© a profundidade `d-1` antes de explorar qualquer n√≥ na profundidade `d`, ela efetivamente simula a ordem de expans√£o da BFS, garantindo que a primeira solu√ß√£o encontrada seja a mais rasa (e, portanto, √≥tima se os custos dos passos forem uniformes).

A principal preocupa√ß√£o com a IDDFS √© a aparente redund√¢ncia, j√° que os n√≥s nos n√≠veis superiores da √°rvore de busca s√£o gerados m√∫ltiplas vezes em diferentes itera√ß√µes. No entanto, Russell e Norvig (2013) demonstram que, para √°rvores de busca onde a maioria dos n√≥s est√° no n√≠vel mais baixo (o que √© comum em muitos problemas, especialmente com fatores de ramifica√ß√£o maiores que 1), o custo adicional de regenerar os n√≥s superiores √© relativamente pequeno em compara√ß√£o com o custo de explorar o √∫ltimo n√≠vel. A complexidade de tempo da IDDFS acaba sendo da mesma ordem de magnitude que a da BFS (O(b^d)), enquanto sua complexidade de espa√ßo √© a mesma da DFS (O(bd)), onde `b` √© o fator de ramifica√ß√£o e `d` √© a profundidade da solu√ß√£o mais rasa. Essa combina√ß√£o de completude, otimalidade (para custos uniformes) e efici√™ncia de mem√≥ria torna a IDDFS a estrat√©gia de busca cega preferida em muitas situa√ß√µes onde o espa√ßo de estados √© grande e a profundidade da solu√ß√£o √© desconhecida.

#### 3.1.1 Implementa√ß√£o de IDDFS

```python
# Representa√ß√£o de um grafo simples como dicion√°rio
grafo_exemplo_iddfs = {
    'A': ['B', 'C', 'D'],
    'B': ['E'],
    'C': ['F', 'G'], # Adicionado n√≥ G para profundidade 2
    'D': ['H'],
    'E': [],
    'F': [],
    'G': [], # Objetivo alternativo
    'H': []
}

def dfs_limitado(grafo, no_atual, objetivo, limite, caminho_atual):
    """
    Busca em profundidade limitada recursiva (DLS).
    
    Args:
        grafo: Dicion√°rio representando o grafo.
        no_atual: N√≥ atual na busca.
        objetivo: N√≥ que queremos encontrar.
        limite: Profundidade m√°xima permitida a partir do n√≥ atual.
        caminho_atual: Lista representando o caminho percorrido at√© o n√≥ atual.
        
    Returns:
        Lista representando o caminho at√© o objetivo se encontrado dentro do limite,
        None caso contr√°rio.
    """
    print(f"Visitando {no_atual} (limite={limite}), Caminho: {caminho_atual}")
    
    if no_atual == objetivo:
        return caminho_atual
        
    if limite == 0:
        return None # Limite de profundidade atingido

    # Explora vizinhos recursivamente
    for vizinho in grafo.get(no_atual, []):
        # Evita ciclos simples verificando se o vizinho j√° est√° no caminho
        if vizinho not in caminho_atual: 
            resultado = dfs_limitado(grafo, vizinho, objetivo, limite - 1, caminho_atual + [vizinho])
            if resultado is not None:
                return resultado # Objetivo encontrado em um ramo descendente
                
    return None # Objetivo n√£o encontrado neste ramo dentro do limite

def iddfs(grafo, inicio, objetivo, limite_maximo):
    """
    Busca com Aprofundamento Iterativo (IDDFS).
    
    Args:
        grafo: Dicion√°rio com os n√≥s e vizinhos.
        inicio: N√≥ inicial da busca.
        objetivo: N√≥ que queremos encontrar.
        limite_maximo: Profundidade m√°xima de busca total.
        
    Returns:
        Lista representando o caminho do in√≠cio ao objetivo, ou None se n√£o encontrado.
    """
    print(f"\nüöÄ Iniciando IDDFS de {inicio} para {objetivo} (limite m√°x: {limite_maximo})")
    for profundidade in range(limite_maximo + 1):
        print(f"\nüîÅ Tentando profundidade: {profundidade}")
        caminho_encontrado = dfs_limitado(grafo, inicio, objetivo, profundidade, [inicio])
        if caminho_encontrado is not None:
            print(f"\n‚úÖ Objetivo '{objetivo}' encontrado na profundidade {profundidade}.")
            print(f"üèÅ Caminho: {caminho_encontrado}")
            return caminho_encontrado
            
    print(f"\n‚ùå Objetivo '{objetivo}' n√£o encontrado at√© a profundidade {limite_maximo}.")
    return None

# Executa o algoritmo procurando o n√≥ 'G' a partir do n√≥ 'A' com profundidade m√°xima 3
if __name__ == "__main__":
    caminho_final = iddfs(grafo_exemplo_iddfs, 'A', 'G', 3)
    if caminho_final:
        print(f"\nCaminho final retornado: {' -> '.join(caminho_final)}")
    else:
        print("\nNenhum caminho encontrado.")
```

**Explica√ß√£o do C√≥digo IDDFS:**

1.  **`dfs_limitado(grafo, no_atual, objetivo, limite, caminho_atual)`**: Esta fun√ß√£o implementa a Busca em Profundidade Limitada (DLS). Ela explora recursivamente a partir do `no_atual` at√© a `limite` de profundidade. O `caminho_atual` √© passado para rastrear o percurso e evitar ciclos simples. Retorna o caminho se o objetivo for encontrado dentro do limite, sen√£o retorna `None`.
2.  **`iddfs(grafo, inicio, objetivo, limite_maximo)`**: Esta √© a fun√ß√£o principal da IDDFS. Ela itera sobre os limites de profundidade, de 0 at√© `limite_maximo`. Em cada itera√ß√£o, chama `dfs_limitado` com o limite de profundidade atual. Se `dfs_limitado` encontrar o objetivo (retornar um caminho), a IDDFS retorna esse caminho imediatamente. Se o loop terminar sem encontrar o objetivo, significa que ele n√£o existe dentro do `limite_maximo`.
3.  **Exemplo de Uso**: O c√≥digo demonstra a busca pelo n√≥ 'G' a partir de 'A' no `grafo_exemplo_iddfs`. A IDDFS tentar√° profundidades 0, 1 e 2. Na profundidade 2, a chamada `dfs_limitado` encontrar√° o caminho A -> C -> G e o retornar√°.

### 3.2 Busca Informada: Busca Recursiva Best-First (RBFS)

A Busca A* √© renomada por sua otimalidade e completude quando usada com heur√≠sticas admiss√≠veis, mas sua principal desvantagem reside na potencial necessidade exponencial de mem√≥ria para armazenar a fronteira (n√≥s abertos). Para contornar essa limita√ß√£o, Russell e Norvig (2013) apresentam a Busca Recursiva Best-First (Recursive Best-First Search - RBFS), um algoritmo que visa mimetizar a opera√ß√£o da A* utilizando apenas espa√ßo linear, similar √† busca em profundidade.

A RBFS opera de forma recursiva. Ela mant√©m o controle do valor `f` (custo `g` + heur√≠stica `h`) do melhor caminho alternativo dispon√≠vel a partir do ancestral do n√≥ atual (um limite superior, `f_limit`). A fun√ß√£o recursiva explora um caminho enquanto o valor `f` dos n√≥s nesse caminho n√£o excede esse limite. Se um n√≥ folha √© alcan√ßado e representa uma solu√ß√£o, a busca termina com sucesso. Se todos os caminhos a partir de um n√≥ excedem o `f_limit`, a recurs√£o retrocede (backtracks) para o n√≥ ancestral. Crucialmente, ao retroceder, a RBFS atualiza o valor `f` do n√≥ que acabou de explorar para refletir o melhor valor `f` encontrado em seus descendentes (incluindo aqueles que excederam o limite). Esse valor atualizado pode ent√£o guiar a busca futura, potencialmente fazendo com que a RBFS decida explorar um caminho diferente que antes parecia menos promissor, mas cujo valor `f` agora √© o melhor abaixo do limite.

A principal vantagem da RBFS √© sua efici√™ncia de espa√ßo, que √© linear em rela√ß√£o √† profundidade da solu√ß√£o mais rasa (`O(bd)`). Ela tamb√©m √© √≥tima e completa, assim como A*, *se* conseguir encontrar a solu√ß√£o (o que depende de ter mem√≥ria suficiente para o caminho em si e a pilha de recurs√£o). No entanto, sua maior desvantagem √© a potencial re-gera√ß√£o excessiva de n√≥s. Como ela descarta sub√°rvores ao retroceder para economizar mem√≥ria, pode ser que precise re-explorar a mesma sub√°rvore m√∫ltiplas vezes se os limites `f` mudarem favoravelmente para ela novamente. Esse comportamento pode tornar a RBFS significativamente mais lenta que a A* em termos de tempo, especialmente se os valores `f` dos n√≥s forem muito pr√≥ximos entre si, levando a muitas mudan√ßas de foco entre diferentes caminhos. Apesar disso, a RBFS √© uma alternativa valiosa quando a mem√≥ria √© o principal gargalo para a aplica√ß√£o da A*.

#### 3.2.1 Implementa√ß√£o de RBFS

```python
import math
import heapq # Usado apenas para ordenar sucessores, n√£o como fila principal

# Representa√ß√£o do grafo com custos reais (g) e heur√≠sticas (h)
# Grafo similar ao exemplo A*, mas com n√≥s diferentes para evitar repeti√ß√£o
grafo_exemplo_rbfs = {
    'S': [('A', 2), ('B', 3)],
    'A': [('C', 4), ('D', 1)],
    'B': [('E', 5), ('F', 2)],
    'C': [('G', 3)],
    'D': [('G', 6)],
    'E': [],
    'F': [('G', 1)],
    'G': [] # Objetivo
}

# Heur√≠stica h(n) estimando a dist√¢ncia de n at√© o objetivo G
heuristica_rbfs = {
    'S': 10,
    'A': 7,
    'B': 8,
    'C': 3,
    'D': 6,
    'E': 100, # N√≥ sem sa√≠da, heur√≠stica alta
    'F': 1,
    'G': 0  # Objetivo
}

# Classe auxiliar para armazenar informa√ß√µes do n√≥ na RBFS
class NoRBFS:
    def __init__(self, estado, pai=None, custo_g=0, heuristica_h=0):
        self.estado = estado
        self.pai = pai
        self.custo_g = custo_g # Custo real do in√≠cio at√© este n√≥
        self.heuristica_h = heuristica_h # Heur√≠stica estimada deste n√≥ at√© o objetivo
        self.valor_f = custo_g + heuristica_h # Valor f = g + h

    # Usado para ordena√ß√£o (heapq ou sort)
    def __lt__(self, other):
        return self.valor_f < other.valor_f

def rbfs_recursive(no, objetivo, f_limit):
    """
    Fun√ß√£o recursiva principal da RBFS.
    
    Args:
        no: Objeto NoRBFS representando o n√≥ atual.
        objetivo: Estado objetivo.
        f_limit: Limite superior do valor f permitido para explora√ß√£o.
        
    Returns:
        Tupla (resultado, novo_f_limit):
        - resultado: N√≥ objetivo se encontrado, None caso contr√°rio.
        - novo_f_limit: O menor valor f dos caminhos alternativos (ou infinito).
    """
    print(f"üîç Explorando {no.estado} (g={no.custo_g}, h={no.heuristica_h}, f={no.valor_f}) com f_limit={f_limit}")

    if no.estado == objetivo:
        print(f"‚úÖ Objetivo {objetivo} alcan√ßado!")
        return no, no.valor_f # Retorna o n√≥ solu√ß√£o e seu valor f

    # Gera sucessores
    sucessores = []
    for vizinho_estado, custo_acao in grafo_exemplo_rbfs.get(no.estado, []):
        custo_g_vizinho = no.custo_g + custo_acao
        heuristica_h_vizinho = heuristica_rbfs.get(vizinho_estado, math.inf)
        sucessor = NoRBFS(vizinho_estado, no, custo_g_vizinho, heuristica_h_vizinho)
        sucessores.append(sucessor)

    if not sucessores:
        print(f"  -> N√≥ {no.estado} sem sucessores.")
        return None, math.inf # Sem sucessores = caminho morto

    # Atualiza o valor f dos sucessores com base no pai (necess√°rio se f foi atualizado no backtrack)
    for s in sucessores:
        s.valor_f = max(s.valor_f, no.valor_f) # f(n) n√£o pode ser menor que f(pai)
        
    while True:
        # Ordena sucessores pelo menor valor f
        sucessores.sort()
        
        melhor = sucessores[0]
        print(f"  -> Melhor sucessor: {melhor.estado} com f={melhor.valor_f}")

        # Se o melhor caminho excede o limite, retorna falha e o f do melhor caminho
        if melhor.valor_f > f_limit:
            print(f"  -> Melhor f ({melhor.valor_f}) excede f_limit ({f_limit}). Retornando...")
            return None, melhor.valor_f

        # Determina o limite para a chamada recursiva:
        # √â o menor entre o f_limit atual e o valor f do segundo melhor sucessor (se existir)
        alternativa_f = sucessores[1].valor_f if len(sucessores) > 1 else math.inf
        novo_f_limit_recursao = min(f_limit, alternativa_f)
        print(f"  -> Chamando recurs√£o para {melhor.estado} com novo f_limit={novo_f_limit_recursao}")

        # Chamada recursiva
        resultado, f_retornado = rbfs_recursive(melhor, objetivo, novo_f_limit_recursao)
        
        # Atualiza o valor f do melhor n√≥ com o valor retornado pela recurs√£o
        # Isso propaga o limite inferior de custo da sub√°rvore explorada
        melhor.valor_f = f_retornado
        print(f"  -> Retornou da recurs√£o de {melhor.estado}. Novo f={melhor.valor_f}")

        # Se a recurs√£o encontrou a solu√ß√£o, retorna
        if resultado is not None:
            return resultado, f_retornado
        
        # Se n√£o encontrou, o loop continua, reordenando os sucessores com o f atualizado
        # e tentando o pr√≥ximo melhor (que agora pode ser o que acabou de retornar).

def iniciar_rbfs(inicio, objetivo):
    """
    Inicia a busca RBFS.
    """
    print(f"\nüöÄ Iniciando RBFS de {inicio} at√© {objetivo}")
    no_inicial = NoRBFS(inicio, custo_g=0, heuristica_h=heuristica_rbfs.get(inicio, math.inf))
    no_solucao, _ = rbfs_recursive(no_inicial, objetivo, math.inf)
    
    if no_solucao:
        print("\nüèÅ Caminho encontrado com sucesso!")
        # Reconstr√≥i o caminho
        caminho = []
        atual = no_solucao
        while atual:
            caminho.append(atual.estado)
            atual = atual.pai
        caminho.reverse()
        print(f"Caminho: {' -> '.join(caminho)}")
        print(f"Custo total (g): {no_solucao.custo_g}")
        return caminho
    else:
        print("\n‚ùå Caminho n√£o encontrado.")
        return None

# Executa o algoritmo
if __name__ == "__main__":
    caminho_rbfs = iniciar_rbfs('S', 'G')
```

**Explica√ß√£o do C√≥digo RBFS:**

1.  **`NoRBFS`**: Classe auxiliar para representar um n√≥ na busca, armazenando estado, pai, custo `g`, heur√≠stica `h` e valor `f`.
2.  **`rbfs_recursive(no, objetivo, f_limit)`**: Fun√ß√£o recursiva principal.
    *   Verifica se o n√≥ atual √© o objetivo.
    *   Gera os sucessores e calcula seus valores `f`.
    *   Atualiza o `f` dos sucessores para garantir que n√£o sejam menores que o `f` do pai (monotonicidade).
    *   Entra em um loop:
        *   Ordena os sucessores por valor `f`.
        *   Pega o melhor sucessor.
        *   Se o `f` do melhor exceder o `f_limit`, retorna falha e o `f` do melhor (ser√° o novo limite para o n√≠vel acima).
        *   Determina o limite para a chamada recursiva (`novo_f_limit_recursao`) como o m√≠nimo entre o `f_limit` atual e o `f` do segundo melhor sucessor.
        *   Chama `rbfs_recursive` para o melhor sucessor com o novo limite.
        *   Atualiza o `f` do melhor sucessor com o valor `f` retornado pela recurs√£o (importante para propagar informa√ß√£o de custo).
        *   Se a recurs√£o encontrou a solu√ß√£o, retorna sucesso.
        *   Caso contr√°rio, o loop continua, reordenando os sucessores com o `f` atualizado.
3.  **`iniciar_rbfs(inicio, objetivo)`**: Prepara o n√≥ inicial e chama a fun√ß√£o recursiva com `f_limit` inicial infinito. Se encontrar a solu√ß√£o, reconstr√≥i e imprime o caminho.
4.  **Exemplo de Uso**: Demonstra a busca de 'S' para 'G' usando o `grafo_exemplo_rbfs` e a `heuristica_rbfs`. A sa√≠da detalhada mostra como o algoritmo explora e retrocede, atualizando os limites `f`.

### 3.3 Busca Local: Recozimento Simulado (Simulated Annealing)

Enquanto a Subida de Encosta (Hill Climbing) √© uma t√©cnica de busca local direta que sempre busca melhorias imediatas, ela frequentemente falha ao ficar presa em √≥timos locais. O Recozimento Simulado (Simulated Annealing), apresentado por Russell e Norvig (2013) como uma melhoria sobre a subida de encosta, oferece uma solu√ß√£o probabil√≠stica para este problema. Inspirado no processo f√≠sico de recozimento (annealing) em metalurgia, onde um material √© aquecido e depois resfriado lentamente para aumentar o tamanho de seus cristais e reduzir seus defeitos, o algoritmo permite movimentos ocasionais para estados piores, diminuindo a probabilidade desses movimentos ao longo do tempo.

O algoritmo come√ßa em um estado inicial aleat√≥rio e, a cada itera√ß√£o, considera um movimento para um vizinho aleat√≥rio. Se o vizinho for melhor (maior valor na fun√ß√£o objetivo para maximiza√ß√£o, ou menor para minimiza√ß√£o), o movimento √© sempre aceito. Se o vizinho for pior, ele ainda pode ser aceito com uma certa probabilidade, que depende de dois fatores: qu√£o pior √© o vizinho (a diferen√ßa de valor, `ŒîE`) e um par√¢metro chamado "temperatura" (`T`). A probabilidade de aceitar um movimento pior √© tipicamente dada por `exp(ŒîE / T)` (para maximiza√ß√£o, onde `ŒîE` seria negativo e menor; para minimiza√ß√£o, seria `exp(-ŒîE / T)` com `ŒîE` positivo). No in√≠cio, a temperatura `T` √© alta, permitindo que muitos movimentos ruins sejam aceitos, o que possibilita ao algoritmo explorar amplamente o espa√ßo de busca e escapar de √≥timos locais iniciais. Gradualmente, a temperatura √© reduzida de acordo com um "cronograma de resfriamento" (cooling schedule). √Ä medida que `T` diminui, a probabilidade de aceitar movimentos ruins tamb√©m diminui, fazendo com que o algoritmo se concentre cada vez mais em melhorias locais, convergindo eventualmente para um estado de baixa energia (alta qualidade).

A grande vantagem do Recozimento Simulado √© sua capacidade de encontrar √≥timos globais (ou solu√ß√µes muito pr√≥ximas a eles) com maior probabilidade do que a Subida de Encosta, justamente por permitir escapar de √≥timos locais. No entanto, seu desempenho √© muito sens√≠vel √† escolha do cronograma de resfriamento (como a temperatura inicial, a taxa de decaimento e o crit√©rio de parada). Um resfriamento muito r√°pido pode fazer com que ele se comporte como a Subida de Encosta e fique preso; um resfriamento muito lento pode torn√°-lo computacionalmente caro.

#### 3.3.1 Implementa√ß√£o de Recozimento Simulado

```python
import random
import math
import matplotlib.pyplot as plt
import numpy as np

def recozimento_simulado(funcao_objetivo, estado_inicial, gerar_vizinho, 
                         temperatura_inicial=100.0, taxa_resfriamento=0.97, 
                         temperatura_minima=0.01, max_iter_por_temp=50):
    """
    Implementa√ß√£o do algoritmo de Recozimento Simulado para maximiza√ß√£o.
    
    Args:
        funcao_objetivo: Fun√ß√£o que avalia a qualidade de um estado (retorna valor a maximizar).
        estado_inicial: Estado a partir do qual iniciar a busca.
        gerar_vizinho: Fun√ß√£o que gera um estado vizinho aleat√≥rio a partir de um estado dado.
        temperatura_inicial: Temperatura inicial.
        taxa_resfriamento: Fator multiplicativo para diminuir a temperatura (e.g., 0.95).
        temperatura_minima: Temperatura de parada.
        max_iter_por_temp: N√∫mero de vizinhos a testar em cada n√≠vel de temperatura.
    
    Returns:
        Tupla (melhor_estado_global, melhor_valor_global, historico)
        historico: Lista de tuplas (iteracao, estado_atual, valor_atual, temperatura)
    """
    estado_atual = estado_inicial
    valor_atual = funcao_objetivo(estado_atual)
    
    melhor_estado_global = estado_atual
    melhor_valor_global = valor_atual
    
    temperatura = temperatura_inicial
    
    historico = [(0, estado_atual, valor_atual, temperatura)]
    iteracao_total = 0
    
    print(f"üöÄ Iniciando Recozimento Simulado a partir de {estado_atual} (Valor={valor_atual:.4f})")
    print(f"   T inicial: {temperatura_inicial:.2f}, Taxa resfri.: {taxa_resfriamento}, T min: {temperatura_minima:.4f}")

    while temperatura > temperatura_minima:
        print(f"\n-- Temperatura atual: {temperatura:.4f} --")
        for i in range(max_iter_por_temp):
            iteracao_total += 1
            # Gera um vizinho aleat√≥rio
            vizinho = gerar_vizinho(estado_atual)
            valor_vizinho = funcao_objetivo(vizinho)
            
            # Calcula a diferen√ßa de energia (para maximiza√ß√£o, delta > 0 √© melhor)
            delta_e = valor_vizinho - valor_atual
            
            # Decide se aceita o novo estado
            aceita = False
            razao = ""
            if delta_e > 0:  # Movimento para um estado melhor √© sempre aceito
                aceita = True
                razao = "melhor"
            else:  # Movimento para um estado pior pode ser aceito
                # Evita divis√£o por zero e math domain error
                if temperatura > 1e-9: 
                    probabilidade = math.exp(delta_e / temperatura)
                    if random.random() < probabilidade:
                        aceita = True
                        razao = f"pior (prob={probabilidade:.4f})"
                    else:
                        razao = f"pior (rejeitado, prob={probabilidade:.4f})"
                else:
                     razao = "pior (rejeitado, T muito baixa)"
            
            print(f"  Iter {iteracao_total} (sub {i+1}): Vizinho={vizinho}, V={valor_vizinho:.4f}, DeltaE={delta_e:.4f} -> Aceito: {aceita} ({razao})")

            if aceita:
                estado_atual = vizinho
                valor_atual = valor_vizinho
                
                # Atualiza o melhor estado global se necess√°rio
                if valor_atual > melhor_valor_global:
                    melhor_estado_global = estado_atual
                    melhor_valor_global = valor_atual
                    print(f"    ‚ú® Novo melhor global encontrado! Valor: {melhor_valor_global:.4f}")
            
            # Registra o estado atual (aceito ou n√£o) para o hist√≥rico
            historico.append((iteracao_total, estado_atual, valor_atual, temperatura))
            
        # Resfria a temperatura
        temperatura *= taxa_resfriamento
        
    print(f"\nüèÅ Recozimento conclu√≠do ap√≥s {iteracao_total} itera√ß√µes")
    print(f"   Temperatura final: {temperatura:.4f}")
    print(f"   Melhor estado global encontrado: {melhor_estado_global}")
    print(f"   Melhor valor global: {melhor_valor_global:.4f}")
    
    return melhor_estado_global, melhor_valor_global, historico

# Exemplo: Otimizar a fun√ß√£o Rastrigin (minimiza√ß√£o, convertida para maximiza√ß√£o)
# Fun√ß√£o complexa com muitos m√≠nimos locais. M√≠nimo global em (0,0) com valor 0.
# Maximizaremos -Rastrigin(x,y), com m√°ximo global em (0,0) com valor 0.
def rastrigin(ponto):
    x, y = ponto
    A = 10
    return A * 2 + (x**2 - A * np.cos(2 * np.pi * x)) + (y**2 - A * np.cos(2 * np.pi * y))

def funcao_objetivo_rastrigin(ponto):
    # Negativo para transformar minimiza√ß√£o em maximiza√ß√£o
    return -rastrigin(ponto)

def gerar_vizinho_rastrigin(ponto, passo_max=0.5):
    x, y = ponto
    # Gera um vizinho adicionando um pequeno vetor aleat√≥rio
    novo_x = x + random.uniform(-passo_max, passo_max)
    novo_y = y + random.uniform(-passo_max, passo_max)
    # Mant√©m dentro dos limites [-5.12, 5.12]
    novo_x = max(-5.12, min(5.12, novo_x))
    novo_y = max(-5.12, min(5.12, novo_y))
    return (novo_x, novo_y)

# Executa o algoritmo
if __name__ == "__main__":
    # Estado inicial aleat√≥rio dentro dos limites
    estado_inicial_rastrigin = (random.uniform(-5.12, 5.12), random.uniform(-5.12, 5.12))
    
    # Executa o recozimento simulado
    melhor_estado, melhor_valor, historico_sa = recozimento_simulado(
        funcao_objetivo_rastrigin, 
        estado_inicial_rastrigin, 
        gerar_vizinho_rastrigin,
        temperatura_inicial=50.0, 
        taxa_resfriamento=0.98, 
        temperatura_minima=0.001,
        max_iter_por_temp=100
    )
    
    # Visualiza o progresso
    iteracoes = [h[0] for h in historico_sa]
    valores = [h[2] for h in historico_sa]
    temperaturas = [h[3] for h in historico_sa]
    
    plt.figure(figsize=(12, 8))
    
    # Evolu√ß√£o do Valor da Fun√ß√£o Objetivo
    ax1 = plt.subplot(2, 1, 1)
    ax1.plot(iteracoes, valores, 'r-', linewidth=1, alpha=0.8)
    ax1.set_xlabel('Itera√ß√£o Total')
    ax1.set_ylabel('Valor da Fun√ß√£o Objetivo (-Rastrigin)')
    ax1.set_title('Evolu√ß√£o do Valor da Fun√ß√£o no Recozimento Simulado')
    ax1.grid(True)
    
    # Evolu√ß√£o da Temperatura
    ax2 = plt.subplot(2, 1, 2)
    ax2.plot(iteracoes, temperaturas, 'g-', linewidth=1)
    ax2.set_xlabel('Itera√ß√£o Total')
    ax2.set_ylabel('Temperatura')
    ax2.set_title('Cronograma de Resfriamento')
    ax2.set_yscale('log') # Escala log para melhor visualiza√ß√£o
    ax2.grid(True)
    
    plt.tight_layout()
    plt.savefig('simulated_annealing_rastrigin_progress.png')
    plt.close()
    
    print(f"\nVisualiza√ß√£o do progresso salva como 'simulated_annealing_rastrigin_progress.png'")
    
    # Visualiza√ß√£o da fun√ß√£o Rastrigin e ponto final (Opcional, requer mais c√≥digo)
    # ... (c√≥digo para plot 2D/3D da fun√ß√£o Rastrigin e o ponto encontrado) ...
```

**Explica√ß√£o do C√≥digo de Recozimento Simulado:**

1.  **`recozimento_simulado(...)`**: Fun√ß√£o principal que implementa o algoritmo.
    *   Inicializa o estado atual, valor atual, melhor estado global e temperatura.
    *   Entra no loop principal que continua enquanto a temperatura for maior que a m√≠nima.
    *   Dentro do loop de temperatura, h√° um loop interno que testa `max_iter_por_temp` vizinhos.
    *   Para cada vizinho, calcula a diferen√ßa de valor (`delta_e`).
    *   Se o vizinho for melhor (`delta_e > 0`), ele √© aceito.
    *   Se for pior, calcula a probabilidade `exp(delta_e / temperatura)` e aceita o vizinho com essa probabilidade.
    *   Se um vizinho √© aceito, o estado atual √© atualizado. O melhor estado global tamb√©m √© atualizado se necess√°rio.
    *   O hist√≥rico de itera√ß√£o, estado, valor e temperatura √© registrado.
    *   Ap√≥s o loop interno, a temperatura √© reduzida (`temperatura *= taxa_resfriamento`).
2.  **Exemplo de Uso (Fun√ß√£o Rastrigin)**: O algoritmo √© aplicado para encontrar o m√°ximo da fun√ß√£o `-Rastrigin(x, y)`. A fun√ß√£o Rastrigin original tem um m√≠nimo global em (0,0) e muitos m√≠nimos locais, tornando-a um bom teste para algoritmos de otimiza√ß√£o global. Usamos `-Rastrigin` para transformar o problema em maximiza√ß√£o.
3.  **`gerar_vizinho_rastrigin`**: Gera um ponto vizinho adicionando um pequeno deslocamento aleat√≥rio e garantindo que permane√ßa dentro dos limites do dom√≠nio da fun√ß√£o.
4.  **Visualiza√ß√£o**: O c√≥digo gera gr√°ficos mostrando a evolu√ß√£o do valor da fun√ß√£o objetivo e a diminui√ß√£o da temperatura ao longo das itera√ß√µes, salvando em `simulated_annealing_rastrigin_progress.png`.

### 3.4 Algoritmos Evolucion√°rios: Estrat√©gias de Evolu√ß√£o (ES)

Os Algoritmos Gen√©ticos (AGs) cl√°ssicos, como discutido por Russell e Norvig (2013), operam tipicamente em representa√ß√µes bin√°rias ou discretas e utilizam operadores como cruzamento e muta√ß√£o bit-a-bit. As Estrat√©gias de Evolu√ß√£o (Evolution Strategies - ES), por outro lado, s√£o uma classe de algoritmos evolucion√°rios particularmente adequados para a otimiza√ß√£o de problemas em espa√ßos de par√¢metros cont√≠nuos. Desenvolvidas independentemente dos AGs na Alemanha nos anos 1960 e 1970 por Ingo Rechenberg e Hans-Paul Schwefel, as ES trabalham diretamente com vetores de n√∫meros reais.

A caracter√≠stica central das ES √© o uso da muta√ß√£o como principal motor de busca, frequentemente modelada por distribui√ß√µes de probabilidade como a Gaussiana (Normal). Al√©m dos par√¢metros do problema (vari√°veis de objeto), as ES modernas frequentemente co-evoluem par√¢metros da pr√≥pria estrat√©gia, como as vari√¢ncias (ou desvios padr√£o) e, √†s vezes, as covari√¢ncias da distribui√ß√£o de muta√ß√£o. Isso permite que o algoritmo adapte a intensidade e a dire√ß√£o da busca ao longo do processo de otimiza√ß√£o, um conceito conhecido como auto-adapta√ß√£o.

Existem v√°rias nota√ß√µes para descrever diferentes ES, como `(Œº/œÅ, Œª)-ES` ou `(Œº/œÅ + Œª)-ES`:

*   `Œº`: N√∫mero de pais selecionados para gerar descendentes.
*   `Œª`: N√∫mero de descendentes gerados em cada gera√ß√£o.
*   `œÅ`: (Opcional) N√∫mero de pais usados para recombinar e gerar um descendente (geralmente 1 ou 2).
*   `,`: Indica sele√ß√£o n√£o-elitista (apenas os descendentes formam a pr√≥xima gera√ß√£o de pais).
*   `+`: Indica sele√ß√£o elitista (pais e descendentes competem juntos para formar a pr√≥xima gera√ß√£o de pais).

A forma mais simples √© a `(1+1)-ES`, onde um pai gera um descendente por muta√ß√£o, e o melhor dos dois (pai ou filho) sobrevive para a pr√≥xima gera√ß√£o. Formas mais complexas como `(Œº, Œª)-ES` ou `(Œº + Œª)-ES` usam popula√ß√µes maiores e podem incluir recombina√ß√£o (geralmente m√©dia aritm√©tica ou intermedi√°ria) entre os pais selecionados antes da muta√ß√£o para gerar descendentes.

#### 3.4.1 Implementa√ß√£o de uma Estrat√©gia de Evolu√ß√£o Simples (1+1)-ES

Vamos implementar uma (1+1)-ES b√°sica com adapta√ß√£o de passo (tamanho da muta√ß√£o) para minimizar a fun√ß√£o Esfera em 2D.

```python
import random
import math
import numpy as np
import matplotlib.pyplot as plt

def estrategia_evolucao_1_mais_1(funcao_objetivo, dimensoes, limites, 
                                 sigma_inicial=1.0, taxa_aprendizado=None, 
                                 max_geracoes=1000, tol=1e-6):
    """
    Implementa√ß√£o de uma Estrat√©gia de Evolu√ß√£o (1+1)-ES simples com 
    adapta√ß√£o de passo da regra 1/5 para minimiza√ß√£o.
    
    Args:
        funcao_objetivo: Fun√ß√£o a ser minimizada (recebe lista/array, retorna float).
        dimensoes: N√∫mero de dimens√µes do vetor de par√¢metros.
        limites: Tupla (min_val, max_val) para os par√¢metros.
        sigma_inicial: Desvio padr√£o inicial para a muta√ß√£o Gaussiana.
        taxa_aprendizado: Fator para ajustar sigma (default: 1 / sqrt(dimensoes)).
        max_geracoes: N√∫mero m√°ximo de gera√ß√µes.
        tol: Toler√¢ncia para crit√©rio de parada (mudan√ßa no valor).
    
    Returns:
        Tupla (melhor_individuo, melhor_fitness, historico)
        historico: Lista de tuplas (geracao, fitness_atual, sigma_atual)
    """
    min_val, max_val = limites
    if taxa_aprendizado is None:
        taxa_aprendizado = 1.0 / math.sqrt(dimensoes)
        
    # Indiv√≠duo pai inicial (aleat√≥rio dentro dos limites)
    pai = np.random.uniform(min_val, max_val, dimensoes)
    fitness_pai = funcao_objetivo(pai)
    
    # Par√¢metro de estrat√©gia (desvio padr√£o da muta√ß√£o)
    sigma = sigma_inicial
    
    melhor_global = pai
    melhor_fitness_global = fitness_pai
    
    historico = [(0, fitness_pai, sigma)]
    sucessos_ultimas_k_geracoes = 0
    k = 10 # Janela para a regra 1/5
    
    print(f"üöÄ Iniciando (1+1)-ES para {dimensoes} dimens√µes")
    print(f"   Pai inicial: {pai}, Fitness: {fitness_pai:.4f}, Sigma: {sigma:.4f}")
    print(f"   Taxa aprendizado (1/5 regra): {taxa_aprendizado:.4f}")

    for geracao in range(1, max_geracoes + 1):
        # Gera filho por muta√ß√£o Gaussiana
        mutacao_vetor = np.random.normal(0, sigma, dimensoes)
        filho = pai + mutacao_vetor
        
        # Garante que o filho permane√ßa dentro dos limites
        filho = np.clip(filho, min_val, max_val)
        
        fitness_filho = funcao_objetivo(filho)
        
        # Sele√ß√£o (1+1): O melhor entre pai e filho sobrevive
        sucesso = False
        if fitness_filho < fitness_pai:
            pai = filho
            fitness_pai = fitness_filho
            sucesso = True
            print(f"  Ger {geracao}: Sucesso! Novo pai fitness: {fitness_pai:.4f}, Sigma: {sigma:.4f}")
            # Atualiza melhor global
            if fitness_pai < melhor_fitness_global:
                 melhor_global = pai
                 melhor_fitness_global = fitness_pai
                 print(f"    ‚ú® Novo melhor global encontrado! Fitness: {melhor_fitness_global:.4f}")
        else:
            print(f"  Ger {geracao}: Falha. Fitness filho: {fitness_filho:.4f} >= Pai: {fitness_pai:.4f}. Sigma: {sigma:.4f}")
            
        # Adapta√ß√£o de Sigma (Regra 1/5 de Rechenberg)
        # A cada k gera√ß√µes, verifica a taxa de sucesso.
        if geracao % k == 0:
            taxa_sucesso = sucessos_ultimas_k_geracoes / k
            fator_ajuste = math.exp(taxa_aprendizado * (taxa_sucesso - 1/5) / (1 - 1/5))
            sigma *= fator_ajuste
            print(f"    Adapta√ß√£o Sigma (Regra 1/5): Taxa sucesso={taxa_sucesso:.2f} -> Novo sigma={sigma:.4f}")
            sucessos_ultimas_k_geracoes = 0 # Reseta contador
        elif sucesso:
            sucessos_ultimas_k_geracoes += 1
            
        # Garante que sigma n√£o fique muito pequeno
        sigma = max(sigma, 1e-8)
        
        historico.append((geracao, fitness_pai, sigma))
        
        # Crit√©rio de parada por toler√¢ncia (opcional)
        if geracao > 1 and abs(historico[-1][1] - historico[-2][1]) < tol:
             print(f"\nConverg√™ncia atingida (toler√¢ncia {tol}). Parando.")
             break
             
    print(f"\nüèÅ (1+1)-ES conclu√≠da ap√≥s {geracao} gera√ß√µes")
    print(f"   Melhor indiv√≠duo: {melhor_global}")
    print(f"   Melhor fitness: {melhor_fitness_global:.6f}")
    print(f"   Sigma final: {sigma:.6f}")
    
    return melhor_global, melhor_fitness_global, historico

# Exemplo: Minimizar a fun√ß√£o Esfera f(x,y) = x^2 + y^2
# M√≠nimo global em (0,0) com valor 0.
def funcao_esfera(ponto):
    return sum(x**2 for x in ponto)

# Executa o algoritmo
if __name__ == "__main__":
    dim = 2
    limites_esfera = (-5.0, 5.0)
    
    melhor_individuo_es, melhor_fitness_es, historico_es = estrategia_evolucao_1_mais_1(
        funcao_esfera, 
        dimensoes=dim,
        limites=limites_esfera,
        sigma_inicial=2.0,
        max_geracoes=200,
        tol=1e-8
    )
    
    # Visualiza o progresso
    geracoes_es = [h[0] for h in historico_es]
    fitness_es = [h[1] for h in historico_es]
    sigmas_es = [h[2] for h in historico_es]
    
    plt.figure(figsize=(12, 8))
    
    # Evolu√ß√£o do Fitness
    ax1 = plt.subplot(2, 1, 1)
    ax1.plot(geracoes_es, fitness_es, 'b-', linewidth=1)
    ax1.set_xlabel('Gera√ß√£o')
    ax1.set_ylabel('Fitness (Fun√ß√£o Esfera)')
    ax1.set_title('Evolu√ß√£o do Fitness na (1+1)-ES')
    ax1.set_yscale('log') # Escala log ajuda a ver a converg√™ncia
    ax1.grid(True)
    
    # Evolu√ß√£o de Sigma
    ax2 = plt.subplot(2, 1, 2)
    ax2.plot(geracoes_es, sigmas_es, 'm-', linewidth=1)
    ax2.set_xlabel('Gera√ß√£o')
    ax2.set_ylabel('Sigma (Desvio Padr√£o da Muta√ß√£o)')
    ax2.set_title('Adapta√ß√£o do Par√¢metro de Estrat√©gia Sigma')
    ax2.set_yscale('log')
    ax2.grid(True)
    
    plt.tight_layout()
    plt.savefig('evolution_strategy_progress.png')
    plt.close()
    
    print(f"\nVisualiza√ß√£o do progresso salva como 'evolution_strategy_progress.png'")
```

**Explica√ß√£o do C√≥digo (1+1)-ES:**

1.  **`estrategia_evolucao_1_mais_1(...)`**: Fun√ß√£o principal da ES.
    *   Inicializa um pai aleat√≥rio e seu fitness.
    *   Inicializa o par√¢metro de estrat√©gia `sigma` (desvio padr√£o da muta√ß√£o).
    *   Entra no loop de gera√ß√µes:
        *   Cria um filho mutando o pai com ru√≠do Gaussiano de desvio padr√£o `sigma`.
        *   Garante que o filho esteja dentro dos limites definidos.
        *   Avalia o fitness do filho.
        *   Sele√ß√£o (1+1): Se o filho for melhor ou igual ao pai (para minimiza√ß√£o), o filho se torna o novo pai.
        *   Adapta√ß√£o de Sigma (Regra 1/5): A cada `k` gera√ß√µes (aqui `k=10`), calcula a taxa de sucesso (propor√ß√£o de muta√ß√µes bem-sucedidas). Se a taxa for maior que 1/5, aumenta `sigma` (explora√ß√£o); se for menor, diminui `sigma` (explota√ß√£o). O fator de ajuste usa `taxa_aprendizado`.
        *   Registra o fitness e sigma no hist√≥rico.
        *   Verifica crit√©rio de parada por toler√¢ncia.
2.  **Exemplo de Uso (Fun√ß√£o Esfera)**: O algoritmo √© usado para minimizar a fun√ß√£o `f(x, y) = x^2 + y^2`, cujo m√≠nimo √© 0 em (0,0). A (1+1)-ES com adapta√ß√£o de passo converge eficientemente para o √≥timo.
3.  **Visualiza√ß√£o**: Gera gr√°ficos mostrando a converg√™ncia do fitness (em escala logar√≠tmica) e a adapta√ß√£o do par√¢metro `sigma` ao longo das gera√ß√µes, salvando em `evolution_strategy_progress.png`.

## 4. Compara√ß√£o de Algoritmos e Aplica√ß√µes Pr√°ticas

### 4.1 Tabela Comparativa dos Algoritmos Implementados

**Tabela 1: Compara√ß√£o dos Algoritmos de Busca Implementados**

| Algoritmo | Tipo | Completude | Otimalidade | Complexidade de Espa√ßo | Aplica√ß√µes T√≠picas |
|-----------|------|------------|-------------|------------------------|-------------------|
| IDDFS | Cega | Sim | Sim (custos unif.) | O(bd) | Problemas com profundidade desconhecida, mem√≥ria limitada |
| RBFS | Informada | Sim (se sol. alcan√ß√°vel) | Sim (heur. admiss√≠vel) | O(bd) | Planejamento com heur√≠sticas, mem√≥ria muito limitada |
| Recozimento Simulado | Local (Estoc√°stico) | N√£o (probabil√≠stico) | N√£o (probabil√≠stico) | O(1) | Otimiza√ß√£o global (combinat√≥ria/cont√≠nua), problemas com muitos √≥timos locais |
| (1+1)-ES | Evolucion√°rio (Local/Global) | N√£o (probabil√≠stico) | N√£o (probabil√≠stico) | O(1) | Otimiza√ß√£o de par√¢metros cont√≠nuos, auto-adapta√ß√£o |

Onde:
- b: fator de ramifica√ß√£o
- d: profundidade da solu√ß√£o mais rasa

### 4.2 Discuss√£o sobre Aplica√ß√µes

Os algoritmos implementados t√™m nichos de aplica√ß√£o distintos:

-   **IDDFS:** Excelente para buscas em √°rvores ou grafos muito grandes onde a profundidade da solu√ß√£o √© desconhecida e a mem√≥ria √© uma restri√ß√£o severa, mas o custo das a√ß√µes √© uniforme. Jogos simples, quebra-cabe√ßas.
-   **RBFS:** √ötil quando se tem uma boa heur√≠stica (como em A*), mas a mem√≥ria √© extremamente limitada, impedindo o armazenamento da fronteira completa de A*. Pode ser mais lento que A* devido √† re-explora√ß√£o.
-   **Recozimento Simulado:** Poderoso para problemas de otimiza√ß√£o (combinat√≥ria ou cont√≠nua) onde a paisagem de busca √© complexa, com muitos √≥timos locais dos quais algoritmos como a Subida de Encosta n√£o conseguiriam escapar. Exemplos: design de VLSI, problema do caixeiro viajante, treinamento de redes neurais (embora menos comum hoje).
-   **Estrat√©gias de Evolu√ß√£o (ES):** Particularmente fortes na otimiza√ß√£o de par√¢metros em espa√ßos cont√≠nuos, especialmente quando a fun√ß√£o objetivo √© ruidosa, n√£o-diferenci√°vel ou complexa. Usadas em design de engenharia, ajuste de controladores, otimiza√ß√£o de par√¢metros de algoritmos de aprendizado de m√°quina.

## 5. Conclus√£o e Perspectivas Futuras

Este portf√≥lio explorou quatro algoritmos de busca distintos, cada um oferecendo uma abordagem diferente para navegar em espa√ßos de estados ou otimizar fun√ß√µes: IDDFS, RBFS, Recozimento Simulado e Estrat√©gias de Evolu√ß√£o. A sele√ß√£o destes algoritmos visou apresentar alternativas aos m√©todos mais comuns, destacando solu√ß√µes para desafios como limita√ß√µes de mem√≥ria (IDDFS, RBFS) e otimiza√ß√£o em paisagens complexas (Recozimento Simulado, ES).

A IDDFS combina a otimalidade da BFS com a efici√™ncia de mem√≥ria da DFS. A RBFS tenta emular a A* sob restri√ß√µes severas de mem√≥ria, sacrificando potencialmente tempo de execu√ß√£o. O Recozimento Simulado introduz aleatoriedade controlada para escapar de √≥timos locais em problemas de otimiza√ß√£o. As Estrat√©gias de Evolu√ß√£o se destacam na otimiza√ß√£o cont√≠nua, com mecanismos de auto-adapta√ß√£o para ajustar a busca dinamicamente.

A escolha do algoritmo apropriado continua sendo crucial e depende intrinsecamente das caracter√≠sticas do problema: a estrutura do espa√ßo de busca, a disponibilidade de heur√≠sticas, as restri√ß√µes computacionais (tempo e mem√≥ria) e a natureza da fun√ß√£o objetivo (para otimiza√ß√£o).

### 5.1 Tend√™ncias e Desenvolvimentos Recentes

(Esta se√ß√£o pode ser mantida da vers√£o anterior, pois as tend√™ncias gerais s√£o relevantes)

1. **Integra√ß√£o com Aprendizado de M√°quina:** Algoritmos de busca est√£o sendo combinados com t√©cnicas de aprendizado de m√°quina para aprender heur√≠sticas automaticamente a partir de dados, como no caso do AlphaGo da DeepMind, que combina busca em √°rvore Monte Carlo com redes neurais profundas.

2. **Busca em Ambientes Parcialmente Observ√°veis:** Desenvolvimento de algoritmos mais robustos para lidar com incerteza e informa√ß√£o parcial, essenciais para aplica√ß√µes em rob√≥tica e sistemas aut√¥nomos.

3. **Algoritmos Anytime:** Algoritmos que podem fornecer uma solu√ß√£o a qualquer momento, melhorando-a progressivamente se mais tempo for disponibilizado, s√£o cada vez mais importantes em aplica√ß√µes de tempo real.

4. **Paraleliza√ß√£o e Distribui√ß√£o:** Implementa√ß√µes paralelas e distribu√≠das de algoritmos de busca para aproveitar arquiteturas de computa√ß√£o modernas e lidar com problemas de escala muito grande.

5. **Busca Multi-objetivo:** Algoritmos que podem otimizar m√∫ltiplos objetivos simultaneamente, essenciais para problemas do mundo real onde frequentemente h√° trade-offs entre diferentes crit√©rios.

### Desafios e Oportunidades


Apesar dos avan√ßos significativos, v√°rios desafios permanecem:

1. **Escalabilidade:** Muitos problemas do mundo real t√™m espa√ßos de estados enormes que desafiam at√© mesmo os algoritmos mais eficientes.

2. **Representa√ß√£o de Conhecimento:** A efic√°cia dos algoritmos de busca depende fortemente de como o problema √© representado e formulado.

3. **Equil√≠brio entre Explora√ß√£o e Explota√ß√£o:** Encontrar o equil√≠brio certo entre explorar novas √°reas do espa√ßo de estados e explotar conhecimento j√° adquirido continua sendo um desafio fundamental.

4. **Interpretabilidade:** √Ä medida que os algoritmos se tornam mais complexos, garantir que suas decis√µes sejam compreens√≠veis para humanos torna-se mais dif√≠cil, mas tamb√©m mais importante.

A resolu√ß√£o de problemas por busca continua sendo uma √°rea vibrante de pesquisa e aplica√ß√£o em IA, com novas t√©cnicas e abordagens surgindo regularmente. O futuro provavelmente ver√° uma integra√ß√£o ainda maior com outras √°reas da IA, como aprendizado de m√°quina e racioc√≠nio probabil√≠stico, levando a sistemas cada vez mais capazes de resolver problemas complexos de forma eficiente e robusta.

## Refer√™ncias Bibliogr√°ficas


RUSSELL, S. J.; NORVIG, P. *Intelig√™ncia artificial*. 3. ed. Rio de Janeiro: Elsevier Campus, 2013. (Fonte principal para a teoria)

KORF, R. E. Depth-first iterative-deepening: An optimal admissible tree search. *Artificial Intelligence*, v. 27, n. 1, p. 97-109, 1985. (Refer√™ncia chave para IDDFS)

KORF, R. E. Linear-space best-first search. *Artificial Intelligence*, v. 62, n. 1, p. 41-78, 1993. (Refer√™ncia chave para RBFS e outras buscas com mem√≥ria limitada)

KIRKPATRICK, S.; GELATT, C. D.; VECCHI, M. P. Optimization by simulated annealing. *Science*, v. 220, n. 4598, p. 671-680, 1983. (Refer√™ncia seminal para Recozimento Simulado)

RECHENBERG, I. *Evolutionsstrategie: Optimierung technischer Systeme nach Prinzipien der biologischen Evolution*. Stuttgart: Frommann-Holzboog, 1973. (Refer√™ncia seminal para Estrat√©gias de Evolu√ß√£o)

SCHWEFEL, H.-P. *Numerical Optimization of Computer Models*. Chichester: Wiley, 1981. (Trabalho importante sobre ES)

B√ÑCK, T.; FOGEL, D. B.; MICHALEWICZ, Z. (Eds.). *Handbook of Evolutionary Computation*. Bristol: IOP Publishing Ltd. and Oxford University Press, 1997. (Vis√£o geral de computa√ß√£o evolucion√°ria)

CORMEN, T. H.; LEISERSON, C. E.; RIVEST, R. L.; STEIN, C. *Introduction to Algorithms*. 3. ed. Cambridge: MIT Press, 2009.

LAVALLE, S. M. *Planning Algorithms*. Cambridge: Cambridge University Press, 2006.
