# 3. Conclusão

Ao longo da elaboração deste portfólio, explorou-se o campo do aprendizado de máquina por meio de projetos práticos envolvendo aprendizado supervisionado, não supervisionado e por reforço. Essa experiência contribuiu para a compreensão aprofundada dos conceitos teóricos e evidenciou a aplicabilidade e os desafios inerentes ao desenvolvimento de agentes inteligentes.

### Aprendizado Supervisionado

No projeto de aprendizado supervisionado, buscou-se aprender uma função que mapeia entradas a saídas corretas a partir de dados rotulados, exemplificado pela classificação de dígitos manuscritos no dataset MNIST. Observou-se a importância do pré-processamento para mitigar ruídos e selecionar modelos capazes de generalizar para dados não vistos. Essa abordagem é amplamente utilizada em aplicações que envolvem dados rotulados, como reconhecimento facial, diagnósticos médicos e sistemas de recomendação.

A definição de inteligência artificial proposta por Russell e Norvig (2010), que concebe agentes inteligentes como aqueles que transformam perceptos em ações, fundamenta este aprendizado ao evidenciar a necessidade de escolha da melhor hipótese e avaliação rigorosa do desempenho do modelo.

### Aprendizado Não Supervisionado

O aprendizado não supervisionado consistiu na identificação de padrões sem supervisão explícita, demonstrado na segmentação de imagens de faces por gênero através de algoritmos de clustering. Destaca-se a dificuldade em validar os resultados pela ausência de rótulos, além da relevância dessa abordagem para agentes que precisam extrair conhecimento de dados não estruturados.

Conforme Russell e Norvig (2010), a representação explícita do conhecimento ganha ênfase aqui, uma vez que o agente constrói modelos internos a partir de observações puras, facilitando processos subsequentes de raciocínio ou aprendizado.

### Aprendizado por Reforço

O aprendizado por reforço envolveu o desenvolvimento de um agente que aprende a agir em um ambiente dinâmico por meio de recompensas e punições, implementado via Q-learning em uma simulação de navegação. A ausência de um modelo explícito do ambiente e a necessidade de equilibrar exploração e explotação evidenciam a complexidade dessa modalidade.

Esse método é particularmente indicado para agentes operando em ambientes incertos, como robôs exploradores, conforme destacado por Russell e Norvig (2010), que reforçam a importância da aprendizagem pela interação para ampliar a autonomia dos agentes.

### Considerações Finais

A experiência prática possibilitou uma integração clara entre os conceitos teóricos e as aplicações reais. Ficou evidente que cada abordagem — supervisionada, não supervisionada e por reforço — possui vantagens específicas e é adequada a diferentes tipos de problemas e ambientes.

A fundamentação teórica de Russell e Norvig (2010) revelou-se essencial para compreender a natureza dos agentes inteligentes e suas capacidades adaptativas. Por fim, o aprendizado de máquina se mostra um campo desafiador e promissor, essencial para o avanço da inteligência artificial.

---


### Referências

RUSSELL, Stuart J.; NORVIG, Peter. *Artificial Intelligence: A Modern Approach*. 3. ed. Englewood Cliffs, NJ: Prentice-Hall, 2010.


---


| Versão | Data       | Modificação         | Nome                 | GitHub                                      |
|--------|------------|---------------------|----------------------|---------------------------------------------|
| `1.0`  | 27/07/2025 | Criação do documento | Ana Beatriz Norberto | [@ananorberto](https://github.com/ananorberto) |

