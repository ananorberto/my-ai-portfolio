{"config":{"lang":["pt"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Portf\u00f3lio de Intelig\u00eancia Artificial","text":"<p>Disciplina de Intelig\u00eancia Artificial \u2013 2025/1 Curso de Engenharia de Software \u2013 Universidade de Bras\u00edlia (UnB) </p>"},{"location":"#sobre-este-site","title":"\ud83d\udca1 Sobre este site","text":"<p>Este site foi desenvolvido como portf\u00f3lio para a disciplina de Intelig\u00eancia Artificial, com o objetivo de registrar os principais conte\u00fados estudados ao longo do semestre, al\u00e9m de reflex\u00f5es, atividades e contribui\u00e7\u00f5es pessoais. Ele tamb\u00e9m funciona como uma forma de treinar organiza\u00e7\u00e3o de conte\u00fado com documenta\u00e7\u00e3o.</p> <p>Curiosidade: a logo usada no site foi desenhada \u00e0 m\u00e3o por mim e depois transformada em uma imagem digital com a ajuda de uma ferramenta de intelig\u00eancia artificial. \ud83e\udd16</p>"},{"location":"#sobre-mim","title":"\ud83d\ude4b Sobre mim","text":"<p>Ol\u00e1! Me chamo Ana Beatriz Norberto, sou estudante de Engenharia de Software na UnB. Tenho interesse em desenvolvimento fullstack e intelig\u00eancia artificial aplicada.</p> <p>\ud83d\udcbb GitHub: @ananorberto</p> <p>Projeto desenvolvido como parte da avalia\u00e7\u00e3o por portf\u00f3lio para a disciplina de IA \u2013 FGA/UnB. Ministrada pelo professor Fabiano Araujo Soares.</p>"},{"location":"en/","title":"Welcome to my AI Portfolio","text":"<p>This portfolio showcases my journey and projects in Artificial Intelligence. Here you'll find:</p> <ul> <li>Introduction to AI concepts</li> <li>Historical overview of AI development</li> <li>Current state of the art</li> <li>Analysis of benefits and risks</li> <li>Study of intelligent agents</li> <li>Practical projects and problems</li> </ul> <p>Use the navigation menu to explore the content. You can switch between light and dark mode using the theme toggle in the top right corner.</p>"},{"location":"en/#about-me","title":"About Me","text":"<p>I'm Ana Norberto, an AI enthusiast and student. This portfolio represents my learning journey in the fascinating world of Artificial Intelligence.</p> <p>\ud83d\udcbb GitHub: @ananorberto</p> <p>Project developed as part of the portfolio evaluation for the AI course \u2013 FGA/UnB. </p>"},{"location":"portfolio1/agentes_inteligentes/","title":"Agentes Inteligentes","text":"<p>Um agente de IA \u00e9 qualquer sistema capaz de perceber seu ambiente por meio de sensores e agir sobre ele atrav\u00e9s de atuadores. Ele pode ser algo f\u00edsico (como um rob\u00f4) ou virtual (como um assistente digital).</p> <p>Segundo Russell e Norvig (2022), o conceito de agente \u00e9 central na IA moderna. Toda a estrutura de racioc\u00ednio e tomada de decis\u00e3o parte da ideia de que o agente interage continuamente com o ambiente, tentando atingir seus objetivos com base nas informa\u00e7\u00f5es que coleta.</p>"},{"location":"portfolio1/agentes_inteligentes/#tipos-de-agentes","title":"Tipos de agentes","text":"<p>A forma como os agentes tomam decis\u00f5es varia de acordo com sua complexidade e capacidade de adapta\u00e7\u00e3o. A seguir, est\u00e3o os principais tipos:</p>"},{"location":"portfolio1/agentes_inteligentes/#agentes-de-reflexo-simples","title":"Agentes de Reflexo Simples","text":"<ul> <li>Agem com base em regras fixas do tipo se\u2013ent\u00e3o.</li> <li>N\u00e3o possuem mem\u00f3ria nem aprendizado.</li> <li>Exemplo: um termostato que liga o ar-condicionado quando a temperatura passa de 26\u202f\u00b0C.</li> </ul>"},{"location":"portfolio1/agentes_inteligentes/#agentes-de-reflexo-baseado-em-modelo","title":"Agentes de Reflexo Baseado em Modelo","text":"<ul> <li>Mant\u00eam um modelo interno do ambiente.</li> <li>Conseguem lidar com situa\u00e7\u00f5es mais complexas, mesmo sem observar todo o estado atual.</li> <li>Exemplo: um aspirador rob\u00f3tico que mapeia a sala para decidir para onde ir.</li> </ul>"},{"location":"portfolio1/agentes_inteligentes/#agentes-baseados-em-objetivos","title":"\ud83c\udfaf Agentes Baseados em Objetivos","text":"<ul> <li>Agem para atingir metas espec\u00edficas.</li> <li>S\u00e3o capazes de escolher entre diferentes a\u00e7\u00f5es avaliando qual aproxima mais do objetivo.</li> <li>Exemplo: um aplicativo de GPS que calcula a melhor rota.</li> </ul>"},{"location":"portfolio1/agentes_inteligentes/#agentes-utilitarios","title":"\ud83d\udcc8 Agentes Utilit\u00e1rios","text":"<ul> <li>V\u00e3o al\u00e9m dos objetivos: tamb\u00e9m consideram a melhor forma de atingi-los.</li> <li>Avaliam consequ\u00eancias, prefer\u00eancias e desempenho.</li> <li>Exemplo: um sistema de investimentos que busca maximizar lucros e minimizar riscos.</li> </ul>"},{"location":"portfolio1/agentes_inteligentes/#agentes-com-aprendizado-learning-agents","title":"\ud83e\uddec Agentes com Aprendizado (Learning Agents)","text":"<ul> <li>Melhoram sua performance ao longo do tempo com base na experi\u00eancia.</li> <li>Podem ajustar internamente seus componentes e regras.</li> <li>Exemplo: redes neurais que ajustam seus pesos com base em dados hist\u00f3ricos.</li> </ul> <p>Esses tipos n\u00e3o s\u00e3o mutuamente exclusivos. Um agente pode, por exemplo, ser baseado em objetivos e tamb\u00e9m aprender com a experi\u00eancia.</p>"},{"location":"portfolio1/agentes_inteligentes/#ambientes-em-ia","title":"Ambientes em IA","text":"<p>O ambiente \u00e9 o contexto onde o agente est\u00e1 inserido. \u00c9 ele que determina o que o agente pode ou n\u00e3o perceber, quais a\u00e7\u00f5es est\u00e3o dispon\u00edveis e como elas impactam o mundo ao redor.</p> <p>Conforme Russell e Norvig (2022), a maneira como o ambiente \u00e9 estruturado influencia diretamente no tipo de agente que pode ser constru\u00eddo.</p>"},{"location":"portfolio1/agentes_inteligentes/#classificacoes-de-ambiente","title":"Classifica\u00e7\u00f5es de ambiente","text":"Dimens\u00e3o Explica\u00e7\u00e3o Exemplo Observabilidade Totalmente observ\u00e1vel / Parcialmente / N\u00e3o observ\u00e1vel Xadrez (totalmente), p\u00f4quer (parcial), rob\u00f4 em espa\u00e7o desconhecido (n\u00e3o) N\u00famero de agentes Agente \u00fanico ou multiagente Sudoku (\u00fanico), jogos online (multiagente) Determinismo Determin\u00edstico ou n\u00e3o determin\u00edstico Jogo de damas (determin\u00edstico), mercado financeiro (n\u00e3o determin\u00edstico) Temporalidade Epis\u00f3dico ou sequencial Diagn\u00f3stico m\u00e9dico (epis\u00f3dico), redes sociais (sequencial) Dinamicidade Est\u00e1tico ou din\u00e2mico Quebra-cabe\u00e7a offline (est\u00e1tico), tr\u00e2nsito urbano (din\u00e2mico) Natureza do estado Discreto ou cont\u00ednuo Tabuleiro (discreto), controle de um drone (cont\u00ednuo) Conhecimento do agente Conhecido ou desconhecido Regras de um jogo (conhecido), interesses de um usu\u00e1rio no YouTube (desconhecido) <p>Cada uma dessas caracter\u00edsticas exige abordagens diferentes na hora de projetar um agente eficiente. Por exemplo, ambientes parcialmente observ\u00e1veis geralmente pedem agentes que consigam manter um modelo interno do estado, enquanto ambientes din\u00e2micos exigem resposta r\u00e1pida e atualiza\u00e7\u00e3o constante das percep\u00e7\u00f5es.</p>"},{"location":"portfolio1/agentes_inteligentes/#consideracoes-finais","title":"Considera\u00e7\u00f5es finais","text":"<p>Entender o que s\u00e3o agentes e como funcionam os ambientes onde eles atuam \u00e9 essencial para projetar sistemas de IA inteligentes e eficientes. Os agentes representam o \"como\" a IA age, enquanto os ambientes representam o \"onde\" e \"com que restri\u00e7\u00f5es\" essa a\u00e7\u00e3o acontece.</p> <p>Combinar essas duas vis\u00f5es \u2014 comportamento interno do agente e caracter\u00edsticas externas do ambiente \u2014 permite desenvolver solu\u00e7\u00f5es mais adapt\u00e1veis, robustas e eficazes. E, como mostram as refer\u00eancias, essa intera\u00e7\u00e3o \u00e9 a base de praticamente todas as aplica\u00e7\u00f5es modernas de Intelig\u00eancia Artificial.</p>"},{"location":"portfolio1/agentes_inteligentes/#referencias","title":"Refer\u00eancias","text":"<ul> <li>Russell, S., &amp; Norvig, P. (2022). Artificial Intelligence: A Modern Approach (4\u00aa ed.). Pearson.  </li> <li>Marsland, S. (2015). Machine Learning: An Algorithmic Perspective (2\u00aa ed.). CRC Press.  </li> <li>Notas de aula da disciplina FGA0221 \u2013 Intelig\u00eancia Artificial, Universidade de Bras\u00edlia (2025/1).</li> </ul>"},{"location":"portfolio1/agentes_inteligentes/#historico-de-versao","title":"Hist\u00f3rico de vers\u00e3o","text":"Vers\u00e3o Data Modifica\u00e7\u00e3o Nome GitHub <code>1.0</code> 06/05/2025 Cria\u00e7\u00e3o do documento Ana Beatriz Norberto @ananorberto"},{"location":"portfolio1/ambientes/","title":"Ambientes em Intelig\u00eancia Artificial","text":""},{"location":"portfolio1/ambientes/#introducao","title":"Introdu\u00e7\u00e3o","text":"<p>Nesta se\u00e7\u00e3o, exploraremos os diferentes tipos de ambientes em que os agentes de IA operam.</p>"},{"location":"portfolio1/ambientes/#tipos-de-ambientes","title":"Tipos de Ambientes","text":"<ul> <li>Ambientes totalmente observ\u00e1veis vs. parcialmente observ\u00e1veis</li> <li>Ambientes determin\u00edsticos vs. estoc\u00e1sticos</li> <li>Ambientes epis\u00f3dicos vs. sequenciais</li> <li>Ambientes est\u00e1ticos vs. din\u00e2micos</li> <li>Ambientes discretos vs. cont\u00ednuos</li> <li>Ambientes \u00fanicos vs. multiagentes</li> </ul>"},{"location":"portfolio1/ambientes/#caracteristicas-dos-ambientes","title":"Caracter\u00edsticas dos Ambientes","text":"<p>Cada tipo de ambiente apresenta desafios espec\u00edficos para o desenvolvimento de agentes inteligentes. </p>"},{"location":"portfolio1/ambientes/#historico-de-versao","title":"Hist\u00f3rico de vers\u00e3o","text":"Vers\u00e3o Data Modifica\u00e7\u00e3o Nome GitHub <code>1.0</code> 05/05/2025 Cria\u00e7\u00e3o do documento Ana Beatriz Norberto @ananorberto"},{"location":"portfolio1/beneficios_riscos/","title":"Benef\u00edcios e Riscos da Intelig\u00eancia Artificial","text":"<p>A IA tem trazido muitos avan\u00e7os para diferentes \u00e1reas da sociedade, e isso \u00e9 algo que n\u00e3o d\u00e1 mais pra ignorar. Ela est\u00e1 ajudando a resolver problemas complexos, automatizando tarefas repetitivas, analisando dados em escala e at\u00e9 apoiando decis\u00f5es em \u00e1reas cr\u00edticas, como sa\u00fade e seguran\u00e7a. Mas junto com todos esses benef\u00edcios, tamb\u00e9m surgem preocupa\u00e7\u00f5es reais \u2014 que precisam ser discutidas com seriedade.</p> <p>Segundo Russell e Norvig (2022), a IA n\u00e3o \u00e9 uma tecnologia neutra. Os sistemas que criamos refletem decis\u00f5es humanas, e isso inclui tanto nossas boas inten\u00e7\u00f5es quanto nossos preconceitos, falhas e interesses. Por isso, n\u00e3o d\u00e1 pra pensar em \"avan\u00e7o\" sem tamb\u00e9m olhar para os impactos \u00e9ticos, sociais e econ\u00f4micos.</p>"},{"location":"portfolio1/beneficios_riscos/#principais-beneficios","title":"Principais benef\u00edcios","text":"<p>Entre os pontos positivos mais vis\u00edveis do uso da IA est\u00e3o:</p> <ul> <li>Automa\u00e7\u00e3o inteligente: tarefas que antes eram feitas manualmente agora podem ser automatizadas com mais precis\u00e3o e velocidade \u2014 o que aumenta a produtividade em muitos setores.</li> <li>Apoio \u00e0 decis\u00e3o: a IA consegue lidar com grandes volumes de dados, encontrar padr\u00f5es e sugerir solu\u00e7\u00f5es que humanos sozinhos teriam dificuldade de visualizar.</li> <li>Avan\u00e7os na ci\u00eancia e na medicina: a tecnologia est\u00e1 ajudando na descoberta de novos medicamentos, na an\u00e1lise de exames e no desenvolvimento de tratamentos mais personalizados.</li> <li>Acessibilidade: sistemas de reconhecimento de fala e imagem est\u00e3o sendo usados para tornar dispositivos mais acess\u00edveis para pessoas com defici\u00eancia.</li> </ul>"},{"location":"portfolio1/beneficios_riscos/#riscos-e-desafios","title":"Riscos e desafios","text":"<p>Por outro lado, os riscos que acompanham esse crescimento tamb\u00e9m s\u00e3o importantes:</p> <ul> <li>Vi\u00e9s algor\u00edtmico: se os dados usados para treinar um sistema forem tendenciosos (o que \u00e9 muito comum), o resultado tamb\u00e9m ser\u00e1. Isso pode gerar injusti\u00e7as, principalmente em decis\u00f5es automatizadas.</li> <li>Falta de explicabilidade: muitos modelos, especialmente os baseados em deep learning, funcionam como \"caixas-pretas\", dificultando a compreens\u00e3o e a auditoria de suas decis\u00f5es.</li> <li>Impacto no trabalho humano: a automa\u00e7\u00e3o pode substituir postos de trabalho, principalmente os mais operacionais, e isso exige planejamento social e pol\u00edtico para evitar desigualdades.</li> <li>Privacidade e seguran\u00e7a: com tanto dado sendo coletado e processado, surge a preocupa\u00e7\u00e3o sobre quem controla essas informa\u00e7\u00f5es e como elas est\u00e3o sendo usadas.</li> <li>Autonomia excessiva: em sistemas cr\u00edticos (como drones militares ou carros aut\u00f4nomos), o risco de perda de controle sobre a tomada de decis\u00e3o se torna um problema \u00e9tico e t\u00e9cnico.</li> </ul>"},{"location":"portfolio1/beneficios_riscos/#consideracoes-finais","title":"Considera\u00e7\u00f5es finais","text":"<p>A IA tem um potencial enorme, mas ela tamb\u00e9m exige responsabilidade. Como dizem Russell e Norvig (2022), desenvolver sistemas inteligentes vai muito al\u00e9m de programar bem \u2014 \u00e9 tamb\u00e9m saber onde, por que e com que valores esses sistemas est\u00e3o sendo aplicados.</p> <p>A gente est\u00e1 num ponto em que as escolhas que fazemos agora v\u00e3o definir o tipo de futuro que queremos construir com a IA. Por isso, mais do que empolga\u00e7\u00e3o com a tecnologia, o momento pede consci\u00eancia.</p>"},{"location":"portfolio1/beneficios_riscos/#referencias","title":"Refer\u00eancias","text":"<ul> <li>Russell, S., &amp; Norvig, P. (2022). Artificial Intelligence: A Modern Approach (4\u00aa ed.). Pearson.  </li> <li>Marsland, S. (2015). Machine Learning: An Algorithmic Perspective (2\u00aa ed.). CRC Press.  </li> <li>Notas de aula da disciplina FGA0221 \u2013 Intelig\u00eancia Artificial, Universidade de Bras\u00edlia (2025/1).</li> </ul>"},{"location":"portfolio1/beneficios_riscos/#historico-de-versao","title":"Hist\u00f3rico de vers\u00e3o","text":"Vers\u00e3o Data Modifica\u00e7\u00e3o Nome GitHub <code>1.0</code> 05/05/2025 Cria\u00e7\u00e3o do documento Ana Beatriz Norberto @ananorberto"},{"location":"portfolio1/conclusao/","title":"Conclus\u00e3o do Portf\u00f3lio 1","text":"<p>Chegamos ao final deste primeiro portf\u00f3lio de Intelig\u00eancia Artificial com uma vis\u00e3o mais clara sobre como essa tecnologia fascinante funciona e impacta nosso mundo. Assim como na introdu\u00e7\u00e3o, onde falei sobre a IA estar presente no nosso cotidiano, agora podemos entender melhor os mecanismos por tr\u00e1s dessas aplica\u00e7\u00f5es - desde os agentes inteligentes at\u00e9 os complexos ambientes onde operam.</p> <p>O que come\u00e7ou como uma explora\u00e7\u00e3o te\u00f3rica sobre conceitos b\u00e1sicos se transformou em uma compreens\u00e3o mais profunda dos reais benef\u00edcios e desafios da IA. Vimos como sistemas aparentemente simples, como um agente de reflexo b\u00e1sico, j\u00e1 fazem parte da nossa rotina em dispositivos dom\u00e9sticos, enquanto t\u00e9cnicas mais avan\u00e7adas como deep learning est\u00e3o revolucionando setores inteiros.</p> <p>Assim como destaquei na introdu\u00e7\u00e3o a import\u00e2ncia de estudar IA na nossa forma\u00e7\u00e3o como engenheiros de software, esta conclus\u00e3o refor\u00e7a como esses conhecimentos s\u00e3o fundamentais para desenvolver solu\u00e7\u00f5es tecnol\u00f3gicas \u00e9ticas e eficientes. Aprendemos que criar sistemas inteligentes vai muito al\u00e9m de programa\u00e7\u00e3o - envolve entender contextos, prever consequ\u00eancias e tomar decis\u00f5es respons\u00e1veis.</p> <p>Este portf\u00f3lio representa meu primeiro passo nessa jornada de aprendizado sobre IA. Nas pr\u00f3ximas etapas, pretendo levar esses fundamentos para projetos mais pr\u00e1ticos, sempre mantendo o foco na aplica\u00e7\u00e3o real e nas implica\u00e7\u00f5es sociais dessa tecnologia poderosa.</p> <p>Assim como a IA continua evoluindo, meu entendimento sobre o assunto tamb\u00e9m seguir\u00e1 crescendo - e este portf\u00f3lio \u00e9 o registro desse processo de descoberta e reflex\u00e3o.</p>"},{"location":"portfolio1/conclusao/#historico-de-versao","title":"Hist\u00f3rico de vers\u00e3o","text":"Vers\u00e3o Data Modifica\u00e7\u00e3o Nome GitHub <code>1.0</code> 06/05/2025 Cria\u00e7\u00e3o do documento Ana Beatriz Norberto @ananorberto ---"},{"location":"portfolio1/estado_arte/","title":"Estado da Arte da Intelig\u00eancia Artificial","text":"<p>A Intelig\u00eancia Artificial evoluiu muito desde os primeiros programas baseados em regras e l\u00f3gica simb\u00f3lica. Hoje, ela est\u00e1 presente em praticamente tudo que envolve tecnologia e dados. O que antes parecia distante da realidade, agora j\u00e1 faz parte da nossa rotina \u2014 seja em sistemas de recomenda\u00e7\u00e3o, aplicativos de transporte, assistentes virtuais ou ferramentas de tradu\u00e7\u00e3o autom\u00e1tica.</p> <p>De acordo com Russell e Norvig (2022), a IA moderna tem focado principalmente em resolver problemas bem definidos com alto desempenho. A ideia de construir uma intelig\u00eancia geral (do tipo humano) continua sendo um desafio distante, mas os avan\u00e7os em tarefas espec\u00edficas \u2014 como vis\u00e3o computacional, linguagem natural e aprendizado por refor\u00e7o \u2014 mostram o quanto a IA j\u00e1 \u00e9 \u00fatil e poderosa, mesmo sendo \"limitada\".</p>"},{"location":"portfolio1/estado_arte/#onde-estamos-agora","title":"Onde estamos agora","text":"<p>Atualmente, a maioria dos sistemas de IA que est\u00e3o em uso no mundo real pertence \u00e0 chamada IA estreita (narrow AI). Isso significa que eles s\u00e3o bons em fazer uma \u00fanica coisa, como identificar rostos em fotos ou recomendar filmes, mas n\u00e3o conseguem \"entender o mundo\" de maneira ampla ou pensar fora da tarefa para a qual foram treinados.</p> <p>Entre os principais destaques do estado atual da IA, segundo os autores, est\u00e3o:</p> <ul> <li>Deep Learning com redes neurais profundas, que revolucionaram tarefas como classifica\u00e7\u00e3o de imagens, tradu\u00e7\u00e3o e s\u00edntese de voz;</li> <li>Aprendizado por refor\u00e7o aplicado a jogos e simula\u00e7\u00f5es, como o caso do AlphaGo e sistemas de controle rob\u00f3tico;</li> <li>Sistemas de NLP (Processamento de Linguagem Natural), capazes de gerar textos, traduzir idiomas e at\u00e9 manter conversas com coer\u00eancia;</li> <li>IA aplicada \u00e0 sa\u00fade, \u00e0 ci\u00eancia, \u00e0 log\u00edstica, \u00e0 educa\u00e7\u00e3o e a muitos outros setores, com foco em apoio \u00e0 decis\u00e3o e automa\u00e7\u00e3o inteligente.</li> </ul>"},{"location":"portfolio1/estado_arte/#o-que-ainda-e-um-desafio","title":"O que ainda \u00e9 um desafio","text":"<p>Mesmo com todos esses avan\u00e7os, Russell e Norvig lembram que a IA atual ainda depende muito de grandes volumes de dados, alto poder computacional e problemas bem definidos. Ou seja, ela n\u00e3o \u00e9 nem de longe \"inteligente\" como n\u00f3s, humanos.</p> <p>Al\u00e9m disso, existem quest\u00f5es importantes que n\u00e3o s\u00e3o apenas t\u00e9cnicas, como:</p> <ul> <li>Como garantir que os sistemas sejam justos e n\u00e3o discriminat\u00f3rios?</li> <li>Como explicar decis\u00f5es que foram feitas por modelos de caixa-preta?</li> <li>Qual o impacto da IA no mercado de trabalho, na educa\u00e7\u00e3o e na privacidade das pessoas?</li> </ul> <p>Esses s\u00e3o os temas que est\u00e3o no centro da discuss\u00e3o hoje. Desenvolver IA n\u00e3o \u00e9 s\u00f3 programar \u2014 \u00e9 tamb\u00e9m pensar nas consequ\u00eancias.</p>"},{"location":"portfolio1/estado_arte/#referencias","title":"Refer\u00eancias","text":"<ul> <li>Russell, S., &amp; Norvig, P. (2022). Artificial Intelligence: A Modern Approach (4\u00aa ed.). Pearson.  </li> <li>Marsland, S. (2015). Machine Learning: An Algorithmic Perspective (2\u00aa ed.). CRC Press.  </li> <li>Notas de aula da disciplina FGA0221 \u2013 Intelig\u00eancia Artificial, Universidade de Bras\u00edlia (2025/1).</li> </ul>"},{"location":"portfolio1/estado_arte/#historico-de-versao","title":"Hist\u00f3rico de vers\u00e3o","text":"Vers\u00e3o Data Modifica\u00e7\u00e3o Nome GitHub 1.0 06/05/2025 Cria\u00e7\u00e3o do documento Ana Beatriz Norberto @ananorberto"},{"location":"portfolio1/historico/","title":"Hist\u00f3rico da Intelig\u00eancia Artificial","text":"<p>A hist\u00f3ria da Intelig\u00eancia Artificial \u00e9 bem curiosa e marcada por muitos acontecimentos e avan\u00e7os tecnol\u00f3gicos, te\u00f3ricos e conceituais que refletem diretamente nas mudan\u00e7as que aconteceram na ci\u00eancia da computa\u00e7\u00e3o e na sociedade ao longo do tempo. Desde muito tempo, a IA tem como objetivo desenvolver sistemas capazes de realizar tarefas que exigiriam intelig\u00eancia se fossem executadas por seres humanos.</p> <p>Segundo Russell e Norvig (2022), os fundamentos da IA remontam \u00e0 Antiguidade, com mitos sobre aut\u00f4matos e tentativas filos\u00f3ficas de entender o racioc\u00ednio humano. Contudo, o desenvolvimento moderno da \u00e1rea come\u00e7a no s\u00e9culo XX, impulsionado pelos trabalhos matem\u00e1ticos de Alan Turing, que prop\u00f4s o conceito de m\u00e1quina universal e a famosa quest\u00e3o \"As m\u00e1quinas podem pensar?\", abrindo espa\u00e7o para investiga\u00e7\u00f5es sobre comportamento inteligente em m\u00e1quinas.</p> <p>Foi s\u00f3 por volta de 1950 que o nascimento da IA foi, de fato, formalizado, com o famoso Dartmouth Workshop (1956), onde John McCarthy cunhou o termo Artificial Intelligence. Na \u00e9poca, j\u00e1 se acreditava que, com avan\u00e7os suficientes, seria poss\u00edvel replicar aspectos da cogni\u00e7\u00e3o humana em computadores (Russell &amp; Norvig, 2022).</p> <p>Nos anos seguintes, a IA passou por v\u00e1rios altos e baixos. Na chamada primeira onda (1950\u20131970), os sistemas se baseavam fortemente em l\u00f3gica simb\u00f3lica e regras expl\u00edcitas. Esses programas conseguiam resolver quebra-cabe\u00e7as e jogar xadrez, mas falhavam em tarefas do mundo real por n\u00e3o lidarem bem com ambiguidade ou incerteza (Marsland, 2015).</p> <p>Na d\u00e9cada de 1980, surgiram os sistemas especialistas, que codificavam o conhecimento de profissionais humanos em regras do tipo se\u2013ent\u00e3o. Ferramentas como o MYCIN, voltado para diagn\u00f3sticos m\u00e9dicos, foram destaque da \u00e9poca. Por\u00e9m, como apontam Marsland (2015) e Russell &amp; Norvig (2022), a rigidez e a dificuldade de manuten\u00e7\u00e3o desses sistemas acabaram dificultando sua aplica\u00e7\u00e3o pr\u00e1tica em larga escala.</p> <p>A partir dos anos 90, uma nova abordagem passou a ser considerada: o Machine Learning (aprendizado de m\u00e1quina). Optou-se por usar algoritmos que aprendem padr\u00f5es a partir de dados, em vez de programar explicitamente todo o conhecimento. Isso marcou uma grande mudan\u00e7a de paradigma dentro da IA: do simb\u00f3lico para o estat\u00edstico. Marsland (2015) enfatiza que essa transi\u00e7\u00e3o foi fundamental para o progresso da \u00e1rea, permitindo que os sistemas se tornassem mais robustos, adapt\u00e1veis e \u00fateis em contextos reais.</p> <p>Dessa forma, \u00e9 evidente que, especialmente na \u00faltima d\u00e9cada (anos 2000), o crescimento exponencial da capacidade computacional e a possibilidade de lidar com grandes volumes de dados (Big Data) tornaram poss\u00edvel o avan\u00e7o de t\u00e9cnicas como o deep learning, baseado em redes neurais profundas. Aplica\u00e7\u00f5es como reconhecimento facial, tradu\u00e7\u00e3o autom\u00e1tica, carros aut\u00f4nomos e assistentes virtuais tornaram a IA parte integrante do nosso cotidiano.</p> <p>Por fim, vale destacar que o campo da IA ainda segue em r\u00e1pida evolu\u00e7\u00e3o. Como observam Russell e Norvig (2022), os desafios contempor\u00e2neos incluem n\u00e3o apenas aprimorar a efici\u00eancia dos sistemas, mas tamb\u00e9m refletir sobre quest\u00f5es \u00e9ticas, sociais e filos\u00f3ficas envolvidas no desenvolvimento de agentes inteligentes.</p>"},{"location":"portfolio1/historico/#referencias","title":"Refer\u00eancias","text":"<ul> <li>Russell, S., &amp; Norvig, P. (2022). Artificial Intelligence: A Modern Approach (4\u00aa ed.). Pearson.  </li> <li>Marsland, S. (2015). Machine Learning: An Algorithmic Perspective (2\u00aa ed.). CRC Press.  </li> <li>Notas de aula da disciplina FGA0221 \u2013 Intelig\u00eancia Artificial, Universidade de Bras\u00edlia (2025/1).</li> </ul>"},{"location":"portfolio1/historico/#historico-de-versao","title":"Hist\u00f3rico de vers\u00e3o","text":"Vers\u00e3o Data Modifica\u00e7\u00e3o Nome GitHub <code>1.0</code> 05/05/2025 Cria\u00e7\u00e3o do documento Ana Beatriz Norberto @ananorberto"},{"location":"portfolio1/introducao/","title":"Introdu\u00e7\u00e3o ao Protf\u00f3lio de Intelig\u00eancia Artificial","text":"<p>Esse portf\u00f3lio tem como objetivo reunir os principais aprendizados da disciplina de Intelig\u00eancia Artificial (IA), cursada em 2025/1 no curso de Engenharia de Software da UnB. Mais do que um resumo de conte\u00fado, ele busca refletir sobre o que foi estudado e como isso se conecta com o mundo real e com a pr\u00e1tica da nossa profiss\u00e3o.</p> <p>A IA \u00e9 uma \u00e1rea da computa\u00e7\u00e3o que tenta dar aos sistemas a capacidade de \u201cpensar\u201d ou agir de forma inteligente. Isso pode parecer distante, mas est\u00e1 cada vez mais presente no nosso dia a dia: seja em assistentes virtuais, carros aut\u00f4nomos, redes sociais ou at\u00e9 na sa\u00fade. Ao longo da disciplina, estudamos desde conceitos b\u00e1sicos, como agentes inteligentes e tipos de ambientes, at\u00e9 algoritmos de busca e heur\u00edsticas que ajudam a resolver problemas complexos.</p> <p>O portf\u00f3lio est\u00e1 organizado para acompanhar essa jornada. Come\u00e7a com uma introdu\u00e7\u00e3o mais te\u00f3rica sobre a IA, passa por discuss\u00f5es sobre seu hist\u00f3rico, estado atual, impactos e riscos, e avan\u00e7a para a parte pr\u00e1tica, onde desenvolvemos agentes e analisamos os resultados. Ao final, compartilho tamb\u00e9m minhas percep\u00e7\u00f5es sobre o conte\u00fado, o processo de aprendizagem e a import\u00e2ncia da IA na forma\u00e7\u00e3o como engenheira de software.</p> <p>A ideia \u00e9 que esse material n\u00e3o s\u00f3 sirva como registro do semestre, mas tamb\u00e9m como uma forma de mostrar como a IA pode ser aplicada de maneira \u00e9tica, criativa e relevante no nosso futuro profissional.</p>"},{"location":"portfolio1/introducao/#historico-de-versao","title":"Hist\u00f3rico de vers\u00e3o","text":"Vers\u00e3o Data Modifica\u00e7\u00e3o Nome GitHub <code>1.0</code> 05/05/2025 Cria\u00e7\u00e3o do documento Ana Beatriz Norberto @ananorberto"},{"location":"portfolio1/projetos/","title":"Problemas/Projetos","text":""},{"location":"portfolio1/projetos/#projeto-sistema-de-busca-semantica-em-relatorios-policiais-sobre-armas-brancas","title":"Projeto: Sistema de Busca Sem\u00e2ntica em Relat\u00f3rios Policiais sobre Armas Brancas","text":""},{"location":"portfolio1/projetos/#contexto-e-relevancia","title":"Contexto e Relev\u00e2ncia","text":"<p>A identifica\u00e7\u00e3o autom\u00e1tica de registros que mencionam armas brancas (como facas, canivetes ou machados) em relat\u00f3rios policiais representa uma contribui\u00e7\u00e3o significativa para investiga\u00e7\u00f5es criminais, intelig\u00eancia policial e pesquisas acad\u00eamicas sobre viol\u00eancia urbana. Ao automatizar a extra\u00e7\u00e3o dessas informa\u00e7\u00f5es em textos n\u00e3o estruturados, como os boletins de ocorr\u00eancia, \u00e9 poss\u00edvel melhorar a efici\u00eancia na an\u00e1lise de padr\u00f5es criminais e subsidiar pol\u00edticas p\u00fablicas de seguran\u00e7a.</p> <p>Este ideia nasceu a partir das discuss\u00f5es realizadas na aula do dia 06/05/2025, em que o professor Fabiano apresentou exemplos de aplica\u00e7\u00e3o de t\u00e9cnicas de intelig\u00eancia artificial em dados de seguran\u00e7a p\u00fablica. Motivada por esse conte\u00fado, aprofundei uma pesquisa em solu\u00e7\u00f5es similares, como as propostas por Tompson et al. [1], que aplicam minera\u00e7\u00e3o de texto em relat\u00f3rios policiais para identificar padr\u00f5es de crimes, e por Ara\u00fajo et al. [2], que exploram mecanismos de similaridade sem\u00e2ntica em documentos policiais.</p>"},{"location":"portfolio1/projetos/#conexao-com-experiencia-pratica","title":"Conex\u00e3o com Experi\u00eancia Pr\u00e1tica","text":"<p>Durante a pesquisa observei que a proposta aqui apresentada est\u00e1 alinhada com os conte\u00fados explorados nos laborat\u00f3rios da disciplina de Programa\u00e7\u00e3o para Sistemas Paralelos e Distribu\u00eddos (PSPD) feitos  no semestre 2024/2. Em especial, destacam-se os experimentos com pipelines de ingest\u00e3o, processamento e visualiza\u00e7\u00e3o de dados utilizando tecnologias como Kafka, Spark e Elasticsearch. Esse conhecimento pr\u00e1tico foi essencial para compreender os desafios de escalabilidade e desempenho envolvidos no tratamento de grandes volumes de texto.</p> <p>Al\u00e9m disso, refer\u00eancias como a de Ladanavar et al. [3] mostram como arquiteturas semelhantes \u2014 combinando pr\u00e9-processamento textual, embeddings BERT e Elasticsearch \u2014 j\u00e1 s\u00e3o aplicadas com sucesso em sistemas de busca sem\u00e2ntica, refor\u00e7ando a viabilidade t\u00e9cnica da nossa abordagem.</p>"},{"location":"portfolio1/projetos/#proposta-tecnica","title":"Proposta T\u00e9cnica","text":"<p>Inspirado por abordagens consolidadas em estudos recentes [2][3], o sistema proposto \u00e9 estruturado em tr\u00eas etapas principais:</p> <ol> <li> <p>Pr\u00e9-processamento Textual    Realiza a limpeza de texto (remo\u00e7\u00e3o de stopwords, pontua\u00e7\u00e3o irrelevante e padroniza\u00e7\u00e3o de caixa), normaliza\u00e7\u00e3o (lematiza\u00e7\u00e3o e corre\u00e7\u00e3o ortogr\u00e1fica), e a extra\u00e7\u00e3o de entidades nomeadas (NER), permitindo identificar automaticamente men\u00e7\u00f5es a armas brancas, locais, datas e participantes.</p> </li> <li> <p>Busca Sem\u00e2ntica com Embeddings    Emprega o modelo <code>bert-base-portuguese-cased</code>, da NeuralMind [4], para transformar os documentos e as consultas dos usu\u00e1rios em vetores densos. Isso permite capturar a sem\u00e2ntica dos textos, mesmo quando diferentes palavras s\u00e3o utilizadas para expressar o mesmo conceito \u2014 algo essencial para lidar com a linguagem informal e amb\u00edgua dos relatos policiais.</p> </li> <li> <p>Classifica\u00e7\u00e3o e Recupera\u00e7\u00e3o    Os vetores gerados s\u00e3o indexados em uma estrutura compat\u00edvel com o Elasticsearch, que permite buscas por similaridade de cosseno. Com isso, \u00e9 poss\u00edvel recuperar os relat\u00f3rios mais semanticamente pr\u00f3ximos \u00e0 consulta fornecida, mesmo na aus\u00eancia de termos exatos [5].</p> </li> </ol>"},{"location":"portfolio1/projetos/#propriedades-do-sistema","title":"Propriedades do Sistema","text":"Aspecto Classifica\u00e7\u00e3o Justificativa Tipo de Dados Texto livre (n\u00e3o estruturado) Relat\u00f3rios policiais com linguagem informal Escalabilidade Alta Grandes volumes de documentos hist\u00f3ricos Linguagem Variada Presen\u00e7a de g\u00edrias, siglas e inconsist\u00eancias Atualiza\u00e7\u00e3o Cont\u00ednua Inclus\u00e3o frequente de novos relatos"},{"location":"portfolio1/projetos/#exemplo-de-codigo-usando-elasticsearch-bert","title":"Exemplo de C\u00f3digo Usando Elasticsearch + BERT","text":"<pre><code>from elasticsearch import Elasticsearch\nfrom sentence_transformers import SentenceTransformer\n\nes = Elasticsearch(\"http://localhost:9200\")\nmodel = SentenceTransformer('neuralmind/bert-base-portuguese-cased')\n\ndef search_weapons(query, top_k=10):\n    query_embedding = model.encode(query)\n    script_query = {\n        \"script_score\": {\n            \"query\": {\"match_all\": {}},\n            \"script\": {\n                \"source\": \"cosineSimilarity(params.query_vector, 'doc_embedding') + 1.0\",\n                \"params\": {\"query_vector\": query_embedding.tolist()}\n            }\n        }\n    }\n    response = es.search(index=\"relatorios_policiais\", body={\"size\": top_k, \"query\": script_query})\n    return [hit[\"_source\"] for hit in response[\"hits\"][\"hits\"]]\n</code></pre>"},{"location":"portfolio1/projetos/#consideracoes-finais","title":"Considera\u00e7\u00f5es Finais","text":"<p>A aplica\u00e7\u00e3o de t\u00e9cnicas de intelig\u00eancia artificial para an\u00e1lise de documentos textuais n\u00e3o estruturados abre novas perspectivas para a seguran\u00e7a p\u00fablica. Estudos como os de Tompson et al. [1], Ara\u00fajo et al. [2] e Ladanavar et al. [3] mostram que j\u00e1 \u00e9 poss\u00edvel empregar modelos de linguagem como o BERT e motores de busca como o Elasticsearch para extrair conhecimento de relat\u00f3rios policiais.</p> <p>Embora desafios como ambiguidade lingu\u00edstica, regionalismos e limita\u00e7\u00f5es \u00e9ticas ainda precisem ser enfrentados, os resultados preliminares s\u00e3o promissores. O uso de ferramentas modernas permite construir solu\u00e7\u00f5es funcionais, escal\u00e1veis e alinhadas \u00e0s necessidades reais das autoridades policiais.</p>"},{"location":"portfolio1/projetos/#referencias-tecnicas","title":"Refer\u00eancias T\u00e9cnicas","text":"<p>[1] TOMPSON, L. et al. Unsupervised identification of crime problems from police free-text reports. Crime Science, [S.l.], v. 9, n. 1, p. 1\u201315, 2020. DOI: https://doi.org/10.1186/s40163-020-00127-4. Dispon\u00edvel em: https://link.springer.com/article/10.1186/s40163-020-00127-4. Acesso em: 7 maio 2025.</p> <p>[2] ARA\u00daJO, J. A. F. et al. Police Report Similarity Search: A Case Study. In: BRAZILIAN CONFERENCE ON INTELLIGENT SYSTEMS (BRACIS), 2023. Anais [...]. Porto Alegre: SBC, 2023. p. 394-409. Dispon\u00edvel em: https://sol.sbc.org.br/index.php/bracis/article/view/28428. Acesso em: 7 maio 2025.</p> <p>[3] LADANAVAR, S. M. et al. Enhancing User Query Comprehension and Contextual Relevance with a Semantic Search Engine using BERT and ElasticSearch. EAI Endorsed Transactions on Internet of Things, [S.l.], v. 10, 2024. DOI: https://doi.org/10.4108/eetiot.6993. Dispon\u00edvel em: https://publications.eai.eu/index.php/IoT/article/view/6993. Acesso em: 7 maio 2025.</p> <p>[4] NEURALMIND. BERTimbau: BERT pr\u00e9-treinado para o portugu\u00eas. 2020. Dispon\u00edvel em: https://github.com/neuralmind-ai/portuguese-bert. Acesso em: 07 maio 2025.</p> <p>[5] ELASTICSEARCH. Elasticsearch: The Definitive Guide. [S. l.]: Elastic, 2024. Dispon\u00edvel em: https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html. Acesso em: 07 maio 2025.</p>"},{"location":"portfolio1/projetos/#historico-de-versao","title":"Hist\u00f3rico de vers\u00e3o","text":"Vers\u00e3o Data Modifica\u00e7\u00e3o Nome GitHub <code>1.0</code> 06/05/2025 Cria\u00e7\u00e3o do documento Ana Beatriz Norberto @ananorberto"},{"location":"portfolio1/racionalidade/","title":"Racionalidade em Intelig\u00eancia Artificial","text":""},{"location":"portfolio1/racionalidade/#o-que-e-racionalidade","title":"O que \u00e9 Racionalidade?","text":"<p>A racionalidade em IA refere-se \u00e0 capacidade de um agente de tomar decis\u00f5es que maximizem sua medida de desempenho, dadas as informa\u00e7\u00f5es dispon\u00edveis.</p>"},{"location":"portfolio1/racionalidade/#tipos-de-racionalidade","title":"Tipos de Racionalidade","text":"<ul> <li>Racionalidade perfeita</li> <li>Racionalidade limitada</li> <li>Racionalidade local vs. global</li> </ul>"},{"location":"portfolio1/racionalidade/#medidas-de-desempenho","title":"Medidas de Desempenho","text":"<ul> <li>Crit\u00e9rios objetivos</li> <li>Fun\u00e7\u00f5es de utilidade</li> <li>M\u00e9tricas de avalia\u00e7\u00e3o</li> </ul>"},{"location":"portfolio1/racionalidade/#desafios-da-racionalidade","title":"Desafios da Racionalidade","text":"<ul> <li>Incerteza</li> <li>Complexidade computacional</li> <li>Limita\u00e7\u00f5es de recursos </li> </ul>"},{"location":"portfolio1/racionalidade/#historico-de-versao","title":"Hist\u00f3rico de vers\u00e3o","text":"Vers\u00e3o Data Modifica\u00e7\u00e3o Nome GitHub <code>1.0</code> 05/05/2025 Cria\u00e7\u00e3o do documento Ana Beatriz Norberto @ananorberto"},{"location":"portfolio2/2conceitos/","title":"Conceitos","text":""},{"location":"portfolio2/2conceitos/#2-apresentacao-dos-conceitos-principais","title":"2. Apresenta\u00e7\u00e3o dos Conceitos Principais","text":"<p>A abordagem de resolu\u00e7\u00e3o de problemas por busca se baseia na ideia de que um agente pode adotar um objetivo e trabalhar para satisfaz\u00ea-lo. Um agente de solu\u00e7\u00e3o de problemas \u00e9 um tipo de agente baseado em objetivos.</p> <p>Os principais conceitos envolvidos s\u00e3o:</p> <ul> <li>Formula\u00e7\u00e3o de Objetivo: O agente adota um ou mais objetivos que deseja alcan\u00e7ar.</li> <li>Formula\u00e7\u00e3o de Problema: O agente descreve os estados poss\u00edveis do \"mundo\" e as a\u00e7\u00f5es que pode realizar para transitar entre esses estados, visando atingir o objetivo. Estados do mundo podem ser considerados como totalidades sem estrutura interna vis\u00edvel (representa\u00e7\u00e3o at\u00f4mica), que \u00e9 a representa\u00e7\u00e3o considerada na busca b\u00e1sica.</li> <li>Espa\u00e7o de Estados (State Space): \u00c9 uma representa\u00e7\u00e3o formal do problema. \u00c9 definido por uma qu\u00e1drupla <code>[N, A, S, GD]</code>, onde:<ul> <li><code>N</code> \u00e9 o conjunto de n\u00f3s ou estados do grafo, correspondendo aos estados no processo de resolu\u00e7\u00e3o do problema.</li> <li><code>A</code> \u00e9 o conjunto de arcos que conectam pares de n\u00f3s, representando conex\u00f5es diretas ou a\u00e7\u00f5es que levam de um estado a outro.</li> <li><code>S</code> \u00e9 o estado inicial.</li> <li><code>GD</code> \u00e9 a descri\u00e7\u00e3o dos estados objetivo, ou seja, a condi\u00e7\u00e3o que define que o problema foi resolvido. Uma solu\u00e7\u00e3o para um problema \u00e9 representada como um caminho no grafo do estado inicial a um estado objetivo.</li> </ul> </li> <li>Busca (Search): Antes de agir, o agente simula sequ\u00eancias de a\u00e7\u00f5es em seu modelo (o espa\u00e7o de estados) para encontrar um caminho que leve ao objetivo. Isso envolve testar sistematicamente caminhos alternativos.</li> <li>Execu\u00e7\u00e3o: Uma vez encontrado um caminho (solu\u00e7\u00e3o) pela busca, o agente executa as a\u00e7\u00f5es correspondentes no ambiente real.</li> <li>Agentes de Solu\u00e7\u00e3o de Problemas: S\u00e3o agentes baseados em objetivos que utilizam a busca em representa\u00e7\u00f5es at\u00f4micas de estados para encontrar solu\u00e7\u00f5es.</li> <li>Estrat\u00e9gias de Busca: S\u00e3o os algoritmos usados para explorar o espa\u00e7o de estados. Elas podem ser:<ul> <li>Busca Cega (Uninformed Search): Algoritmos que n\u00e3o utilizam nenhuma informa\u00e7\u00e3o sobre o qu\u00e3o pr\u00f3ximo um estado est\u00e1 do(s) objetivo(s) al\u00e9m da defini\u00e7\u00e3o do problema.</li> <li>Busca Informada (Informed Search): Algoritmos que utilizam dicas espec\u00edficas do dom\u00ednio (heur\u00edsticas) sobre a localiza\u00e7\u00e3o dos objetivos para guiar a busca de forma mais eficiente.</li> </ul> </li> <li>Heur\u00edsticas: S\u00e3o fun\u00e7\u00f5es, denotadas como <code>h(n)</code>, que fornecem uma estimativa do custo do caminho mais econ\u00f4mico do estado no n\u00f3 <code>n</code> para um estado objetivo. Elas s\u00e3o informa\u00e7\u00f5es espec\u00edficas do dom\u00ednio que podem melhorar significativamente a efici\u00eancia da busca.</li> <li>Medidas de Performance: Crit\u00e9rios para avaliar algoritmos de busca:<ul> <li>Completude (Completeness): O algoritmo garante encontrar uma solu\u00e7\u00e3o quando existe uma, ou reportar a falha corretamente.</li> <li>Otimiza\u00e7\u00e3o de Custos (Cost Optimization): O algoritmo garante encontrar a solu\u00e7\u00e3o com o menor custo.</li> <li>Complexidade de Tempo (Time Complexity): Quanto tempo leva para encontrar a solu\u00e7\u00e3o.</li> <li>Complexidade de Espa\u00e7o (Space Complexity): Quanta mem\u00f3ria \u00e9 necess\u00e1ria para a busca.</li> </ul> </li> <li>Filas: Estruturas de dados usadas para gerenciar a ordem em que os n\u00f3s s\u00e3o explorados pelos algoritmos de busca: fila FIFO (First-In, First-Out) para busca em largura, pilha LIFO (Last-In, First-Out) para busca em profundidade, e fila de prioridade para busca best-first. O uso dessas estruturas permite que os algoritmos explorem estados n\u00e3o testados (lista open) e evitem repetir caminhos infrut\u00edferos (lista closed).</li> </ul>"},{"location":"portfolio2/2conceitos/#21-discussao-peas-para-problema-de-navegacao-robotica","title":"2.1 Discuss\u00e3o PEAS para Problema de Navega\u00e7\u00e3o Rob\u00f3tica","text":"<p>Para ilustrar a aplica\u00e7\u00e3o do modelo PEAS (Performance, Environment, Actuators, Sensors) na resolu\u00e7\u00e3o de problemas por busca, analisaremos o caso de um rob\u00f4 de navega\u00e7\u00e3o em um ambiente de armaz\u00e9m:</p> <p>Performance (Medida de Desempenho): - Minimizar o tempo total para encontrar e transportar itens - Minimizar o consumo de energia - Evitar colis\u00f5es com obst\u00e1culos e outros rob\u00f4s - Completar todas as tarefas de coleta na ordem correta</p> <p>Environment (Ambiente): - Armaz\u00e9m com corredores, prateleiras e \u00e1reas de carga/descarga - Obst\u00e1culos fixos (paredes, prateleiras) e din\u00e2micos (outros rob\u00f4s, trabalhadores) - Superf\u00edcie plana com poss\u00edveis rampas ou elevadores - Condi\u00e7\u00f5es de ilumina\u00e7\u00e3o vari\u00e1veis</p> <p>Actuators (Atuadores): - Motores para movimenta\u00e7\u00e3o (frente, tr\u00e1s, rota\u00e7\u00e3o) - Bra\u00e7o rob\u00f3tico para pegar itens - Sinalizadores visuais e sonoros - Sistema de frenagem</p> <p>Sensors (Sensores): - C\u00e2meras para reconhecimento de objetos e leitura de c\u00f3digos - Sensores de proximidade (ultrass\u00f4nicos, infravermelhos) - GPS interno ou sistema de localiza\u00e7\u00e3o baseado em marcadores - Sensores de velocidade e acelera\u00e7\u00e3o - Sensores de carga da bateria</p>"},{"location":"portfolio2/2conceitos/#22-descricao-do-ambiente-do-problema","title":"2.2 Descri\u00e7\u00e3o do Ambiente do Problema","text":"<p>O ambiente de navega\u00e7\u00e3o rob\u00f3tica em um armaz\u00e9m possui as seguintes propriedades:</p> <ul> <li>Observ\u00e1vel parcialmente: O rob\u00f4 s\u00f3 consegue perceber o que est\u00e1 em seu campo de vis\u00e3o imediato.</li> <li>Determin\u00edstico: As a\u00e7\u00f5es do rob\u00f4 t\u00eam resultados previs\u00edveis.</li> <li>Sequencial: Decis\u00f5es anteriores afetam estados futuros e op\u00e7\u00f5es dispon\u00edveis.</li> <li>Din\u00e2mico: O ambiente pode mudar enquanto o rob\u00f4 opera (outros rob\u00f4s, trabalhadores).</li> <li>Cont\u00ednuo: Posi\u00e7\u00e3o e velocidade variam continuamente, embora possam ser discretizadas para simplifica\u00e7\u00e3o.</li> <li>Multi-agente: M\u00faltiplos rob\u00f4s podem estar operando simultaneamente no mesmo ambiente.</li> </ul> <p>Compreender estas propriedades \u00e9 fundamental para escolher os algoritmos de busca adequados. Por exemplo, a natureza parcialmente observ\u00e1vel do ambiente pode exigir replaneamento frequente, enquanto sua natureza din\u00e2mica pode favorecer algoritmos que possam se adaptar rapidamente a mudan\u00e7as.</p>"},{"location":"portfolio2/2conceitos/#referencias-bibliograficas","title":"Refer\u00eancias Bibliogr\u00e1ficas","text":"<p>RUSSELL, S. J.; NORVIG, P. Intelig\u00eancia artificial. 3. ed. Rio de Janeiro: Elsevier Campus, 2013.</p> <p>CORMEN, T. H.; LEISERSON, C. E.; RIVEST, R. L.; STEIN, C. Introduction to Algorithms. 3. ed. Cambridge: MIT Press, 2009.</p> <p>KORF, R. E. Depth-first iterative-deepening: An optimal admissible tree search. Artificial Intelligence, v. 27, n. 1, p. 97-109, 1985.</p> <p>HART, P. E.; NILSSON, N. J.; RAPHAEL, B. A formal basis for the heuristic determination of minimum cost paths. IEEE Transactions on Systems Science and Cybernetics, v. 4, n. 2, p. 100-107, 1968.</p> <p>KIRKPATRICK, S.; GELATT, C. D.; VECCHI, M. P. Optimization by simulated annealing. Science, v. 220, n. 4598, p. 671-680, 1983.</p> <p>HOLLAND, J. H. Adaptation in Natural and Artificial Systems. Ann Arbor: University of Michigan Press, 1975.</p> <p>KOZA, J. R. Genetic Programming: On the Programming of Computers by Means of Natural Selection. Cambridge: MIT Press, 1992.</p> <p>SILVER, D. et al. Mastering the game of Go with deep neural networks and tree search. Nature, v. 529, n. 7587, p. 484-489, 2016.</p> <p>THRUN, S.; BURGARD, W.; FOX, D. Probabilistic Robotics. Cambridge: MIT Press, 2005.</p> <p>LAVALLE, S. M. Planning Algorithms. Cambridge: Cambridge University Press, 2006.</p> Vers\u00e3o Data Modifica\u00e7\u00e3o Nome GitHub <code>1.0</code> 27/05/2025 Cria\u00e7\u00e3o do documento Ana Beatriz Norberto @ananorberto"},{"location":"portfolio2/3algoritmos/","title":"Algoritmos","text":""},{"location":"portfolio2/3algoritmos/#3-analise-de-algoritmos-de-busca","title":"3. An\u00e1lise de Algoritmos de Busca","text":""},{"location":"portfolio2/3algoritmos/#31-algoritmos-de-busca-cega-uninformed-search","title":"3.1 Algoritmos de Busca Cega (Uninformed Search)","text":"<p>Quando falamos de algoritmos de busca cega (ou n\u00e3o informada), estamos nos referindo \u00e0queles que exploram o espa\u00e7o de estados sem ter nenhuma pista sobre qu\u00e3o pr\u00f3ximos estamos do objetivo. \u00c9 como tentar encontrar um caminho no escuro. Os principais tipos s\u00e3o:</p> <ul> <li>Busca em Largura (Breadth-First Search - BFS): Expande sistematicamente os n\u00f3s mais rasos e n\u00e3o expandidos primeiro. Garante encontrar a solu\u00e7\u00e3o mais rasa (\u00f3tima em termos de n\u00famero de passos se os custos forem uniformes), mas pode exigir muita mem\u00f3ria.</li> <li>Busca de Custo Uniforme (Uniform-Cost Search - UCS): Expande o n\u00f3 n\u00e3o expandido com o menor custo de caminho acumulado (<code>g(n)</code>). \u00c9 \u00f3tima e completa, desde que os custos dos passos sejam n\u00e3o negativos. \u00c9 essencialmente uma generaliza\u00e7\u00e3o da BFS para custos de passo vari\u00e1veis.</li> <li>Busca em Profundidade (Depth-First Search - DFS): Expande sempre o n\u00f3 mais profundo na fronteira da \u00e1rvore de busca. Usa menos mem\u00f3ria que a BFS (ordem linear em rela\u00e7\u00e3o \u00e0 profundidade m\u00e1xima), mas n\u00e3o \u00e9 completa (pode se perder em caminhos infinitos) nem \u00f3tima por si s\u00f3.</li> <li>Busca com Aprofundamento Iterativo (Iterative Deepening Depth-First Search - IDDFS ou IDS): Combina os benef\u00edcios da BFS (completude e otimalidade para custos uniformes) e da DFS (requisitos modestos de mem\u00f3ria). Realiza buscas em profundidade com limites de profundidade crescentes (1, 2, 3, ...), at\u00e9 encontrar a solu\u00e7\u00e3o. Embora pare\u00e7a redundante por repetir expans\u00f5es, \u00e9 geralmente o m\u00e9todo de busca cega preferido quando o espa\u00e7o de busca \u00e9 grande e a profundidade da solu\u00e7\u00e3o \u00e9 desconhecida.</li> <li>Busca Bidirecional (Bidirectional Search): Executa duas buscas simult\u00e2neas, uma partindo do estado inicial e outra partindo do estado objetivo (se as a\u00e7\u00f5es forem revers\u00edveis), parando quando as duas buscas se encontram no meio. Pode reduzir drasticamente a complexidade de tempo e espa\u00e7o, explorando uma \u00e1rea muito menor do espa\u00e7o de estados em compara\u00e7\u00e3o com buscas unidirecionais.</li> </ul>"},{"location":"portfolio2/3algoritmos/#311-implementacao-da-busca-bidirecional","title":"3.1.1 Implementa\u00e7\u00e3o da Busca Bidirecional","text":"<p>A Busca Bidirecional \u00e9 uma t\u00e9cnica poderosa que executa duas buscas simult\u00e2neas - uma partindo do estado inicial e outra do estado objetivo - at\u00e9 que os dois caminhos se encontrem. Esta abordagem pode reduzir significativamente o espa\u00e7o de busca explorado, especialmente em grafos grandes.</p> Implementa\u00e7\u00e3o da Busca Bidirecional <pre><code>from collections import deque\n\ndef busca_bidirecional(grafo, inicio, objetivo):\n    \"\"\"\n    Implementa\u00e7\u00e3o da Busca Bidirecional para encontrar o caminho mais curto\n    entre os n\u00f3s 'inicio' e 'objetivo' em um grafo.\n\n    Args:\n        grafo: Dicion\u00e1rio onde as chaves s\u00e3o n\u00f3s e os valores s\u00e3o listas de vizinhos\n        inicio: N\u00f3 inicial\n        objetivo: N\u00f3 objetivo\n\n    Returns:\n        O caminho mais curto, ou None se n\u00e3o existir\n    \"\"\"\n    # Verifica se o grafo \u00e9 bidirecional (todos os caminhos s\u00e3o revers\u00edveis)\n    if not verificar_bidirecional(grafo):\n        print(\"Aviso: O grafo n\u00e3o \u00e9 bidirecional. A busca bidirecional pode n\u00e3o funcionar corretamente.\")\n\n    # Inicializa as filas para busca em ambas as dire\u00e7\u00f5es\n    fila_inicio = deque([(inicio, [inicio])])  # (n\u00f3 atual, caminho at\u00e9 o n\u00f3)\n    fila_objetivo = deque([(objetivo, [objetivo])])\n\n    # Conjuntos para rastrear n\u00f3s visitados em cada dire\u00e7\u00e3o\n    visitados_inicio = {inicio: [inicio]}  # n\u00f3: caminho\n    visitados_objetivo = {objetivo: [objetivo]}\n\n    # Contadores para an\u00e1lise de desempenho\n    nos_expandidos = 0\n\n    print(f\"Iniciando Busca Bidirecional de {inicio} para {objetivo}\")\n\n    while fila_inicio and fila_objetivo:\n        # Expande um n\u00edvel da busca a partir do in\u00edcio\n        nos_expandidos += expandir_nivel(grafo, fila_inicio, visitados_inicio, visitados_objetivo, \"in\u00edcio\")\n\n        # Expande um n\u00edvel da busca a partir do objetivo\n        nos_expandidos += expandir_nivel(grafo, fila_objetivo, visitados_objetivo, visitados_inicio, \"objetivo\")\n\n    print(f\"N\u00e3o foi poss\u00edvel encontrar um caminho at\u00e9 {objetivo}\")\n    print(f\"Total de n\u00f3s expandidos: {nos_expandidos}\")\n    return None\n\ndef expandir_nivel(grafo, fila, visitados_atual, visitados_outro, direcao):\n    \"\"\"\n    Expande um n\u00edvel da busca em uma dire\u00e7\u00e3o.\n\n    Args:\n        grafo: O grafo do problema\n        fila: A fila de busca atual\n        visitados_atual: Dicion\u00e1rio de n\u00f3s visitados na dire\u00e7\u00e3o atual\n        visitados_outro: Dicion\u00e1rio de n\u00f3s visitados na outra dire\u00e7\u00e3o\n        direcao: String indicando a dire\u00e7\u00e3o (\"in\u00edcio\" ou \"objetivo\")\n\n    Returns:\n        N\u00famero de n\u00f3s expandidos\n    \"\"\"\n    if not fila:\n        return 0\n\n    nos_expandidos = 0\n    tamanho_nivel = len(fila)\n\n    for _ in range(tamanho_nivel):\n        no_atual, caminho_atual = fila.popleft()\n        nos_expandidos += 1\n\n        print(f\"Expandindo n\u00f3 {no_atual} na dire\u00e7\u00e3o {direcao}\")\n\n        # Verifica se encontramos um caminho comum\n        if no_atual in visitados_outro:\n            caminho_outro = visitados_outro[no_atual]\n            if direcao == \"in\u00edcio\":\n                caminho_completo = caminho_atual + caminho_outro[::-1][1:]\n            else:\n                caminho_completo = caminho_outro + caminho_atual[::-1][1:]\n\n            print(f\"Caminho encontrado! N\u00f3 de encontro: {no_atual}\")\n            print(f\"Caminho completo: {caminho_completo}\")\n            print(f\"Total de n\u00f3s expandidos: {nos_expandidos}\")\n            return caminho_completo\n\n        # Expande os vizinhos\n        for vizinho in grafo.get(no_atual, []):\n            if vizinho not in visitados_atual:\n                novo_caminho = caminho_atual + [vizinho]\n                visitados_atual[vizinho] = novo_caminho\n                fila.append((vizinho, novo_caminho))\n                print(f\"  Adicionando vizinho {vizinho} \u00e0 fila {direcao}\")\n\n    return nos_expandidos\n\ndef verificar_bidirecional(grafo):\n    \"\"\"\n    Verifica se o grafo \u00e9 bidirecional (todos os caminhos s\u00e3o revers\u00edveis).\n\n    Args:\n        grafo: O grafo a ser verificado\n\n    Returns:\n        True se o grafo for bidirecional, False caso contr\u00e1rio\n    \"\"\"\n    for no, vizinhos in grafo.items():\n        for vizinho in vizinhos:\n            if no not in grafo.get(vizinho, []):\n                return False\n    return True\n\n# Exemplo de uso\nif __name__ == \"__main__\":\n    # Grafo representando um mapa simples\n    mapa = {\n        'A': ['B', 'C'],\n        'B': ['A', 'D', 'E'],\n        'C': ['A', 'F'],\n        'D': ['B'],\n        'E': ['B', 'F'],\n        'F': ['C', 'E']\n    }\n\n    # Busca um caminho de A at\u00e9 F\n    caminho = busca_bidirecional(mapa, 'A', 'F')\n\n    if caminho:\n        print(f\"Caminho encontrado: {' -&gt; '.join(caminho)}\")\n    else:\n        print(\"N\u00e3o existe caminho entre os pontos especificados.\")\n</code></pre>"},{"location":"portfolio2/3algoritmos/#32-algoritmos-de-busca-informada-heuristica","title":"3.2 Algoritmos de Busca Informada (Heur\u00edstica)","text":"<p>Os algoritmos de busca informada, ou busca heur\u00edstica, utilizam conhecimento espec\u00edfico do problema, na forma de uma fun\u00e7\u00e3o heur\u00edstica <code>h(n)</code>, para estimar a dist\u00e2ncia (ou custo) de um estado <code>n</code> at\u00e9 o objetivo. Essa informa\u00e7\u00e3o guia a busca de forma mais eficiente, priorizando caminhos que parecem mais promissores. Russell e Norvig (2013) destacam as seguintes abordagens:</p> <ul> <li>Busca Best-First Gen\u00e9rica (Generic Best-First Search): \u00c9 um paradigma de busca que seleciona o pr\u00f3ximo n\u00f3 a ser expandido com base em uma fun\u00e7\u00e3o de avalia\u00e7\u00e3o <code>f(n)</code>. Diferentes algoritmos best-first surgem da escolha de diferentes fun\u00e7\u00f5es <code>f</code>.</li> <li>Busca Best-First Gulosa (Greedy Best-First Search): Uma inst\u00e2ncia da busca best-first que tenta expandir o n\u00f3 que est\u00e1 estimado como o mais pr\u00f3ximo do objetivo, usando a fun\u00e7\u00e3o heur\u00edstica diretamente como fun\u00e7\u00e3o de avalia\u00e7\u00e3o: <code>f(n) = h(n)</code>. Embora possa ser r\u00e1pida, n\u00e3o \u00e9 \u00f3tima nem completa.</li> <li>Busca A (A Search): Considerado o algoritmo de busca heur\u00edstica mais conhecido, A combina o custo do caminho percorrido desde o in\u00edcio (<code>g(n)</code>) com a estimativa heur\u00edstica do custo restante at\u00e9 o objetivo (<code>h(n)</code>), utilizando a fun\u00e7\u00e3o de avalia\u00e7\u00e3o <code>f(n) = g(n) + h(n)</code>. A \u00e9 completo e \u00f3timo, desde que a heur\u00edstica <code>h(n)</code> seja admiss\u00edvel (nunca superestima o custo real) e, para efici\u00eancia \u00f3tima, consistente. \u00c9 amplamente utilizado em problemas de planejamento de caminhos e outros.</li> <li>Buscas Heur\u00edsticas com Mem\u00f3ria Limitada: Como A* pode consumir muita mem\u00f3ria, foram desenvolvidas variantes que operam com restri\u00e7\u00f5es de espa\u00e7o:<ul> <li>Busca Recursiva Best-First (Recursive Best-First Search - RBFS): Simula a opera\u00e7\u00e3o de A* usando apenas espa\u00e7o linear. Faz isso explorando um caminho e mantendo o valor <code>f</code> do melhor caminho alternativo a partir de seus ancestrais. Se o custo do caminho atual exceder esse valor limite, ele retrocede e explora o caminho alternativo. Pode sofrer de recomputa\u00e7\u00e3o excessiva.</li> <li>SMA (Simplified Memory-Bounded A): Utiliza toda a mem\u00f3ria dispon\u00edvel. Expande os melhores n\u00f3s folha at\u00e9 que a mem\u00f3ria esteja cheia. Nesse ponto, remove o n\u00f3 folha com o maior valor <code>f</code> (o pior) para liberar espa\u00e7o para um novo n\u00f3. \u00c9 completo se houver mem\u00f3ria suficiente para armazenar o caminho da solu\u00e7\u00e3o mais rasa e \u00f3timo se encontrar uma solu\u00e7\u00e3o.</li> </ul> </li> <li>Aprendizado de Heur\u00edsticas (Learning Heuristics): Abordagens onde a fun\u00e7\u00e3o heur\u00edstica n\u00e3o \u00e9 dada a priori, mas aprendida a partir da experi\u00eancia ou de exemplos do problema, como resolver subproblemas mais simples (bases de dados de padr\u00f5es) ou atrav\u00e9s de aprendizado indutivo.</li> </ul>"},{"location":"portfolio2/3algoritmos/#321-implementacao-da-greedy-best-first-search","title":"3.2.1 Implementa\u00e7\u00e3o da Greedy Best-First Search","text":"<p>A Greedy Best-First Search \u00e9 um algoritmo de busca informada que utiliza apenas a fun\u00e7\u00e3o heur\u00edstica para guiar a busca, sempre escolhendo expandir o n\u00f3 que parece estar mais pr\u00f3ximo do objetivo. Diferente do A*, ela n\u00e3o considera o custo do caminho j\u00e1 percorrido.</p> Implementa\u00e7\u00e3o da Greedy Best-First Search <pre><code>import heapq\n\ndef busca_gulosa(grafo, inicio, objetivo, heuristica):\n    \"\"\"\n    Implementa\u00e7\u00e3o da Greedy Best-First Search para encontrar um caminho\n    entre os n\u00f3s 'inicio' e 'objetivo' em um grafo, usando uma fun\u00e7\u00e3o heur\u00edstica.\n\n    Args:\n        grafo: Dicion\u00e1rio onde as chaves s\u00e3o n\u00f3s e os valores s\u00e3o dicion\u00e1rios\n               de vizinhos com seus respectivos custos {vizinho: custo}\n        inicio: N\u00f3 inicial\n        objetivo: N\u00f3 objetivo\n        heuristica: Fun\u00e7\u00e3o que estima a dist\u00e2ncia de um n\u00f3 at\u00e9 o objetivo\n\n    Returns:\n        O caminho encontrado, ou None se n\u00e3o existir\n    \"\"\"\n    # Fila de prioridade para os n\u00f3s a serem expandidos\n    # Formato: (valor_heuristico, contador, n\u00f3, caminho)\n    # contador \u00e9 usado para desempate quando valores heur\u00edsticos s\u00e3o iguais\n    fila_prioridade = [(heuristica(inicio, objetivo), 0, inicio, [inicio])]\n\n    # Conjunto para rastrear n\u00f3s visitados\n    visitados = set([inicio])\n\n    # Contador para desempate e para rastrear n\u00f3s expandidos\n    contador = 1\n    nos_expandidos = 0\n\n    print(f\"Iniciando Busca Gulosa a partir de {inicio}, buscando {objetivo}\")\n    print(f\"Valor heur\u00edstico inicial: h({inicio}) = {heuristica(inicio, objetivo)}\")\n\n    while fila_prioridade:\n        # Retira o n\u00f3 com menor valor heur\u00edstico\n        _, _, no_atual, caminho = heapq.heappop(fila_prioridade)\n        nos_expandidos += 1\n\n        print(f\"Expandindo n\u00f3: {no_atual}, Caminho at\u00e9 aqui: {caminho}\")\n\n        # Verifica se chegamos ao objetivo\n        if no_atual == objetivo:\n            print(f\"Objetivo encontrado! Caminho: {caminho}\")\n            print(f\"Total de n\u00f3s expandidos: {nos_expandidos}\")\n            return caminho\n\n        # Explora todos os vizinhos n\u00e3o visitados\n        for vizinho in grafo.get(no_atual, {}).keys():\n            if vizinho not in visitados:\n                # Marca como visitado\n                visitados.add(vizinho)\n\n                # Calcula o valor heur\u00edstico do vizinho\n                h_valor = heuristica(vizinho, objetivo)\n\n                # Adiciona \u00e0 fila de prioridade\n                novo_caminho = caminho + [vizinho]\n                heapq.heappush(fila_prioridade, (h_valor, contador, vizinho, novo_caminho))\n                contador += 1\n\n                print(f\"  Adicionando vizinho {vizinho} \u00e0 fila, h={h_valor}\")\n\n    # Se a fila esvaziar sem encontrar o objetivo, n\u00e3o h\u00e1 caminho\n    print(f\"N\u00e3o foi poss\u00edvel encontrar um caminho at\u00e9 {objetivo}\")\n    print(f\"Total de n\u00f3s expandidos: {nos_expandidos}\")\n    return None\n\n# Fun\u00e7\u00e3o heur\u00edstica de exemplo: dist\u00e2ncia Manhattan em uma grade 2D\ndef distancia_manhattan(ponto1, ponto2):\n    \"\"\"\n    Calcula a dist\u00e2ncia Manhattan entre dois pontos em uma grade 2D.\n    Assume que os pontos s\u00e3o representados como strings 'x,y'.\n    \"\"\"\n    x1, y1 = map(int, ponto1.split(','))\n    x2, y2 = map(int, ponto2.split(','))\n    return abs(x1 - x2) + abs(y1 - y2)\n\n# Exemplo de uso\nif __name__ == \"__main__\":\n    # Grafo representando uma grade 2D com obst\u00e1culos\n    # Formato: {n\u00f3: {vizinho1: custo1, vizinho2: custo2, ...}}\n    grade = {\n        '0,0': {'1,0': 1, '0,1': 1},\n        '0,1': {'0,0': 1, '0,2': 1, '1,1': 1},\n        '0,2': {'0,1': 1, '1,2': 1},\n        '1,0': {'0,0': 1, '2,0': 1, '1,1': 1},\n        '1,1': {'0,1': 1, '1,0': 1, '1,2': 1, '2,1': 1},\n        '1,2': {'0,2': 1, '1,1': 1, '2,2': 1},\n        '2,0': {'1,0': 1, '3,0': 1, '2,1': 1},\n        '2,1': {'1,1': 1, '2,0': 1, '2,2': 1, '3,1': 1},\n        '2,2': {'1,2': 1, '2,1': 1, '3,2': 1},\n        '3,0': {'2,0': 1, '3,1': 1},\n        '3,1': {'3,0': 1, '2,1': 1, '3,2': 1},\n        '3,2': {'3,1': 1, '2,2': 1}\n    }\n\n    # Busca um caminho de (0,0) at\u00e9 (3,2)\n    caminho = busca_gulosa(grade, '0,0', '3,2', distancia_manhattan)\n\n    if caminho:\n        print(f\"Caminho encontrado: {' -&gt; '.join(caminho)}\")\n    else:\n        print(\"N\u00e3o existe caminho entre os pontos especificados.\")\n</code></pre>"},{"location":"portfolio2/3algoritmos/#33-algoritmos-de-busca-em-ambientes-complexos","title":"3.3 Algoritmos de Busca em Ambientes Complexos","text":"<p>Ambientes complexos apresentam desafios adicionais em rela\u00e7\u00e3o \u00e0 busca cl\u00e1ssica, como a necessidade de otimizar uma fun\u00e7\u00e3o objetivo sem se preocupar com o caminho, lidar com m\u00faltiplos agentes com objetivos conflitantes, agir sob incerteza ou com informa\u00e7\u00f5es parciais. Russell e Norvig (2013) abordam diversas t\u00e9cnicas para esses cen\u00e1rios:</p> <ul> <li>Busca Local (Local Search): Utilizada principalmente em problemas de otimiza\u00e7\u00e3o, onde o objetivo \u00e9 encontrar o estado com o melhor valor de uma fun\u00e7\u00e3o objetivo, e o caminho at\u00e9 ele n\u00e3o importa. Esses algoritmos mant\u00eam apenas um estado atual (ou um pequeno conjunto) e tentam melhor\u00e1-lo movendo-se para estados vizinhos.<ul> <li>Subida de Encosta (Hill Climbing): Move-se continuamente em dire\u00e7\u00e3o a um valor crescente da fun\u00e7\u00e3o objetivo. \u00c9 simples e eficiente em mem\u00f3ria, mas suscet\u00edvel a m\u00e1ximos locais, plat\u00f4s e cumeeiras.</li> <li>Subida de Encosta com Rein\u00edcio Aleat\u00f3rio (Random-Restart Hill Climbing): Executa a subida de encosta m\u00faltiplas vezes a partir de estados iniciais aleat\u00f3rios para aumentar a chance de encontrar o \u00f3timo global.</li> <li>Recozimento Simulado (Simulated Annealing): Permite movimentos para estados piores com uma probabilidade que diminui ao longo do tempo (controlada por uma \"temperatura\"), ajudando a escapar de m\u00e1ximos locais.</li> <li>Busca de Feixe Local (Local Beam Search): Mant\u00e9m <code>k</code> estados em paralelo. Em cada passo, gera todos os sucessores dos <code>k</code> estados e seleciona os <code>k</code> melhores sucessores para a pr\u00f3xima itera\u00e7\u00e3o. \u00c9 menos suscet\u00edvel a m\u00e1ximos locais que a subida de encosta simples.</li> <li>Busca de Feixe Local Estoc\u00e1stica (Stochastic Beam Search): Similar \u00e0 busca de feixe local, mas escolhe os <code>k</code> sucessores com probabilidade proporcional \u00e0 sua qualidade, introduzindo aleatoriedade.</li> </ul> </li> </ul>"},{"location":"portfolio2/3algoritmos/#331-implementacao-da-busca-de-feixe-local-estocastica-stochastic-beam-search","title":"3.3.1 Implementa\u00e7\u00e3o da Busca de Feixe Local Estoc\u00e1stica (Stochastic Beam Search)","text":"<p>A Busca de Feixe Local Estoc\u00e1stica \u00e9 uma varia\u00e7\u00e3o da busca de feixe local que introduz aleatoriedade na sele\u00e7\u00e3o dos sucessores. Em vez de sempre escolher os k melhores sucessores, ela seleciona k sucessores com probabilidade proporcional \u00e0 sua qualidade, o que ajuda a escapar de m\u00e1ximos locais.</p> Implementa\u00e7\u00e3o da Busca de Feixe Local Estoc\u00e1stica <pre><code>import random\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef busca_feixe_estocastica(funcao_objetivo, estado_inicial, gerar_vizinhos, k=3, max_iteracoes=1000):\n    \"\"\"\n    Implementa\u00e7\u00e3o da Busca de Feixe Local Estoc\u00e1stica para maximiza\u00e7\u00e3o.\n\n    Args:\n        funcao_objetivo: Fun\u00e7\u00e3o que avalia a qualidade de um estado\n        estado_inicial: Estado a partir do qual iniciar a busca\n        gerar_vizinhos: Fun\u00e7\u00e3o que gera estados vizinhos de um estado dado\n        k: N\u00famero de estados a manter em cada itera\u00e7\u00e3o (tamanho do feixe)\n        max_iteracoes: N\u00famero m\u00e1ximo de itera\u00e7\u00f5es permitidas\n\n    Returns:\n        Tupla (melhor_estado, melhor_valor, historico)\n    \"\"\"\n    # Inicializa o feixe com k c\u00f3pias do estado inicial\n    feixe = [estado_inicial] * k\n    valores = [funcao_objetivo(estado) for estado in feixe]\n\n    # Para rastrear o melhor estado encontrado\n    melhor_estado = estado_inicial\n    melhor_valor = funcao_objetivo(estado_inicial)\n\n    # Para visualiza\u00e7\u00e3o do progresso\n    historico = [(estado_inicial, melhor_valor)]\n\n    print(f\"Iniciando Busca de Feixe Estoc\u00e1stica com k={k}\")\n    print(f\"Estado inicial: {estado_inicial}, Valor: {melhor_valor}\")\n\n    for i in range(max_iteracoes):\n        # Gera todos os sucessores poss\u00edveis\n        todos_sucessores = []\n        for estado in feixe:\n            sucessores = gerar_vizinhos(estado)\n            todos_sucessores.extend(sucessores)\n\n        # Avalia todos os sucessores\n        valores_sucessores = [funcao_objetivo(s) for s in todos_sucessores]\n\n        # Normaliza os valores para usar como probabilidades\n        valores_norm = np.array(valores_sucessores)\n        valores_norm = valores_norm - np.min(valores_norm) + 1e-10  # Evita valores negativos\n        probabilidades = valores_norm / np.sum(valores_norm)\n\n        # Seleciona k sucessores estocasticamente\n        indices_selecionados = np.random.choice(\n            len(todos_sucessores),\n            size=k,\n            p=probabilidades,\n            replace=False\n        )\n\n        # Atualiza o feixe\n        feixe = [todos_sucessores[idx] for idx in indices_selecionados]\n        valores = [valores_sucessores[idx] for idx in indices_selecionados]\n\n        # Atualiza o melhor estado encontrado\n        max_valor = max(valores)\n        if max_valor &gt; melhor_valor:\n            melhor_valor = max_valor\n            melhor_estado = feixe[valores.index(max_valor)]\n            print(f\"Itera\u00e7\u00e3o {i+1}: Novo melhor valor encontrado: {melhor_valor}\")\n\n        # Registra o progresso\n        historico.append((melhor_estado, melhor_valor))\n\n        # Verifica converg\u00eancia\n        if len(set(map(tuple, feixe))) == 1:\n            print(f\"Converg\u00eancia atingida ap\u00f3s {i+1} itera\u00e7\u00f5es!\")\n            break\n\n    print(f\"\\nResultado final:\")\n    print(f\"Melhor estado: {melhor_estado}\")\n    print(f\"Melhor valor: {melhor_valor}\")\n\n    return melhor_estado, melhor_valor, historico\n\n# Exemplo: Encontrar o m\u00e1ximo da fun\u00e7\u00e3o f(x,y) = -(x^2 + y^2) + 4\n# O m\u00e1ximo global est\u00e1 em (0,0) com valor 4\n\ndef funcao_objetivo(ponto):\n    \"\"\"Fun\u00e7\u00e3o objetivo a ser maximizada: f(x,y) = -(x^2 + y^2) + 4\"\"\"\n    x, y = ponto\n    return -(x**2 + y**2) + 4\n\ndef gerar_vizinhos(ponto, passo=0.1):\n    \"\"\"Gera pontos vizinhos em uma grade 2D\"\"\"\n    x, y = ponto\n    vizinhos = [\n        (x + passo, y),\n        (x - passo, y),\n        (x, y + passo),\n        (x, y - passo),\n        (x + passo, y + passo),\n        (x - passo, y - passo),\n        (x + passo, y - passo),\n        (x - passo, y + passo)\n    ]\n    return vizinhos\n\n# Executa o algoritmo\nif __name__ == \"__main__\":\n    # Ponto inicial aleat\u00f3rio entre -2 e 2\n    estado_inicial = (random.uniform(-2, 2), random.uniform(-2, 2))\n\n    # Executa a busca de feixe estoc\u00e1stica\n    melhor_estado, melhor_valor, historico = busca_feixe_estocastica(\n        funcao_objetivo, estado_inicial, gerar_vizinhos, k=3\n    )\n\n    # Visualiza o progresso\n    estados = [h[0] for h in historico]\n    valores = [h[1] for h in historico]\n\n    # Cria uma malha para visualizar a fun\u00e7\u00e3o objetivo\n    x = np.linspace(-2, 2, 100)\n    y = np.linspace(-2, 2, 100)\n    X, Y = np.meshgrid(x, y)\n    Z = -(X**2 + Y**2) + 4\n\n    # Plota a superf\u00edcie e o caminho percorrido\n    plt.figure(figsize=(12, 6))\n\n    # Superf\u00edcie 3D\n    ax1 = plt.subplot(121, projection='3d')\n    ax1.plot_surface(X, Y, Z, cmap='viridis', alpha=0.8)\n    x_path = [e[0] for e in estados]\n    y_path = [e[1] for e in estados]\n    z_path = valores\n    ax1.plot(x_path, y_path, z_path, 'r-o', linewidth=2, markersize=5)\n    ax1.set_xlabel('X')\n    ax1.set_ylabel('Y')\n    ax1.set_zlabel('f(X,Y)')\n    ax1.set_title('Trajet\u00f3ria da Busca de Feixe Estoc\u00e1stica em 3D')\n\n    # Contorno 2D com caminho\n    ax2 = plt.subplot(122)\n    contour = ax2.contourf(X, Y, Z, 20, cmap='viridis')\n    ax2.plot(x_path, y_path, 'r-o', linewidth=2, markersize=5)\n    ax2.set_xlabel('X')\n    ax2.set_ylabel('Y')\n    ax2.set_title('Trajet\u00f3ria da Busca de Feixe Estoc\u00e1stica (Vista Superior)')\n    plt.colorbar(contour, ax=ax2)\n\n    plt.tight_layout()\n    plt.savefig('stochastic_beam_search_visualization.png')\n    plt.close()\n\n    print(f\"Visualiza\u00e7\u00e3o salva como 'stochastic_beam_search_visualization.png'\")\n</code></pre>"},{"location":"portfolio2/3algoritmos/#34-algoritmos-geneticos-e-evolucionarios","title":"3.4 Algoritmos Gen\u00e9ticos e Evolucion\u00e1rios","text":"<p>Os Algoritmos Gen\u00e9ticos (AGs) pertencem a uma classe mais ampla de algoritmos evolucion\u00e1rios, que se inspiram na evolu\u00e7\u00e3o biol\u00f3gica para resolver problemas de busca e otimiza\u00e7\u00e3o. Eles operam sobre uma popula\u00e7\u00e3o de solu\u00e7\u00f5es candidatas, aplicando operadores como sele\u00e7\u00e3o, recombina\u00e7\u00e3o (cruzamento) e muta\u00e7\u00e3o para gerar novas popula\u00e7\u00f5es com aptid\u00e3o progressivamente maior. Russell e Norvig (2013) discutem essas abordagens no contexto da busca local estoc\u00e1stica e otimiza\u00e7\u00e3o:</p> <ul> <li>Algoritmos Gen\u00e9ticos (Genetic Algorithms - GAs): Os AGs mant\u00eam uma popula\u00e7\u00e3o de estados candidatos (representados como strings ou cromossomos) e geram a pr\u00f3xima gera\u00e7\u00e3o combinando pares de indiv\u00edduos (cruzamento) e introduzindo pequenas altera\u00e7\u00f5es aleat\u00f3rias (muta\u00e7\u00e3o). A sele\u00e7\u00e3o dos pais geralmente favorece indiv\u00edduos com maior aptid\u00e3o (fitness), que mede a qualidade da solu\u00e7\u00e3o representada pelo indiv\u00edduo.</li> <li>Programa\u00e7\u00e3o Gen\u00e9tica (Genetic Programming - GP): Uma variante dos AGs onde os indiv\u00edduos na popula\u00e7\u00e3o s\u00e3o programas de computador (geralmente representados como \u00e1rvores de express\u00e3o) em vez de strings. O objetivo \u00e9 evoluir um programa que resolva uma tarefa espec\u00edfica. Os operadores de cruzamento e muta\u00e7\u00e3o s\u00e3o adaptados para manipular essas estruturas de programa.</li> <li>Estrat\u00e9gias de Evolu\u00e7\u00e3o (Evolution Strategies - ES): Outra abordagem evolucion\u00e1ria, frequentemente usada para otimiza\u00e7\u00e3o de par\u00e2metros em espa\u00e7os cont\u00ednuos. Diferentemente dos AGs cl\u00e1ssicos que operam em representa\u00e7\u00f5es bin\u00e1rias ou discretas e enfatizam o cruzamento, as ES geralmente trabalham com vetores de n\u00fameros reais e focam mais na muta\u00e7\u00e3o (frequentemente usando distribui\u00e7\u00f5es gaussianas) e na sele\u00e7\u00e3o determin\u00edstica ou probabil\u00edstica dos melhores indiv\u00edduos (pais e/ou filhos) para formar a pr\u00f3xima gera\u00e7\u00e3o.</li> </ul>"},{"location":"portfolio2/3algoritmos/#341-implementacao-de-um-algoritmo-genetico-simples","title":"3.4.1 Implementa\u00e7\u00e3o de um Algoritmo Gen\u00e9tico Simples","text":"<p>Os Algoritmos Gen\u00e9ticos s\u00e3o m\u00e9todos de busca inspirados na sele\u00e7\u00e3o natural e na gen\u00e9tica. Eles mant\u00eam uma popula\u00e7\u00e3o de solu\u00e7\u00f5es candidatas que evoluem ao longo de gera\u00e7\u00f5es atrav\u00e9s de operadores como sele\u00e7\u00e3o, cruzamento e muta\u00e7\u00e3o.</p> Implementa\u00e7\u00e3o de um Algoritmo Gen\u00e9tico Simples <pre><code>import random\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef algoritmo_genetico(funcao_fitness, tamanho_cromossomo, tamanho_populacao=100, \n                      taxa_cruzamento=0.8, taxa_mutacao=0.1, num_geracoes=100):\n    \"\"\"\n    Implementa\u00e7\u00e3o de um Algoritmo Gen\u00e9tico simples para maximiza\u00e7\u00e3o.\n\n    Args:\n        funcao_fitness: Fun\u00e7\u00e3o que avalia a qualidade de um cromossomo\n        tamanho_cromossomo: N\u00famero de genes em cada cromossomo\n        tamanho_populacao: N\u00famero de indiv\u00edduos na popula\u00e7\u00e3o\n        taxa_cruzamento: Probabilidade de cruzamento entre pares de indiv\u00edduos\n        taxa_mutacao: Probabilidade de muta\u00e7\u00e3o de cada gene\n        num_geracoes: N\u00famero de gera\u00e7\u00f5es a evoluir\n\n    Returns:\n        Tupla (melhor_individuo, melhor_fitness, historico_fitness)\n    \"\"\"\n    # Inicializa a popula\u00e7\u00e3o aleatoriamente (0s e 1s)\n    populacao = [\n        [random.randint(0, 1) for _ in range(tamanho_cromossomo)]\n        for _ in range(tamanho_populacao)\n    ]\n\n    # Para rastrear o progresso\n    melhor_global = None\n    melhor_fitness_global = -float('inf')\n    historico_fitness = []\n\n    print(f\"Iniciando Algoritmo Gen\u00e9tico com popula\u00e7\u00e3o de {tamanho_populacao} indiv\u00edduos\")\n    print(f\"Tamanho do cromossomo: {tamanho_cromossomo}\")\n    print(f\"Taxa de cruzamento: {taxa_cruzamento}, Taxa de muta\u00e7\u00e3o: {taxa_mutacao}\")\n\n    for geracao in range(num_geracoes):\n        # Avalia a aptid\u00e3o (fitness) de cada indiv\u00edduo\n        fitness_valores = [funcao_fitness(individuo) for individuo in populacao]\n\n        # Encontra o melhor indiv\u00edduo desta gera\u00e7\u00e3o\n        melhor_idx = fitness_valores.index(max(fitness_valores))\n        melhor_individuo = populacao[melhor_idx]\n        melhor_fitness = fitness_valores[melhor_idx]\n\n        # Atualiza o melhor global se necess\u00e1rio\n        if melhor_fitness &gt; melhor_fitness_global:\n            melhor_global = melhor_individuo.copy()\n            melhor_fitness_global = melhor_fitness\n\n        # Registra estat\u00edsticas\n        fitness_medio = sum(fitness_valores) / len(fitness_valores)\n        historico_fitness.append((geracao, melhor_fitness, fitness_medio))\n\n        print(f\"Gera\u00e7\u00e3o {geracao+1}: Melhor fitness = {melhor_fitness}, M\u00e9dia = {fitness_medio:.2f}\")\n\n        # Cria a pr\u00f3xima gera\u00e7\u00e3o\n        nova_populacao = []\n\n        # Elitismo: mant\u00e9m o melhor indiv\u00edduo\n        nova_populacao.append(melhor_individuo)\n\n        # Preenche o resto da popula\u00e7\u00e3o com novos indiv\u00edduos\n        while len(nova_populacao) &lt; tamanho_populacao:\n            # Sele\u00e7\u00e3o por torneio\n            pai1 = selecao_torneio(populacao, fitness_valores)\n            pai2 = selecao_torneio(populacao, fitness_valores)\n\n            # Cruzamento\n            if random.random() &lt; taxa_cruzamento:\n                filho1, filho2 = cruzamento(pai1, pai2)\n            else:\n                filho1, filho2 = pai1.copy(), pai2.copy()\n\n            # Muta\u00e7\u00e3o\n            mutacao(filho1, taxa_mutacao)\n            mutacao(filho2, taxa_mutacao)\n\n            # Adiciona \u00e0 nova popula\u00e7\u00e3o\n            nova_populacao.append(filho1)\n            if len(nova_populacao) &lt; tamanho_populacao:\n                nova_populacao.append(filho2)\n\n        # Substitui a popula\u00e7\u00e3o antiga pela nova\n        populacao = nova_populacao\n\n    print(f\"\\nMelhor solu\u00e7\u00e3o encontrada:\")\n    print(f\"Cromossomo: {melhor_global}\")\n    print(f\"Fitness: {melhor_fitness_global}\")\n\n    return melhor_global, melhor_fitness_global, historico_fitness\n\ndef selecao_torneio(populacao, fitness_valores, tamanho_torneio=3):\n    \"\"\"Seleciona um indiv\u00edduo usando sele\u00e7\u00e3o por torneio\"\"\"\n    indices_torneio = random.sample(range(len(populacao)), tamanho_torneio)\n    indice_vencedor = max(indices_torneio, key=lambda i: fitness_valores[i])\n    return populacao[indice_vencedor].copy()\n\ndef cruzamento(pai1, pai2):\n    \"\"\"Realiza cruzamento de um ponto entre dois pais\"\"\"\n    ponto = random.randint(1, len(pai1) - 1)\n    filho1 = pai1[:ponto] + pai2[ponto:]\n    filho2 = pai2[:ponto] + pai1[ponto:]\n    return filho1, filho2\n\ndef mutacao(cromossomo, taxa_mutacao):\n    \"\"\"Aplica muta\u00e7\u00e3o bit-flip com probabilidade taxa_mutacao para cada gene\"\"\"\n    for i in range(len(cromossomo)):\n        if random.random() &lt; taxa_mutacao:\n            cromossomo[i] = 1 - cromossomo[i]  # Inverte o bit (0-&gt;1, 1-&gt;0)\n\n# Exemplo: Problema da mochila\n# Temos n itens, cada um com um peso e um valor.\n# Queremos maximizar o valor total sem exceder a capacidade da mochila.\n\ndef fitness_mochila(cromossomo):\n    \"\"\"\n    Fun\u00e7\u00e3o de fitness para o problema da mochila.\n    Cromossomo \u00e9 uma lista bin\u00e1ria onde 1 indica que o item \u00e9 selecionado.\n    \"\"\"\n    # Pesos e valores dos itens\n    pesos = [2, 3, 5, 7, 1, 4, 1, 3, 8, 9]\n    valores = [5, 7, 10, 15, 3, 9, 2, 6, 16, 18]\n\n    # Capacidade da mochila\n    capacidade = 20\n\n    # Calcula peso e valor total dos itens selecionados\n    peso_total = sum(pesos[i] for i in range(len(cromossomo)) if cromossomo[i] == 1)\n    valor_total = sum(valores[i] for i in range(len(cromossomo)) if cromossomo[i] == 1)\n\n    # Penaliza solu\u00e7\u00f5es que excedem a capacidade\n    if peso_total &gt; capacidade:\n        return 0  # ou alguma penalidade proporcional ao excesso\n\n    return valor_total\n\n# Executa o algoritmo\nif __name__ == \"__main__\":\n    # N\u00famero de itens no problema da mochila\n    num_itens = 10\n\n    # Executa o algoritmo gen\u00e9tico\n    melhor_solucao, melhor_fitness, historico = algoritmo_genetico(\n        fitness_mochila, num_itens, tamanho_populacao=50, num_geracoes=100\n    )\n\n    # Visualiza o progresso\n    geracoes = [h[0] for h in historico]\n    melhores = [h[1] for h in historico]\n    medias = [h[2] for h in historico]\n\n    plt.figure(figsize=(10, 6))\n    plt.plot(geracoes, melhores, 'r-', label='Melhor Fitness')\n    plt.plot(geracoes, medias, 'b--', label='Fitness M\u00e9dio')\n    plt.xlabel('Gera\u00e7\u00e3o')\n    plt.ylabel('Fitness')\n    plt.title('Evolu\u00e7\u00e3o do Fitness ao Longo das Gera\u00e7\u00f5es')\n    plt.legend()\n    plt.grid(True)\n    plt.savefig('genetic_algorithm_progress.png')\n    plt.close()\n\n    print(f\"Visualiza\u00e7\u00e3o salva como 'genetic_algorithm_progress.png'\")\n\n    # Mostra os itens selecionados\n    pesos = [2, 3, 5, 7, 1, 4, 1, 3, 8, 9]\n    valores = [5, 7, 10, 15, 3, 9, 2, 6, 16, 18]\n\n    itens_selecionados = [i for i in range(len(melhor_solucao)) if melhor_solucao[i] == 1]\n    peso_total = sum(pesos[i] for i in itens_selecionados)\n    valor_total = sum(valores[i] for i in itens_selecionados)\n\n    print(f\"\\nItens selecionados: {itens_selecionados}\")\n    print(f\"Peso total: {peso_total}/20\")\n    print(f\"Valor total: {valor_total}\")\n</code></pre>"},{"location":"portfolio2/3algoritmos/#referencias-bibliograficas","title":"Refer\u00eancias Bibliogr\u00e1ficas","text":"<p>RUSSELL, S. J.; NORVIG, P. Intelig\u00eancia artificial. 3. ed. Rio de Janeiro: Elsevier Campus, 2013.</p> <p>CORMEN, T. H.; LEISERSON, C. E.; RIVEST, R. L.; STEIN, C. Introduction to Algorithms. 3. ed. Cambridge: MIT Press, 2009.</p> <p>KORF, R. E. Depth-first iterative-deepening: An optimal admissible tree search. Artificial Intelligence, v. 27, n. 1, p. 97-109, 1985.</p> <p>HART, P. E.; NILSSON, N. J.; RAPHAEL, B. A formal basis for the heuristic determination of minimum cost paths. IEEE Transactions on Systems Science and Cybernetics, v. 4, n. 2, p. 100-107, 1968.</p> <p>KIRKPATRICK, S.; GELATT, C. D.; VECCHI, M. P. Optimization by simulated annealing. Science, v. 220, n. 4598, p. 671-680, 1983.</p> <p>HOLLAND, J. H. Adaptation in Natural and Artificial Systems. Ann Arbor: University of Michigan Press, 1975.</p> <p>KOZA, J. R. Genetic Programming: On the Programming of Computers by Means of Natural Selection. Cambridge: MIT Press, 1992.</p> <p>SILVER, D. et al. Mastering the game of Go with deep neural networks and tree search. Nature, v. 529, n. 7587, p. 484-489, 2016.</p> <p>THRUN, S.; BURGARD, W.; FOX, D. Probabilistic Robotics. Cambridge: MIT Press, 2005.</p> <p>LAVALLE, S. M. Planning Algorithms. Cambridge: Cambridge University Press, 2006.</p> Vers\u00e3o Data Modifica\u00e7\u00e3o Nome GitHub <code>1.0</code> 27/05/2025 Cria\u00e7\u00e3o do documento Ana Beatriz Norberto @ananorberto"},{"location":"portfolio2/Introducao/","title":"Portf\u00f3lio: Resolvendo Problemas por Busca em Intelig\u00eancia Artificial","text":""},{"location":"portfolio2/Introducao/#introducao","title":"Introdu\u00e7\u00e3o","text":"<p>A Intelig\u00eancia Artificial (IA) envolve o estudo de agentes que recebem percep\u00e7\u00f5es do ambiente e realizam a\u00e7\u00f5es. Definimos IA como o estudo da a\u00e7\u00e3o racional e, nesse contexto, o planejamento \u2014 elaborar um plano de a\u00e7\u00e3o para alcan\u00e7ar objetivos \u2014 \u00e9 uma parte crucial da IA.</p> <p>A resolu\u00e7\u00e3o de problemas por busca \u00e9 uma t\u00e9cnica central em IA para encontrar uma sequ\u00eancia de a\u00e7\u00f5es que leve um agente a atingir um objetivo. Newell e Simon argumentaram que esta \u00e9 a base essencial da resolu\u00e7\u00e3o de problemas humanos, como um jogador de xadrez examinando movimentos ou um m\u00e9dico considerando diagn\u00f3sticos alternativos. Embora as primeiras abordagens pudessem ser ineficientes sem orienta\u00e7\u00e3o adequada, a busca, juntamente com a representa\u00e7\u00e3o do conhecimento, permanece no cerne da maioria dos trabalhos modernos em IA.</p> <p>A busca \u00e9 uma metodologia de resolu\u00e7\u00e3o de problemas que explora sistematicamente um espa\u00e7o de estados, que representa os est\u00e1gios sucessivos e alternativos no processo de busca pela solu\u00e7\u00e3o. Exemplos pr\u00e1ticos de aplica\u00e7\u00e3o da busca incluem layout VLSI (circuitos integrados de larga escala), navega\u00e7\u00e3o rob\u00f3tica, sequenciamento de montagem autom\u00e1tica e problemas de roteamento. Al\u00e9m disso, a busca tem sido aplicada em \u00e1reas como diagn\u00f3stico de falhas mec\u00e2nicas e mesmo no racioc\u00ednio baseado em l\u00f3gica.</p> <p>A capacidade de um agente de resolver problemas atrav\u00e9s da busca permite que ele navegue por ambientes complexos, tome decis\u00f5es sequenciais e encontre caminhos para atingir metas, tornando-se uma ferramenta indispens\u00e1vel para a cria\u00e7\u00e3o de sistemas inteligentes.</p>"},{"location":"portfolio2/Introducao/#historico-e-evolucao-da-busca-em-ia","title":"Hist\u00f3rico e Evolu\u00e7\u00e3o da Busca em IA","text":"<p>A hist\u00f3ria da busca em IA remonta aos prim\u00f3rdios da disciplina nos anos 1950, quando pesquisadores como Allen Newell e Herbert Simon desenvolveram os primeiros programas de resolu\u00e7\u00e3o de problemas, como o Logic Theorist e o General Problem Solver (GPS). Estes sistemas pioneiros utilizavam t\u00e9cnicas de busca para provar teoremas matem\u00e1ticos e resolver quebra-cabe\u00e7as, respectivamente.</p> <p>Durante os anos 1960 e 1970, houve avan\u00e7os significativos com o desenvolvimento de algoritmos como A* por Peter Hart, Nils Nilsson e Bertram Raphael em 1968, que introduziu o conceito de busca heur\u00edstica eficiente. Este per\u00edodo tamb\u00e9m viu o surgimento de t\u00e9cnicas como a busca em profundidade iterativa e a busca bidirecional.</p> <p>Nos anos 1980 e 1990, com o aumento do poder computacional, as t\u00e9cnicas de busca foram aplicadas a problemas mais complexos, incluindo jogos como xadrez, culminando na vit\u00f3ria do Deep Blue da IBM sobre o campe\u00e3o mundial Garry Kasparov em 1997. Este per\u00edodo tamb\u00e9m viu a integra\u00e7\u00e3o de t\u00e9cnicas de busca com m\u00e9todos probabil\u00edsticos e de aprendizado de m\u00e1quina.</p> <p>Atualmente, os algoritmos de busca continuam sendo fundamentais em IA, formando a base de sistemas de navega\u00e7\u00e3o, planejamento de rotas, diagn\u00f3stico m\u00e9dico, e muitas outras aplica\u00e7\u00f5es que impactam diretamente nossa sociedade.</p>"},{"location":"portfolio2/Introducao/#referencias-bibliograficas","title":"Refer\u00eancias Bibliogr\u00e1ficas","text":"<p>RUSSELL, S. J.; NORVIG, P. Intelig\u00eancia artificial. 3. ed. Rio de Janeiro: Elsevier Campus, 2013.</p> <p>CORMEN, T. H.; LEISERSON, C. E.; RIVEST, R. L.; STEIN, C. Introduction to Algorithms. 3. ed. Cambridge: MIT Press, 2009.</p> <p>KORF, R. E. Depth-first iterative-deepening: An optimal admissible tree search. Artificial Intelligence, v. 27, n. 1, p. 97-109, 1985.</p> <p>HART, P. E.; NILSSON, N. J.; RAPHAEL, B. A formal basis for the heuristic determination of minimum cost paths. IEEE Transactions on Systems Science and Cybernetics, v. 4, n. 2, p. 100-107, 1968.</p> <p>KIRKPATRICK, S.; GELATT, C. D.; VECCHI, M. P. Optimization by simulated annealing. Science, v. 220, n. 4598, p. 671-680, 1983.</p> <p>HOLLAND, J. H. Adaptation in Natural and Artificial Systems. Ann Arbor: University of Michigan Press, 1975.</p> <p>KOZA, J. R. Genetic Programming: On the Programming of Computers by Means of Natural Selection. Cambridge: MIT Press, 1992.</p> <p>SILVER, D. et al. Mastering the game of Go with deep neural networks and tree search. Nature, v. 529, n. 7587, p. 484-489, 2016.</p> <p>THRUN, S.; BURGARD, W.; FOX, D. Probabilistic Robotics. Cambridge: MIT Press, 2005.</p> <p>LAVALLE, S. M. Planning Algorithms. Cambridge: Cambridge University Press, 2006.</p>"},{"location":"portfolio2/Introducao/#historico-de-versao","title":"Hist\u00f3rico de vers\u00e3o","text":"Vers\u00e3o Data Modifica\u00e7\u00e3o Nome GitHub <code>1.0</code> 27/05/2025 Cria\u00e7\u00e3o do documento Ana Beatriz Norberto @ananorberto"},{"location":"portfolio2/comparando/","title":"Comparando","text":""},{"location":"portfolio2/comparando/#comparacao-de-algoritmos-e-aplicacoes-praticas","title":"Compara\u00e7\u00e3o de Algoritmos e Aplica\u00e7\u00f5es Pr\u00e1ticas","text":""},{"location":"portfolio2/comparando/#tabela-comparativa-de-algoritmos-de-busca","title":"Tabela Comparativa de Algoritmos de Busca","text":"<p>Tabela 1: Compara\u00e7\u00e3o de Algoritmos de Busca em Termos de Propriedades e Desempenho</p> Algoritmo Completude Otimalidade Complexidade de Tempo Complexidade de Espa\u00e7o Aplica\u00e7\u00f5es T\u00edpicas Busca em Largura (BFS) Sim Sim (para custos uniformes) O(b^d) O(b^d) Caminhos mais curtos em grafos n\u00e3o ponderados, quebra-cabe\u00e7as com poucas a\u00e7\u00f5es Busca em Profundidade (DFS) N\u00e3o (em espa\u00e7os infinitos) N\u00e3o O(b^m) O(bm) Labirintos, quebra-cabe\u00e7as, an\u00e1lise de jogos Busca com Aprofundamento Iterativo (IDDFS) Sim Sim (para custos uniformes) O(b^d) O(bd) Problemas com profundidade de solu\u00e7\u00e3o desconhecida Busca de Custo Uniforme Sim Sim O(b^[C*/\u03b5]) O(b^[C*/\u03b5]) Caminhos de menor custo em grafos ponderados Busca Gulosa Best-First N\u00e3o N\u00e3o O(b^m) O(b^m) Problemas onde a heur\u00edstica \u00e9 informativa A* Sim Sim (com heur\u00edstica admiss\u00edvel) O(b^d) O(b^d) Planejamento de rotas, navega\u00e7\u00e3o rob\u00f3tica Subida de Encosta N\u00e3o N\u00e3o O(\u221e) O(1) Otimiza\u00e7\u00e3o local, ajuste de par\u00e2metros Recozimento Simulado N\u00e3o N\u00e3o (probabilisticamente sim) O(\u221e) O(1) Problemas com muitos m\u00e1ximos locais Algoritmos Gen\u00e9ticos N\u00e3o N\u00e3o (probabilisticamente sim) O(\u221e) O(p) Otimiza\u00e7\u00e3o combinat\u00f3ria, design <p>Onde: - b: fator de ramifica\u00e7\u00e3o - d: profundidade da solu\u00e7\u00e3o mais rasa - m: profundidade m\u00e1xima do espa\u00e7o de estados - C*: custo da solu\u00e7\u00e3o \u00f3tima - \u03b5: diferen\u00e7a m\u00ednima entre custos de a\u00e7\u00f5es - p: tamanho da popula\u00e7\u00e3o</p>"},{"location":"portfolio2/comparando/#grafico-comparativo-de-desempenho","title":"Gr\u00e1fico Comparativo de Desempenho","text":"<p>Figura 1: Compara\u00e7\u00e3o do N\u00famero de N\u00f3s Expandidos por Diferentes Algoritmos de Busca em Fun\u00e7\u00e3o da Profundidade da Solu\u00e7\u00e3o</p> <p></p> <p>O gr\u00e1fico acima ilustra como o n\u00famero de n\u00f3s expandidos cresce com a profundidade da solu\u00e7\u00e3o para diferentes algoritmos. Observe como a busca informada (A*) com uma boa heur\u00edstica expande significativamente menos n\u00f3s que os algoritmos de busca cega, demonstrando a import\u00e2ncia do conhecimento espec\u00edfico do dom\u00ednio na efici\u00eancia da busca.</p>"},{"location":"portfolio2/comparando/#aplicacoes-praticas","title":"Aplica\u00e7\u00f5es Pr\u00e1ticas","text":"<p>A resolu\u00e7\u00e3o de problemas por busca tem in\u00fameras aplica\u00e7\u00f5es pr\u00e1ticas em diversos campos:</p> <ol> <li>Navega\u00e7\u00e3o e Planejamento de Rotas:</li> <li>Sistemas GPS utilizam algoritmos como A* para encontrar o caminho mais curto ou mais r\u00e1pido entre dois pontos.</li> <li> <p>Rob\u00f4s aut\u00f4nomos empregam t\u00e9cnicas de busca para navegar em ambientes desconhecidos ou din\u00e2micos.</p> </li> <li> <p>Jogos e Entretenimento:</p> </li> <li>Intelig\u00eancia artificial em jogos de tabuleiro como xadrez e Go utiliza busca advers\u00e1ria (minimax, MCTS).</li> <li> <p>Personagens n\u00e3o-jog\u00e1veis (NPCs) em videogames usam algoritmos de busca para encontrar caminhos e tomar decis\u00f5es.</p> </li> <li> <p>Otimiza\u00e7\u00e3o de Recursos:</p> </li> <li>Problemas de escalonamento de tarefas em sistemas de produ\u00e7\u00e3o.</li> <li>Otimiza\u00e7\u00e3o de rotas para frotas de ve\u00edculos (problema do caixeiro viajante).</li> <li> <p>Aloca\u00e7\u00e3o eficiente de recursos em sistemas distribu\u00eddos.</p> </li> <li> <p>Bioinform\u00e1tica:</p> </li> <li>Alinhamento de sequ\u00eancias de DNA e prote\u00ednas.</li> <li>Predi\u00e7\u00e3o de estruturas de prote\u00ednas.</li> <li> <p>Descoberta de medicamentos atrav\u00e9s de algoritmos gen\u00e9ticos.</p> </li> <li> <p>Processamento de Linguagem Natural:</p> </li> <li>An\u00e1lise sint\u00e1tica de senten\u00e7as.</li> <li>Tradu\u00e7\u00e3o autom\u00e1tica.</li> <li>Sistemas de perguntas e respostas.</li> </ol>"},{"location":"portfolio2/comparando/#referencias-bibliograficas","title":"Refer\u00eancias Bibliogr\u00e1ficas","text":"<p>RUSSELL, S. J.; NORVIG, P. Intelig\u00eancia artificial. 3. ed. Rio de Janeiro: Elsevier Campus, 2013.</p> <p>CORMEN, T. H.; LEISERSON, C. E.; RIVEST, R. L.; STEIN, C. Introduction to Algorithms. 3. ed. Cambridge: MIT Press, 2009.</p> <p>KORF, R. E. Depth-first iterative-deepening: An optimal admissible tree search. Artificial Intelligence, v. 27, n. 1, p. 97-109, 1985.</p> <p>HART, P. E.; NILSSON, N. J.; RAPHAEL, B. A formal basis for the heuristic determination of minimum cost paths. IEEE Transactions on Systems Science and Cybernetics, v. 4, n. 2, p. 100-107, 1968.</p> <p>KIRKPATRICK, S.; GELATT, C. D.; VECCHI, M. P. Optimization by simulated annealing. Science, v. 220, n. 4598, p. 671-680, 1983.</p> <p>HOLLAND, J. H. Adaptation in Natural and Artificial Systems. Ann Arbor: University of Michigan Press, 1975.</p> <p>KOZA, J. R. Genetic Programming: On the Programming of Computers by Means of Natural Selection. Cambridge: MIT Press, 1992.</p> <p>SILVER, D. et al. Mastering the game of Go with deep neural networks and tree search. Nature, v. 529, n. 7587, p. 484-489, 2016.</p> <p>THRUN, S.; BURGARD, W.; FOX, D. Probabilistic Robotics. Cambridge: MIT Press, 2005.</p> <p>LAVALLE, S. M. Planning Algorithms. Cambridge: Cambridge University Press, 2006.</p> Vers\u00e3o Data Modifica\u00e7\u00e3o Nome GitHub <code>1.0</code> 27/05/2025 Cria\u00e7\u00e3o do documento Ana Beatriz Norberto @ananorberto"},{"location":"portfolio2/conclus%C3%A3o/","title":"Conclus\u00e3o","text":""},{"location":"portfolio2/conclus%C3%A3o/#conclusao-e-perspectivas-futuras","title":"Conclus\u00e3o e Perspectivas Futuras","text":"<p>A resolu\u00e7\u00e3o de problemas por busca \u00e9 um componente fundamental da Intelig\u00eancia Artificial, fornecendo m\u00e9todos sistem\u00e1ticos para encontrar solu\u00e7\u00f5es em espa\u00e7os de estados complexos. Ao longo deste portf\u00f3lio, exploramos diversos algoritmos de busca, desde os mais b\u00e1sicos como Busca em Largura e Busca em Profundidade, at\u00e9 abordagens mais sofisticadas como A*, Recozimento Simulado e Algoritmos Gen\u00e9ticos.</p> <p>Cada algoritmo possui caracter\u00edsticas distintas que o tornam mais adequado para determinados tipos de problemas. A escolha do algoritmo correto depende de fatores como a natureza do espa\u00e7o de estados, a disponibilidade de heur\u00edsticas informativas, restri\u00e7\u00f5es de mem\u00f3ria e tempo, e a necessidade de otimalidade.</p> <p>Os algoritmos de busca cega, como BFS e DFS, s\u00e3o fundamentais quando n\u00e3o temos conhecimento espec\u00edfico sobre o dom\u00ednio do problema. J\u00e1 os algoritmos de busca informada, como A*, aproveitam heur\u00edsticas para direcionar a busca de forma mais eficiente. Para problemas de otimiza\u00e7\u00e3o complexos, t\u00e9cnicas como Recozimento Simulado e Algoritmos Gen\u00e9ticos oferecem abordagens inspiradas em processos naturais que podem encontrar solu\u00e7\u00f5es de alta qualidade em espa\u00e7os de busca enormes.</p>"},{"location":"portfolio2/conclus%C3%A3o/#tendencias-e-desenvolvimentos-recentes","title":"Tend\u00eancias e Desenvolvimentos Recentes","text":"<p>Nos \u00faltimos anos, temos observado v\u00e1rias tend\u00eancias importantes na \u00e1rea de resolu\u00e7\u00e3o de problemas por busca:</p> <ol> <li> <p>Integra\u00e7\u00e3o com Aprendizado de M\u00e1quina: Algoritmos de busca est\u00e3o sendo combinados com t\u00e9cnicas de aprendizado de m\u00e1quina para aprender heur\u00edsticas automaticamente a partir de dados, como no caso do AlphaGo da DeepMind, que combina busca em \u00e1rvore Monte Carlo com redes neurais profundas.</p> </li> <li> <p>Busca em Ambientes Parcialmente Observ\u00e1veis: Desenvolvimento de algoritmos mais robustos para lidar com incerteza e informa\u00e7\u00e3o parcial, essenciais para aplica\u00e7\u00f5es em rob\u00f3tica e sistemas aut\u00f4nomos.</p> </li> <li> <p>Algoritmos Anytime: Algoritmos que podem fornecer uma solu\u00e7\u00e3o a qualquer momento, melhorando-a progressivamente se mais tempo for disponibilizado, s\u00e3o cada vez mais importantes em aplica\u00e7\u00f5es de tempo real.</p> </li> <li> <p>Paraleliza\u00e7\u00e3o e Distribui\u00e7\u00e3o: Implementa\u00e7\u00f5es paralelas e distribu\u00eddas de algoritmos de busca para aproveitar arquiteturas de computa\u00e7\u00e3o modernas e lidar com problemas de escala muito grande.</p> </li> <li> <p>Busca Multi-objetivo: Algoritmos que podem otimizar m\u00faltiplos objetivos simultaneamente, essenciais para problemas do mundo real onde frequentemente h\u00e1 trade-offs entre diferentes crit\u00e9rios.</p> </li> </ol>"},{"location":"portfolio2/conclus%C3%A3o/#62-desafios-e-oportunidades","title":"6.2 Desafios e Oportunidades","text":"<p>Apesar dos avan\u00e7os significativos, v\u00e1rios desafios permanecem:</p> <ol> <li> <p>Escalabilidade: Muitos problemas do mundo real t\u00eam espa\u00e7os de estados enormes que desafiam at\u00e9 mesmo os algoritmos mais eficientes.</p> </li> <li> <p>Representa\u00e7\u00e3o de Conhecimento: A efic\u00e1cia dos algoritmos de busca depende fortemente de como o problema \u00e9 representado e formulado.</p> </li> <li> <p>Equil\u00edbrio entre Explora\u00e7\u00e3o e Explota\u00e7\u00e3o: Encontrar o equil\u00edbrio certo entre explorar novas \u00e1reas do espa\u00e7o de estados e explotar conhecimento j\u00e1 adquirido continua sendo um desafio fundamental.</p> </li> <li> <p>Interpretabilidade: \u00c0 medida que os algoritmos se tornam mais complexos, garantir que suas decis\u00f5es sejam compreens\u00edveis para humanos torna-se mais dif\u00edcil, mas tamb\u00e9m mais importante.</p> </li> </ol> <p>A resolu\u00e7\u00e3o de problemas por busca continua sendo uma \u00e1rea vibrante de pesquisa e aplica\u00e7\u00e3o em IA, com novas t\u00e9cnicas e abordagens surgindo regularmente. O futuro provavelmente ver\u00e1 uma integra\u00e7\u00e3o ainda maior com outras \u00e1reas da IA, como aprendizado de m\u00e1quina e racioc\u00ednio probabil\u00edstico, levando a sistemas cada vez mais capazes de resolver problemas complexos de forma eficiente e robusta.</p> <p>Refer\u00eancias Bibliogr\u00e1ficas</p> <p>RUSSELL, S. J.; NORVIG, P. Intelig\u00eancia artificial. 3. ed. Rio de Janeiro: Elsevier Campus, 2013.</p> <p>CORMEN, T. H.; LEISERSON, C. E.; RIVEST, R. L.; STEIN, C. Introduction to Algorithms. 3. ed. Cambridge: MIT Press, 2009.</p> <p>KORF, R. E. Depth-first iterative-deepening: An optimal admissible tree search. Artificial Intelligence, v. 27, n. 1, p. 97-109, 1985.</p> <p>HART, P. E.; NILSSON, N. J.; RAPHAEL, B. A formal basis for the heuristic determination of minimum cost paths. IEEE Transactions on Systems Science and Cybernetics, v. 4, n. 2, p. 100-107, 1968.</p> <p>KIRKPATRICK, S.; GELATT, C. D.; VECCHI, M. P. Optimization by simulated annealing. Science, v. 220, n. 4598, p. 671-680, 1983.</p> <p>HOLLAND, J. H. Adaptation in Natural and Artificial Systems. Ann Arbor: University of Michigan Press, 1975.</p> <p>KOZA, J. R. Genetic Programming: On the Programming of Computers by Means of Natural Selection. Cambridge: MIT Press, 1992.</p> <p>SILVER, D. et al. Mastering the game of Go with deep neural networks and tree search. Nature, v. 529, n. 7587, p. 484-489, 2016.</p> <p>THRUN, S.; BURGARD, W.; FOX, D. Probabilistic Robotics. Cambridge: MIT Press, 2005.</p> <p>LAVALLE, S. M. Planning Algorithms. Cambridge: Cambridge University Press, 2006.</p> Vers\u00e3o Data Modifica\u00e7\u00e3o Nome GitHub <code>1.0</code> 27/05/2025 Cria\u00e7\u00e3o do documento Ana Beatriz Norberto @ananorberto"},{"location":"portfolio2/portfolio2/","title":"Portf\u00f3lio: Resolvendo Problemas por Busca em Intelig\u00eancia Artificial","text":""},{"location":"portfolio2/portfolio2/#1-introducao-importancia-e-impacto-da-resolucao-de-problemas-por-busca-na-ia-e-na-sociedade","title":"1. Introdu\u00e7\u00e3o: Import\u00e2ncia e Impacto da Resolu\u00e7\u00e3o de Problemas por Busca na IA e na Sociedade","text":"<p>A Intelig\u00eancia Artificial (IA) envolve o estudo de agentes que recebem percep\u00e7\u00f5es do ambiente e realizam a\u00e7\u00f5es. Definimos IA como o estudo da a\u00e7\u00e3o racional e, nesse contexto, o planejamento \u2014 elaborar um plano de a\u00e7\u00e3o para alcan\u00e7ar objetivos \u2014 \u00e9 uma parte crucial da IA.</p> <p>A resolu\u00e7\u00e3o de problemas por busca \u00e9 uma t\u00e9cnica central em IA para encontrar uma sequ\u00eancia de a\u00e7\u00f5es que leve um agente a atingir um objetivo. Newell e Simon argumentaram que esta \u00e9 a base essencial da resolu\u00e7\u00e3o de problemas humanos, como um jogador de xadrez examinando movimentos ou um m\u00e9dico considerando diagn\u00f3sticos alternativos. Embora as primeiras abordagens pudessem ser ineficientes sem orienta\u00e7\u00e3o adequada, a busca, juntamente com a representa\u00e7\u00e3o do conhecimento, permanece no cerne da maioria dos trabalhos modernos em IA.</p> <p>A busca \u00e9 uma metodologia de resolu\u00e7\u00e3o de problemas que explora sistematicamente um espa\u00e7o de estados, que representa os est\u00e1gios sucessivos e alternativos no processo de busca pela solu\u00e7\u00e3o. Exemplos pr\u00e1ticos de aplica\u00e7\u00e3o da busca incluem layout VLSI (circuitos integrados de larga escala), navega\u00e7\u00e3o rob\u00f3tica, sequenciamento de montagem autom\u00e1tica e problemas de roteamento. Al\u00e9m disso, a busca tem sido aplicada em \u00e1reas como diagn\u00f3stico de falhas mec\u00e2nicas e mesmo no racioc\u00ednio baseado em l\u00f3gica.</p> <p>A capacidade de um agente de resolver problemas atrav\u00e9s da busca permite que ele navegue por ambientes complexos, tome decis\u00f5es sequenciais e encontre caminhos para atingir metas, tornando-se uma ferramenta indispens\u00e1vel para a cria\u00e7\u00e3o de sistemas inteligentes.</p>"},{"location":"portfolio2/portfolio2/#11-historico-e-evolucao-da-busca-em-ia","title":"1.1 Hist\u00f3rico e Evolu\u00e7\u00e3o da Busca em IA","text":"<p>A hist\u00f3ria da busca em IA remonta aos prim\u00f3rdios da disciplina nos anos 1950, quando pesquisadores como Allen Newell e Herbert Simon desenvolveram os primeiros programas de resolu\u00e7\u00e3o de problemas, como o Logic Theorist e o General Problem Solver (GPS). Estes sistemas pioneiros utilizavam t\u00e9cnicas de busca para provar teoremas matem\u00e1ticos e resolver quebra-cabe\u00e7as, respectivamente.</p> <p>Durante os anos 1960 e 1970, houve avan\u00e7os significativos com o desenvolvimento de algoritmos como A* por Peter Hart, Nils Nilsson e Bertram Raphael em 1968, que introduziu o conceito de busca heur\u00edstica eficiente. Este per\u00edodo tamb\u00e9m viu o surgimento de t\u00e9cnicas como a busca em profundidade iterativa (IDDFS) e a busca bidirecional.</p> <p>Nos anos 1980 e 1990, com o aumento do poder computacional, as t\u00e9cnicas de busca foram aplicadas a problemas mais complexos, incluindo jogos como xadrez, culminando na vit\u00f3ria do Deep Blue da IBM sobre o campe\u00e3o mundial Garry Kasparov em 1997. Este per\u00edodo tamb\u00e9m viu a integra\u00e7\u00e3o de t\u00e9cnicas de busca com m\u00e9todos probabil\u00edsticos e de aprendizado de m\u00e1quina, incluindo o desenvolvimento e refinamento de algoritmos evolucion\u00e1rios e de busca local como Recozimento Simulado e Estrat\u00e9gias de Evolu\u00e7\u00e3o.</p> <p>Atualmente, os algoritmos de busca continuam sendo fundamentais em IA, formando a base de sistemas de navega\u00e7\u00e3o, planejamento de rotas, diagn\u00f3stico m\u00e9dico, otimiza\u00e7\u00e3o de par\u00e2metros e muitas outras aplica\u00e7\u00f5es que impactam diretamente nossa sociedade.</p>"},{"location":"portfolio2/portfolio2/#2-apresentacao-dos-conceitos-principais","title":"2. Apresenta\u00e7\u00e3o dos Conceitos Principais","text":"<p>A abordagem de resolu\u00e7\u00e3o de problemas por busca se baseia na ideia de que um agente pode adotar um objetivo e trabalhar para satisfaz\u00ea-lo. Um agente de solu\u00e7\u00e3o de problemas \u00e9 um tipo de agente baseado em objetivos.</p> <p>Os principais conceitos envolvidos s\u00e3o:</p> <ul> <li>Formula\u00e7\u00e3o de Objetivo: O agente adota um ou mais objetivos que deseja alcan\u00e7ar.</li> <li>Formula\u00e7\u00e3o de Problema: O agente descreve os estados poss\u00edveis do \"mundo\" e as a\u00e7\u00f5es que pode realizar para transitar entre esses estados, visando atingir o objetivo. Estados do mundo podem ser considerados como totalidades sem estrutura interna vis\u00edvel (representa\u00e7\u00e3o at\u00f4mica), que \u00e9 a representa\u00e7\u00e3o considerada na busca b\u00e1sica.</li> <li>Espa\u00e7o de Estados (State Space): \u00c9 uma representa\u00e7\u00e3o formal do problema. \u00c9 definido por uma qu\u00e1drupla <code>[N, A, S, GD]</code>, onde:<ul> <li><code>N</code> \u00e9 o conjunto de n\u00f3s ou estados do grafo, correspondendo aos estados no processo de resolu\u00e7\u00e3o do problema.</li> <li><code>A</code> \u00e9 o conjunto de arcos que conectam pares de n\u00f3s, representando conex\u00f5es diretas ou a\u00e7\u00f5es que levam de um estado a outro.</li> <li><code>S</code> \u00e9 o estado inicial.</li> <li><code>GD</code> \u00e9 a descri\u00e7\u00e3o dos estados objetivo, ou seja, a condi\u00e7\u00e3o que define que o problema foi resolvido. Uma solu\u00e7\u00e3o para um problema \u00e9 representada como um caminho no grafo do estado inicial a um estado objetivo.</li> </ul> </li> <li>Busca (Search): Antes de agir, o agente simula sequ\u00eancias de a\u00e7\u00f5es em seu modelo (o espa\u00e7o de estados) para encontrar um caminho que leve ao objetivo. Isso envolve testar sistematicamente caminhos alternativos.</li> <li>Execu\u00e7\u00e3o: Uma vez encontrado um caminho (solu\u00e7\u00e3o) pela busca, o agente executa as a\u00e7\u00f5es correspondentes no ambiente real.</li> <li>Agentes de Solu\u00e7\u00e3o de Problemas: S\u00e3o agentes baseados em objetivos que utilizam a busca em representa\u00e7\u00f5es at\u00f4micas de estados para encontrar solu\u00e7\u00f5es.</li> <li>Estrat\u00e9gias de Busca: S\u00e3o os algoritmos usados para explorar o espa\u00e7o de estados. Elas podem ser:<ul> <li>Busca Cega (Uninformed Search): Algoritmos que n\u00e3o utilizam nenhuma informa\u00e7\u00e3o sobre o qu\u00e3o pr\u00f3ximo um estado est\u00e1 do(s) objetivo(s) al\u00e9m da defini\u00e7\u00e3o do problema.</li> <li>Busca Informada (Informed Search): Algoritmos que utilizam dicas espec\u00edficas do dom\u00ednio (heur\u00edsticas) sobre a localiza\u00e7\u00e3o dos objetivos para guiar a busca de forma mais eficiente.</li> </ul> </li> <li>Heur\u00edsticas: S\u00e3o fun\u00e7\u00f5es, denotadas como <code>h(n)</code>, que fornecem uma estimativa do custo do caminho mais econ\u00f4mico do estado no n\u00f3 <code>n</code> para um estado objetivo. Elas s\u00e3o informa\u00e7\u00f5es espec\u00edficas do dom\u00ednio que podem melhorar significativamente a efici\u00eancia da busca.</li> <li>Medidas de Performance: Crit\u00e9rios para avaliar algoritmos de busca:<ul> <li>Completude (Completeness): O algoritmo garante encontrar uma solu\u00e7\u00e3o quando existe uma, ou reportar a falha corretamente.</li> <li>Otimiza\u00e7\u00e3o de Custos (Cost Optimization): O algoritmo garante encontrar a solu\u00e7\u00e3o com o menor custo.</li> <li>Complexidade de Tempo (Time Complexity): Quanto tempo leva para encontrar a solu\u00e7\u00e3o.</li> <li>Complexidade de Espa\u00e7o (Space Complexity): Quanta mem\u00f3ria \u00e9 necess\u00e1ria para a busca.</li> </ul> </li> <li>Filas: Estruturas de dados usadas para gerenciar a ordem em que os n\u00f3s s\u00e3o explorados pelos algoritmos de busca: fila FIFO (First-In, First-Out) para busca em largura, pilha LIFO (Last-In, First-Out) para busca em profundidade, e fila de prioridade para busca best-first. O uso dessas estruturas permite que os algoritmos explorem estados n\u00e3o testados (lista open) e evitem repetir caminhos infrut\u00edferos (lista closed).</li> </ul>"},{"location":"portfolio2/portfolio2/#21-discussao-peas-para-problema-de-otimizacao-de-parametros-de-antena","title":"2.1 Discuss\u00e3o PEAS para Problema de Otimiza\u00e7\u00e3o de Par\u00e2metros de Antena","text":"<p>Para ilustrar a aplica\u00e7\u00e3o do modelo PEAS (Performance, Environment, Actuators, Sensors) em um contexto de otimiza\u00e7\u00e3o, analisaremos o problema de ajustar os par\u00e2metros de uma antena de phased array para maximizar a intensidade do sinal em uma dire\u00e7\u00e3o espec\u00edfica:</p> <p>Performance (Medida de Desempenho): - Maximizar a diretividade (ganho) na dire\u00e7\u00e3o desejada. - Minimizar a pot\u00eancia nos l\u00f3bulos laterais (sidelobes). - Manter a imped\u00e2ncia de entrada dentro de limites aceit\u00e1veis. - Convergir para uma boa solu\u00e7\u00e3o em tempo computacional razo\u00e1vel.</p> <p>Environment (Ambiente): - Espa\u00e7o de par\u00e2metros da antena (fases e amplitudes dos elementos). - Modelo eletromagn\u00e9tico que simula o padr\u00e3o de radia\u00e7\u00e3o da antena para um dado conjunto de par\u00e2metros. - Restri\u00e7\u00f5es f\u00edsicas ou de design nos par\u00e2metros. - O ambiente \u00e9 tipicamente est\u00e1tico (o modelo n\u00e3o muda durante a otimiza\u00e7\u00e3o) e totalmente observ\u00e1vel (podemos calcular o desempenho para qualquer conjunto de par\u00e2metros).</p> <p>Actuators (Atuadores): - O algoritmo de otimiza\u00e7\u00e3o (ex: Estrat\u00e9gias de Evolu\u00e7\u00e3o) que modifica os par\u00e2metros da antena (fases/amplitudes) a cada itera\u00e7\u00e3o.</p> <p>Sensors (Sensores): - A fun\u00e7\u00e3o objetivo (ou fun\u00e7\u00e3o de fitness) que avalia a qualidade de um conjunto de par\u00e2metros, calculando a diretividade, n\u00edveis de l\u00f3bulos laterais, etc., com base no modelo eletromagn\u00e9tico.</p>"},{"location":"portfolio2/portfolio2/#22-descricao-do-ambiente-do-problema","title":"2.2 Descri\u00e7\u00e3o do Ambiente do Problema","text":"<p>O ambiente de otimiza\u00e7\u00e3o de par\u00e2metros de antena possui as seguintes propriedades:</p> <ul> <li>Totalmente Observ\u00e1vel: Podemos calcular o desempenho exato para qualquer conjunto de par\u00e2metros usando o modelo.</li> <li>Determin\u00edstico: A avalia\u00e7\u00e3o de um conjunto de par\u00e2metros sempre produz o mesmo resultado.</li> <li>Est\u00e1tico: O modelo da antena e a fun\u00e7\u00e3o objetivo n\u00e3o mudam durante a busca.</li> <li>Cont\u00ednuo (ou Discreto): Os par\u00e2metros (fases, amplitudes) podem ser cont\u00ednuos ou discretizados.</li> <li>Agente \u00danico: O algoritmo de otimiza\u00e7\u00e3o \u00e9 o \u00fanico agente agindo no ambiente.</li> </ul> <p>Compreender estas propriedades ajuda a escolher algoritmos de busca apropriados. A natureza cont\u00ednua e potencialmente multimodal (com m\u00faltiplos \u00f3timos locais) do espa\u00e7o de par\u00e2metros torna algoritmos como Estrat\u00e9gias de Evolu\u00e7\u00e3o e Recozimento Simulado candidatos adequados.</p>"},{"location":"portfolio2/portfolio2/#3-analise-e-implementacao-de-algoritmos-de-busca-selecionados","title":"3. An\u00e1lise e Implementa\u00e7\u00e3o de Algoritmos de Busca Selecionados","text":"<p>Nesta se\u00e7\u00e3o, detalharemos quatro algoritmos de busca que representam diferentes estrat\u00e9gias e s\u00e3o aplic\u00e1veis a diversos tipos de problemas, evitando aqueles j\u00e1 explorados em sala de aula: Busca com Aprofundamento Iterativo (IDDFS), Busca Recursiva Best-First (RBFS), Recozimento Simulado (Simulated Annealing) e Estrat\u00e9gias de Evolu\u00e7\u00e3o (ES).</p>"},{"location":"portfolio2/portfolio2/#31-busca-cega-busca-com-aprofundamento-iterativo-iddfs","title":"3.1 Busca Cega: Busca com Aprofundamento Iterativo (IDDFS)","text":"<p>A Busca com Aprofundamento Iterativo (Iterative Deepening Depth-First Search - IDDFS), conforme descrita por Russell e Norvig (2013), representa uma engenhosa combina\u00e7\u00e3o das vantagens da Busca em Largura (BFS) e da Busca em Profundidade (DFS). Enquanto a BFS garante encontrar a solu\u00e7\u00e3o mais rasa (\u00f3tima em termos de n\u00famero de passos para custos uniformes) e \u00e9 completa, ela sofre com altos requisitos de mem\u00f3ria, que podem crescer exponencialmente com a profundidade. Por outro lado, a DFS possui requisitos de mem\u00f3ria modestos (lineares em rela\u00e7\u00e3o \u00e0 profundidade m\u00e1xima), mas n\u00e3o \u00e9 completa em espa\u00e7os de estados infinitos ou com ciclos, e n\u00e3o garante otimalidade.</p> <p>A IDDFS supera essas limita\u00e7\u00f5es realizando repetidas buscas em profundidade, mas com um limite de profundidade crescente. Ela come\u00e7a com uma busca em profundidade limitada \u00e0 profundidade 0 (apenas o n\u00f3 inicial). Se a solu\u00e7\u00e3o n\u00e3o for encontrada, ela descarta os n\u00f3s gerados e inicia uma nova busca em profundidade, desta vez com limite 1. Esse processo continua, incrementando o limite de profundidade (2, 3, 4, ...) a cada itera\u00e7\u00e3o, at\u00e9 que uma solu\u00e7\u00e3o seja encontrada no limite de profundidade atual <code>d</code>. Como ela explora todos os n\u00f3s at\u00e9 a profundidade <code>d-1</code> antes de explorar qualquer n\u00f3 na profundidade <code>d</code>, ela efetivamente simula a ordem de expans\u00e3o da BFS, garantindo que a primeira solu\u00e7\u00e3o encontrada seja a mais rasa (e, portanto, \u00f3tima se os custos dos passos forem uniformes).</p> <p>A principal preocupa\u00e7\u00e3o com a IDDFS \u00e9 a aparente redund\u00e2ncia, j\u00e1 que os n\u00f3s nos n\u00edveis superiores da \u00e1rvore de busca s\u00e3o gerados m\u00faltiplas vezes em diferentes itera\u00e7\u00f5es. No entanto, Russell e Norvig (2013) demonstram que, para \u00e1rvores de busca onde a maioria dos n\u00f3s est\u00e1 no n\u00edvel mais baixo (o que \u00e9 comum em muitos problemas, especialmente com fatores de ramifica\u00e7\u00e3o maiores que 1), o custo adicional de regenerar os n\u00f3s superiores \u00e9 relativamente pequeno em compara\u00e7\u00e3o com o custo de explorar o \u00faltimo n\u00edvel. A complexidade de tempo da IDDFS acaba sendo da mesma ordem de magnitude que a da BFS (O(b^d)), enquanto sua complexidade de espa\u00e7o \u00e9 a mesma da DFS (O(bd)), onde <code>b</code> \u00e9 o fator de ramifica\u00e7\u00e3o e <code>d</code> \u00e9 a profundidade da solu\u00e7\u00e3o mais rasa. Essa combina\u00e7\u00e3o de completude, otimalidade (para custos uniformes) e efici\u00eancia de mem\u00f3ria torna a IDDFS a estrat\u00e9gia de busca cega preferida em muitas situa\u00e7\u00f5es onde o espa\u00e7o de estados \u00e9 grande e a profundidade da solu\u00e7\u00e3o \u00e9 desconhecida.</p>"},{"location":"portfolio2/portfolio2/#311-implementacao-de-iddfs","title":"3.1.1 Implementa\u00e7\u00e3o de IDDFS","text":"<pre><code># Representa\u00e7\u00e3o de um grafo simples como dicion\u00e1rio\ngrafo_exemplo_iddfs = {\n    'A': ['B', 'C', 'D'],\n    'B': ['E'],\n    'C': ['F', 'G'], # Adicionado n\u00f3 G para profundidade 2\n    'D': ['H'],\n    'E': [],\n    'F': [],\n    'G': [], # Objetivo alternativo\n    'H': []\n}\n\ndef dfs_limitado(grafo, no_atual, objetivo, limite, caminho_atual):\n    \"\"\"\n    Busca em profundidade limitada recursiva (DLS).\n\n    Args:\n        grafo: Dicion\u00e1rio representando o grafo.\n        no_atual: N\u00f3 atual na busca.\n        objetivo: N\u00f3 que queremos encontrar.\n        limite: Profundidade m\u00e1xima permitida a partir do n\u00f3 atual.\n        caminho_atual: Lista representando o caminho percorrido at\u00e9 o n\u00f3 atual.\n\n    Returns:\n        Lista representando o caminho at\u00e9 o objetivo se encontrado dentro do limite,\n        None caso contr\u00e1rio.\n    \"\"\"\n    print(f\"Visitando {no_atual} (limite={limite}), Caminho: {caminho_atual}\")\n\n    if no_atual == objetivo:\n        return caminho_atual\n\n    if limite == 0:\n        return None # Limite de profundidade atingido\n\n    # Explora vizinhos recursivamente\n    for vizinho in grafo.get(no_atual, []):\n        # Evita ciclos simples verificando se o vizinho j\u00e1 est\u00e1 no caminho\n        if vizinho not in caminho_atual: \n            resultado = dfs_limitado(grafo, vizinho, objetivo, limite - 1, caminho_atual + [vizinho])\n            if resultado is not None:\n                return resultado # Objetivo encontrado em um ramo descendente\n\n    return None # Objetivo n\u00e3o encontrado neste ramo dentro do limite\n\ndef iddfs(grafo, inicio, objetivo, limite_maximo):\n    \"\"\"\n    Busca com Aprofundamento Iterativo (IDDFS).\n\n    Args:\n        grafo: Dicion\u00e1rio com os n\u00f3s e vizinhos.\n        inicio: N\u00f3 inicial da busca.\n        objetivo: N\u00f3 que queremos encontrar.\n        limite_maximo: Profundidade m\u00e1xima de busca total.\n\n    Returns:\n        Lista representando o caminho do in\u00edcio ao objetivo, ou None se n\u00e3o encontrado.\n    \"\"\"\n    print(f\"\\n\ud83d\ude80 Iniciando IDDFS de {inicio} para {objetivo} (limite m\u00e1x: {limite_maximo})\")\n    for profundidade in range(limite_maximo + 1):\n        print(f\"\\n\ud83d\udd01 Tentando profundidade: {profundidade}\")\n        caminho_encontrado = dfs_limitado(grafo, inicio, objetivo, profundidade, [inicio])\n        if caminho_encontrado is not None:\n            print(f\"\\n\u2705 Objetivo '{objetivo}' encontrado na profundidade {profundidade}.\")\n            print(f\"\ud83c\udfc1 Caminho: {caminho_encontrado}\")\n            return caminho_encontrado\n\n    print(f\"\\n\u274c Objetivo '{objetivo}' n\u00e3o encontrado at\u00e9 a profundidade {limite_maximo}.\")\n    return None\n\n# Executa o algoritmo procurando o n\u00f3 'G' a partir do n\u00f3 'A' com profundidade m\u00e1xima 3\nif __name__ == \"__main__\":\n    caminho_final = iddfs(grafo_exemplo_iddfs, 'A', 'G', 3)\n    if caminho_final:\n        print(f\"\\nCaminho final retornado: {' -&gt; '.join(caminho_final)}\")\n    else:\n        print(\"\\nNenhum caminho encontrado.\")\n</code></pre> <p>Explica\u00e7\u00e3o do C\u00f3digo IDDFS:</p> <ol> <li><code>dfs_limitado(grafo, no_atual, objetivo, limite, caminho_atual)</code>: Esta fun\u00e7\u00e3o implementa a Busca em Profundidade Limitada (DLS). Ela explora recursivamente a partir do <code>no_atual</code> at\u00e9 a <code>limite</code> de profundidade. O <code>caminho_atual</code> \u00e9 passado para rastrear o percurso e evitar ciclos simples. Retorna o caminho se o objetivo for encontrado dentro do limite, sen\u00e3o retorna <code>None</code>.</li> <li><code>iddfs(grafo, inicio, objetivo, limite_maximo)</code>: Esta \u00e9 a fun\u00e7\u00e3o principal da IDDFS. Ela itera sobre os limites de profundidade, de 0 at\u00e9 <code>limite_maximo</code>. Em cada itera\u00e7\u00e3o, chama <code>dfs_limitado</code> com o limite de profundidade atual. Se <code>dfs_limitado</code> encontrar o objetivo (retornar um caminho), a IDDFS retorna esse caminho imediatamente. Se o loop terminar sem encontrar o objetivo, significa que ele n\u00e3o existe dentro do <code>limite_maximo</code>.</li> <li>Exemplo de Uso: O c\u00f3digo demonstra a busca pelo n\u00f3 'G' a partir de 'A' no <code>grafo_exemplo_iddfs</code>. A IDDFS tentar\u00e1 profundidades 0, 1 e 2. Na profundidade 2, a chamada <code>dfs_limitado</code> encontrar\u00e1 o caminho A -&gt; C -&gt; G e o retornar\u00e1.</li> </ol>"},{"location":"portfolio2/portfolio2/#32-busca-informada-busca-recursiva-best-first-rbfs","title":"3.2 Busca Informada: Busca Recursiva Best-First (RBFS)","text":"<p>A Busca A \u00e9 renomada por sua otimalidade e completude quando usada com heur\u00edsticas admiss\u00edveis, mas sua principal desvantagem reside na potencial necessidade exponencial de mem\u00f3ria para armazenar a fronteira (n\u00f3s abertos). Para contornar essa limita\u00e7\u00e3o, Russell e Norvig (2013) apresentam a Busca Recursiva Best-First (Recursive Best-First Search - RBFS), um algoritmo que visa mimetizar a opera\u00e7\u00e3o da A utilizando apenas espa\u00e7o linear, similar \u00e0 busca em profundidade.</p> <p>A RBFS opera de forma recursiva. Ela mant\u00e9m o controle do valor <code>f</code> (custo <code>g</code> + heur\u00edstica <code>h</code>) do melhor caminho alternativo dispon\u00edvel a partir do ancestral do n\u00f3 atual (um limite superior, <code>f_limit</code>). A fun\u00e7\u00e3o recursiva explora um caminho enquanto o valor <code>f</code> dos n\u00f3s nesse caminho n\u00e3o excede esse limite. Se um n\u00f3 folha \u00e9 alcan\u00e7ado e representa uma solu\u00e7\u00e3o, a busca termina com sucesso. Se todos os caminhos a partir de um n\u00f3 excedem o <code>f_limit</code>, a recurs\u00e3o retrocede (backtracks) para o n\u00f3 ancestral. Crucialmente, ao retroceder, a RBFS atualiza o valor <code>f</code> do n\u00f3 que acabou de explorar para refletir o melhor valor <code>f</code> encontrado em seus descendentes (incluindo aqueles que excederam o limite). Esse valor atualizado pode ent\u00e3o guiar a busca futura, potencialmente fazendo com que a RBFS decida explorar um caminho diferente que antes parecia menos promissor, mas cujo valor <code>f</code> agora \u00e9 o melhor abaixo do limite.</p> <p>A principal vantagem da RBFS \u00e9 sua efici\u00eancia de espa\u00e7o, que \u00e9 linear em rela\u00e7\u00e3o \u00e0 profundidade da solu\u00e7\u00e3o mais rasa (<code>O(bd)</code>). Ela tamb\u00e9m \u00e9 \u00f3tima e completa, assim como A, se conseguir encontrar a solu\u00e7\u00e3o (o que depende de ter mem\u00f3ria suficiente para o caminho em si e a pilha de recurs\u00e3o). No entanto, sua maior desvantagem \u00e9 a potencial re-gera\u00e7\u00e3o excessiva de n\u00f3s. Como ela descarta sub\u00e1rvores ao retroceder para economizar mem\u00f3ria, pode ser que precise re-explorar a mesma sub\u00e1rvore m\u00faltiplas vezes se os limites <code>f</code> mudarem favoravelmente para ela novamente. Esse comportamento pode tornar a RBFS significativamente mais lenta que a A em termos de tempo, especialmente se os valores <code>f</code> dos n\u00f3s forem muito pr\u00f3ximos entre si, levando a muitas mudan\u00e7as de foco entre diferentes caminhos. Apesar disso, a RBFS \u00e9 uma alternativa valiosa quando a mem\u00f3ria \u00e9 o principal gargalo para a aplica\u00e7\u00e3o da A*.</p>"},{"location":"portfolio2/portfolio2/#321-implementacao-de-rbfs","title":"3.2.1 Implementa\u00e7\u00e3o de RBFS","text":"<pre><code>import math\nimport heapq # Usado apenas para ordenar sucessores, n\u00e3o como fila principal\n\n# Representa\u00e7\u00e3o do grafo com custos reais (g) e heur\u00edsticas (h)\n# Grafo similar ao exemplo A*, mas com n\u00f3s diferentes para evitar repeti\u00e7\u00e3o\ngrafo_exemplo_rbfs = {\n    'S': [('A', 2), ('B', 3)],\n    'A': [('C', 4), ('D', 1)],\n    'B': [('E', 5), ('F', 2)],\n    'C': [('G', 3)],\n    'D': [('G', 6)],\n    'E': [],\n    'F': [('G', 1)],\n    'G': [] # Objetivo\n}\n\n# Heur\u00edstica h(n) estimando a dist\u00e2ncia de n at\u00e9 o objetivo G\nheuristica_rbfs = {\n    'S': 10,\n    'A': 7,\n    'B': 8,\n    'C': 3,\n    'D': 6,\n    'E': 100, # N\u00f3 sem sa\u00edda, heur\u00edstica alta\n    'F': 1,\n    'G': 0  # Objetivo\n}\n\n# Classe auxiliar para armazenar informa\u00e7\u00f5es do n\u00f3 na RBFS\nclass NoRBFS:\n    def __init__(self, estado, pai=None, custo_g=0, heuristica_h=0):\n        self.estado = estado\n        self.pai = pai\n        self.custo_g = custo_g # Custo real do in\u00edcio at\u00e9 este n\u00f3\n        self.heuristica_h = heuristica_h # Heur\u00edstica estimada deste n\u00f3 at\u00e9 o objetivo\n        self.valor_f = custo_g + heuristica_h # Valor f = g + h\n\n    # Usado para ordena\u00e7\u00e3o (heapq ou sort)\n    def __lt__(self, other):\n        return self.valor_f &lt; other.valor_f\n\ndef rbfs_recursive(no, objetivo, f_limit):\n    \"\"\"\n    Fun\u00e7\u00e3o recursiva principal da RBFS.\n\n    Args:\n        no: Objeto NoRBFS representando o n\u00f3 atual.\n        objetivo: Estado objetivo.\n        f_limit: Limite superior do valor f permitido para explora\u00e7\u00e3o.\n\n    Returns:\n        Tupla (resultado, novo_f_limit):\n        - resultado: N\u00f3 objetivo se encontrado, None caso contr\u00e1rio.\n        - novo_f_limit: O menor valor f dos caminhos alternativos (ou infinito).\n    \"\"\"\n    print(f\"\ud83d\udd0d Explorando {no.estado} (g={no.custo_g}, h={no.heuristica_h}, f={no.valor_f}) com f_limit={f_limit}\")\n\n    if no.estado == objetivo:\n        print(f\"\u2705 Objetivo {objetivo} alcan\u00e7ado!\")\n        return no, no.valor_f # Retorna o n\u00f3 solu\u00e7\u00e3o e seu valor f\n\n    # Gera sucessores\n    sucessores = []\n    for vizinho_estado, custo_acao in grafo_exemplo_rbfs.get(no.estado, []):\n        custo_g_vizinho = no.custo_g + custo_acao\n        heuristica_h_vizinho = heuristica_rbfs.get(vizinho_estado, math.inf)\n        sucessor = NoRBFS(vizinho_estado, no, custo_g_vizinho, heuristica_h_vizinho)\n        sucessores.append(sucessor)\n\n    if not sucessores:\n        print(f\"  -&gt; N\u00f3 {no.estado} sem sucessores.\")\n        return None, math.inf # Sem sucessores = caminho morto\n\n    # Atualiza o valor f dos sucessores com base no pai (necess\u00e1rio se f foi atualizado no backtrack)\n    for s in sucessores:\n        s.valor_f = max(s.valor_f, no.valor_f) # f(n) n\u00e3o pode ser menor que f(pai)\n\n    while True:\n        # Ordena sucessores pelo menor valor f\n        sucessores.sort()\n\n        melhor = sucessores[0]\n        print(f\"  -&gt; Melhor sucessor: {melhor.estado} com f={melhor.valor_f}\")\n\n        # Se o melhor caminho excede o limite, retorna falha e o f do melhor caminho\n        if melhor.valor_f &gt; f_limit:\n            print(f\"  -&gt; Melhor f ({melhor.valor_f}) excede f_limit ({f_limit}). Retornando...\")\n            return None, melhor.valor_f\n\n        # Determina o limite para a chamada recursiva:\n        # \u00c9 o menor entre o f_limit atual e o valor f do segundo melhor sucessor (se existir)\n        alternativa_f = sucessores[1].valor_f if len(sucessores) &gt; 1 else math.inf\n        novo_f_limit_recursao = min(f_limit, alternativa_f)\n        print(f\"  -&gt; Chamando recurs\u00e3o para {melhor.estado} com novo f_limit={novo_f_limit_recursao}\")\n\n        # Chamada recursiva\n        resultado, f_retornado = rbfs_recursive(melhor, objetivo, novo_f_limit_recursao)\n\n        # Atualiza o valor f do melhor n\u00f3 com o valor retornado pela recurs\u00e3o\n        # Isso propaga o limite inferior de custo da sub\u00e1rvore explorada\n        melhor.valor_f = f_retornado\n        print(f\"  -&gt; Retornou da recurs\u00e3o de {melhor.estado}. Novo f={melhor.valor_f}\")\n\n        # Se a recurs\u00e3o encontrou a solu\u00e7\u00e3o, retorna\n        if resultado is not None:\n            return resultado, f_retornado\n\n        # Se n\u00e3o encontrou, o loop continua, reordenando os sucessores com o f atualizado\n        # e tentando o pr\u00f3ximo melhor (que agora pode ser o que acabou de retornar).\n\ndef iniciar_rbfs(inicio, objetivo):\n    \"\"\"\n    Inicia a busca RBFS.\n    \"\"\"\n    print(f\"\\n\ud83d\ude80 Iniciando RBFS de {inicio} at\u00e9 {objetivo}\")\n    no_inicial = NoRBFS(inicio, custo_g=0, heuristica_h=heuristica_rbfs.get(inicio, math.inf))\n    no_solucao, _ = rbfs_recursive(no_inicial, objetivo, math.inf)\n\n    if no_solucao:\n        print(\"\\n\ud83c\udfc1 Caminho encontrado com sucesso!\")\n        # Reconstr\u00f3i o caminho\n        caminho = []\n        atual = no_solucao\n        while atual:\n            caminho.append(atual.estado)\n            atual = atual.pai\n        caminho.reverse()\n        print(f\"Caminho: {' -&gt; '.join(caminho)}\")\n        print(f\"Custo total (g): {no_solucao.custo_g}\")\n        return caminho\n    else:\n        print(\"\\n\u274c Caminho n\u00e3o encontrado.\")\n        return None\n\n# Executa o algoritmo\nif __name__ == \"__main__\":\n    caminho_rbfs = iniciar_rbfs('S', 'G')\n</code></pre> <p>Explica\u00e7\u00e3o do C\u00f3digo RBFS:</p> <ol> <li><code>NoRBFS</code>: Classe auxiliar para representar um n\u00f3 na busca, armazenando estado, pai, custo <code>g</code>, heur\u00edstica <code>h</code> e valor <code>f</code>.</li> <li><code>rbfs_recursive(no, objetivo, f_limit)</code>: Fun\u00e7\u00e3o recursiva principal.<ul> <li>Verifica se o n\u00f3 atual \u00e9 o objetivo.</li> <li>Gera os sucessores e calcula seus valores <code>f</code>.</li> <li>Atualiza o <code>f</code> dos sucessores para garantir que n\u00e3o sejam menores que o <code>f</code> do pai (monotonicidade).</li> <li>Entra em um loop:<ul> <li>Ordena os sucessores por valor <code>f</code>.</li> <li>Pega o melhor sucessor.</li> <li>Se o <code>f</code> do melhor exceder o <code>f_limit</code>, retorna falha e o <code>f</code> do melhor (ser\u00e1 o novo limite para o n\u00edvel acima).</li> <li>Determina o limite para a chamada recursiva (<code>novo_f_limit_recursao</code>) como o m\u00ednimo entre o <code>f_limit</code> atual e o <code>f</code> do segundo melhor sucessor.</li> <li>Chama <code>rbfs_recursive</code> para o melhor sucessor com o novo limite.</li> <li>Atualiza o <code>f</code> do melhor sucessor com o valor <code>f</code> retornado pela recurs\u00e3o (importante para propagar informa\u00e7\u00e3o de custo).</li> <li>Se a recurs\u00e3o encontrou a solu\u00e7\u00e3o, retorna sucesso.</li> <li>Caso contr\u00e1rio, o loop continua, reordenando os sucessores com o <code>f</code> atualizado.</li> </ul> </li> </ul> </li> <li><code>iniciar_rbfs(inicio, objetivo)</code>: Prepara o n\u00f3 inicial e chama a fun\u00e7\u00e3o recursiva com <code>f_limit</code> inicial infinito. Se encontrar a solu\u00e7\u00e3o, reconstr\u00f3i e imprime o caminho.</li> <li>Exemplo de Uso: Demonstra a busca de 'S' para 'G' usando o <code>grafo_exemplo_rbfs</code> e a <code>heuristica_rbfs</code>. A sa\u00edda detalhada mostra como o algoritmo explora e retrocede, atualizando os limites <code>f</code>.</li> </ol>"},{"location":"portfolio2/portfolio2/#33-busca-local-recozimento-simulado-simulated-annealing","title":"3.3 Busca Local: Recozimento Simulado (Simulated Annealing)","text":"<p>Enquanto a Subida de Encosta (Hill Climbing) \u00e9 uma t\u00e9cnica de busca local direta que sempre busca melhorias imediatas, ela frequentemente falha ao ficar presa em \u00f3timos locais. O Recozimento Simulado (Simulated Annealing), apresentado por Russell e Norvig (2013) como uma melhoria sobre a subida de encosta, oferece uma solu\u00e7\u00e3o probabil\u00edstica para este problema. Inspirado no processo f\u00edsico de recozimento (annealing) em metalurgia, onde um material \u00e9 aquecido e depois resfriado lentamente para aumentar o tamanho de seus cristais e reduzir seus defeitos, o algoritmo permite movimentos ocasionais para estados piores, diminuindo a probabilidade desses movimentos ao longo do tempo.</p> <p>O algoritmo come\u00e7a em um estado inicial aleat\u00f3rio e, a cada itera\u00e7\u00e3o, considera um movimento para um vizinho aleat\u00f3rio. Se o vizinho for melhor (maior valor na fun\u00e7\u00e3o objetivo para maximiza\u00e7\u00e3o, ou menor para minimiza\u00e7\u00e3o), o movimento \u00e9 sempre aceito. Se o vizinho for pior, ele ainda pode ser aceito com uma certa probabilidade, que depende de dois fatores: qu\u00e3o pior \u00e9 o vizinho (a diferen\u00e7a de valor, <code>\u0394E</code>) e um par\u00e2metro chamado \"temperatura\" (<code>T</code>). A probabilidade de aceitar um movimento pior \u00e9 tipicamente dada por <code>exp(\u0394E / T)</code> (para maximiza\u00e7\u00e3o, onde <code>\u0394E</code> seria negativo e menor; para minimiza\u00e7\u00e3o, seria <code>exp(-\u0394E / T)</code> com <code>\u0394E</code> positivo). No in\u00edcio, a temperatura <code>T</code> \u00e9 alta, permitindo que muitos movimentos ruins sejam aceitos, o que possibilita ao algoritmo explorar amplamente o espa\u00e7o de busca e escapar de \u00f3timos locais iniciais. Gradualmente, a temperatura \u00e9 reduzida de acordo com um \"cronograma de resfriamento\" (cooling schedule). \u00c0 medida que <code>T</code> diminui, a probabilidade de aceitar movimentos ruins tamb\u00e9m diminui, fazendo com que o algoritmo se concentre cada vez mais em melhorias locais, convergindo eventualmente para um estado de baixa energia (alta qualidade).</p> <p>A grande vantagem do Recozimento Simulado \u00e9 sua capacidade de encontrar \u00f3timos globais (ou solu\u00e7\u00f5es muito pr\u00f3ximas a eles) com maior probabilidade do que a Subida de Encosta, justamente por permitir escapar de \u00f3timos locais. No entanto, seu desempenho \u00e9 muito sens\u00edvel \u00e0 escolha do cronograma de resfriamento (como a temperatura inicial, a taxa de decaimento e o crit\u00e9rio de parada). Um resfriamento muito r\u00e1pido pode fazer com que ele se comporte como a Subida de Encosta e fique preso; um resfriamento muito lento pode torn\u00e1-lo computacionalmente caro.</p>"},{"location":"portfolio2/portfolio2/#331-implementacao-de-recozimento-simulado","title":"3.3.1 Implementa\u00e7\u00e3o de Recozimento Simulado","text":"<pre><code>import random\nimport math\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef recozimento_simulado(funcao_objetivo, estado_inicial, gerar_vizinho, \n                         temperatura_inicial=100.0, taxa_resfriamento=0.97, \n                         temperatura_minima=0.01, max_iter_por_temp=50):\n    \"\"\"\n    Implementa\u00e7\u00e3o do algoritmo de Recozimento Simulado para maximiza\u00e7\u00e3o.\n\n    Args:\n        funcao_objetivo: Fun\u00e7\u00e3o que avalia a qualidade de um estado (retorna valor a maximizar).\n        estado_inicial: Estado a partir do qual iniciar a busca.\n        gerar_vizinho: Fun\u00e7\u00e3o que gera um estado vizinho aleat\u00f3rio a partir de um estado dado.\n        temperatura_inicial: Temperatura inicial.\n        taxa_resfriamento: Fator multiplicativo para diminuir a temperatura (e.g., 0.95).\n        temperatura_minima: Temperatura de parada.\n        max_iter_por_temp: N\u00famero de vizinhos a testar em cada n\u00edvel de temperatura.\n\n    Returns:\n        Tupla (melhor_estado_global, melhor_valor_global, historico)\n        historico: Lista de tuplas (iteracao, estado_atual, valor_atual, temperatura)\n    \"\"\"\n    estado_atual = estado_inicial\n    valor_atual = funcao_objetivo(estado_atual)\n\n    melhor_estado_global = estado_atual\n    melhor_valor_global = valor_atual\n\n    temperatura = temperatura_inicial\n\n    historico = [(0, estado_atual, valor_atual, temperatura)]\n    iteracao_total = 0\n\n    print(f\"\ud83d\ude80 Iniciando Recozimento Simulado a partir de {estado_atual} (Valor={valor_atual:.4f})\")\n    print(f\"   T inicial: {temperatura_inicial:.2f}, Taxa resfri.: {taxa_resfriamento}, T min: {temperatura_minima:.4f}\")\n\n    while temperatura &gt; temperatura_minima:\n        print(f\"\\n-- Temperatura atual: {temperatura:.4f} --\")\n        for i in range(max_iter_por_temp):\n            iteracao_total += 1\n            # Gera um vizinho aleat\u00f3rio\n            vizinho = gerar_vizinho(estado_atual)\n            valor_vizinho = funcao_objetivo(vizinho)\n\n            # Calcula a diferen\u00e7a de energia (para maximiza\u00e7\u00e3o, delta &gt; 0 \u00e9 melhor)\n            delta_e = valor_vizinho - valor_atual\n\n            # Decide se aceita o novo estado\n            aceita = False\n            razao = \"\"\n            if delta_e &gt; 0:  # Movimento para um estado melhor \u00e9 sempre aceito\n                aceita = True\n                razao = \"melhor\"\n            else:  # Movimento para um estado pior pode ser aceito\n                # Evita divis\u00e3o por zero e math domain error\n                if temperatura &gt; 1e-9: \n                    probabilidade = math.exp(delta_e / temperatura)\n                    if random.random() &lt; probabilidade:\n                        aceita = True\n                        razao = f\"pior (prob={probabilidade:.4f})\"\n                    else:\n                        razao = f\"pior (rejeitado, prob={probabilidade:.4f})\"\n                else:\n                     razao = \"pior (rejeitado, T muito baixa)\"\n\n            print(f\"  Iter {iteracao_total} (sub {i+1}): Vizinho={vizinho}, V={valor_vizinho:.4f}, DeltaE={delta_e:.4f} -&gt; Aceito: {aceita} ({razao})\")\n\n            if aceita:\n                estado_atual = vizinho\n                valor_atual = valor_vizinho\n\n                # Atualiza o melhor estado global se necess\u00e1rio\n                if valor_atual &gt; melhor_valor_global:\n                    melhor_estado_global = estado_atual\n                    melhor_valor_global = valor_atual\n                    print(f\"    \u2728 Novo melhor global encontrado! Valor: {melhor_valor_global:.4f}\")\n\n            # Registra o estado atual (aceito ou n\u00e3o) para o hist\u00f3rico\n            historico.append((iteracao_total, estado_atual, valor_atual, temperatura))\n\n        # Resfria a temperatura\n        temperatura *= taxa_resfriamento\n\n    print(f\"\\n\ud83c\udfc1 Recozimento conclu\u00eddo ap\u00f3s {iteracao_total} itera\u00e7\u00f5es\")\n    print(f\"   Temperatura final: {temperatura:.4f}\")\n    print(f\"   Melhor estado global encontrado: {melhor_estado_global}\")\n    print(f\"   Melhor valor global: {melhor_valor_global:.4f}\")\n\n    return melhor_estado_global, melhor_valor_global, historico\n\n# Exemplo: Otimizar a fun\u00e7\u00e3o Rastrigin (minimiza\u00e7\u00e3o, convertida para maximiza\u00e7\u00e3o)\n# Fun\u00e7\u00e3o complexa com muitos m\u00ednimos locais. M\u00ednimo global em (0,0) com valor 0.\n# Maximizaremos -Rastrigin(x,y), com m\u00e1ximo global em (0,0) com valor 0.\ndef rastrigin(ponto):\n    x, y = ponto\n    A = 10\n    return A * 2 + (x**2 - A * np.cos(2 * np.pi * x)) + (y**2 - A * np.cos(2 * np.pi * y))\n\ndef funcao_objetivo_rastrigin(ponto):\n    # Negativo para transformar minimiza\u00e7\u00e3o em maximiza\u00e7\u00e3o\n    return -rastrigin(ponto)\n\ndef gerar_vizinho_rastrigin(ponto, passo_max=0.5):\n    x, y = ponto\n    # Gera um vizinho adicionando um pequeno vetor aleat\u00f3rio\n    novo_x = x + random.uniform(-passo_max, passo_max)\n    novo_y = y + random.uniform(-passo_max, passo_max)\n    # Mant\u00e9m dentro dos limites [-5.12, 5.12]\n    novo_x = max(-5.12, min(5.12, novo_x))\n    novo_y = max(-5.12, min(5.12, novo_y))\n    return (novo_x, novo_y)\n\n# Executa o algoritmo\nif __name__ == \"__main__\":\n    # Estado inicial aleat\u00f3rio dentro dos limites\n    estado_inicial_rastrigin = (random.uniform(-5.12, 5.12), random.uniform(-5.12, 5.12))\n\n    # Executa o recozimento simulado\n    melhor_estado, melhor_valor, historico_sa = recozimento_simulado(\n        funcao_objetivo_rastrigin, \n        estado_inicial_rastrigin, \n        gerar_vizinho_rastrigin,\n        temperatura_inicial=50.0, \n        taxa_resfriamento=0.98, \n        temperatura_minima=0.001,\n        max_iter_por_temp=100\n    )\n\n    # Visualiza o progresso\n    iteracoes = [h[0] for h in historico_sa]\n    valores = [h[2] for h in historico_sa]\n    temperaturas = [h[3] for h in historico_sa]\n\n    plt.figure(figsize=(12, 8))\n\n    # Evolu\u00e7\u00e3o do Valor da Fun\u00e7\u00e3o Objetivo\n    ax1 = plt.subplot(2, 1, 1)\n    ax1.plot(iteracoes, valores, 'r-', linewidth=1, alpha=0.8)\n    ax1.set_xlabel('Itera\u00e7\u00e3o Total')\n    ax1.set_ylabel('Valor da Fun\u00e7\u00e3o Objetivo (-Rastrigin)')\n    ax1.set_title('Evolu\u00e7\u00e3o do Valor da Fun\u00e7\u00e3o no Recozimento Simulado')\n    ax1.grid(True)\n\n    # Evolu\u00e7\u00e3o da Temperatura\n    ax2 = plt.subplot(2, 1, 2)\n    ax2.plot(iteracoes, temperaturas, 'g-', linewidth=1)\n    ax2.set_xlabel('Itera\u00e7\u00e3o Total')\n    ax2.set_ylabel('Temperatura')\n    ax2.set_title('Cronograma de Resfriamento')\n    ax2.set_yscale('log') # Escala log para melhor visualiza\u00e7\u00e3o\n    ax2.grid(True)\n\n    plt.tight_layout()\n    plt.savefig('simulated_annealing_rastrigin_progress.png')\n    plt.close()\n\n    print(f\"\\nVisualiza\u00e7\u00e3o do progresso salva como 'simulated_annealing_rastrigin_progress.png'\")\n\n    # Visualiza\u00e7\u00e3o da fun\u00e7\u00e3o Rastrigin e ponto final (Opcional, requer mais c\u00f3digo)\n    # ... (c\u00f3digo para plot 2D/3D da fun\u00e7\u00e3o Rastrigin e o ponto encontrado) ...\n</code></pre> <p>Explica\u00e7\u00e3o do C\u00f3digo de Recozimento Simulado:</p> <ol> <li><code>recozimento_simulado(...)</code>: Fun\u00e7\u00e3o principal que implementa o algoritmo.<ul> <li>Inicializa o estado atual, valor atual, melhor estado global e temperatura.</li> <li>Entra no loop principal que continua enquanto a temperatura for maior que a m\u00ednima.</li> <li>Dentro do loop de temperatura, h\u00e1 um loop interno que testa <code>max_iter_por_temp</code> vizinhos.</li> <li>Para cada vizinho, calcula a diferen\u00e7a de valor (<code>delta_e</code>).</li> <li>Se o vizinho for melhor (<code>delta_e &gt; 0</code>), ele \u00e9 aceito.</li> <li>Se for pior, calcula a probabilidade <code>exp(delta_e / temperatura)</code> e aceita o vizinho com essa probabilidade.</li> <li>Se um vizinho \u00e9 aceito, o estado atual \u00e9 atualizado. O melhor estado global tamb\u00e9m \u00e9 atualizado se necess\u00e1rio.</li> <li>O hist\u00f3rico de itera\u00e7\u00e3o, estado, valor e temperatura \u00e9 registrado.</li> <li>Ap\u00f3s o loop interno, a temperatura \u00e9 reduzida (<code>temperatura *= taxa_resfriamento</code>).</li> </ul> </li> <li>Exemplo de Uso (Fun\u00e7\u00e3o Rastrigin): O algoritmo \u00e9 aplicado para encontrar o m\u00e1ximo da fun\u00e7\u00e3o <code>-Rastrigin(x, y)</code>. A fun\u00e7\u00e3o Rastrigin original tem um m\u00ednimo global em (0,0) e muitos m\u00ednimos locais, tornando-a um bom teste para algoritmos de otimiza\u00e7\u00e3o global. Usamos <code>-Rastrigin</code> para transformar o problema em maximiza\u00e7\u00e3o.</li> <li><code>gerar_vizinho_rastrigin</code>: Gera um ponto vizinho adicionando um pequeno deslocamento aleat\u00f3rio e garantindo que permane\u00e7a dentro dos limites do dom\u00ednio da fun\u00e7\u00e3o.</li> <li>Visualiza\u00e7\u00e3o: O c\u00f3digo gera gr\u00e1ficos mostrando a evolu\u00e7\u00e3o do valor da fun\u00e7\u00e3o objetivo e a diminui\u00e7\u00e3o da temperatura ao longo das itera\u00e7\u00f5es, salvando em <code>simulated_annealing_rastrigin_progress.png</code>.</li> </ol>"},{"location":"portfolio2/portfolio2/#34-algoritmos-evolucionarios-estrategias-de-evolucao-es","title":"3.4 Algoritmos Evolucion\u00e1rios: Estrat\u00e9gias de Evolu\u00e7\u00e3o (ES)","text":"<p>Os Algoritmos Gen\u00e9ticos (AGs) cl\u00e1ssicos, como discutido por Russell e Norvig (2013), operam tipicamente em representa\u00e7\u00f5es bin\u00e1rias ou discretas e utilizam operadores como cruzamento e muta\u00e7\u00e3o bit-a-bit. As Estrat\u00e9gias de Evolu\u00e7\u00e3o (Evolution Strategies - ES), por outro lado, s\u00e3o uma classe de algoritmos evolucion\u00e1rios particularmente adequados para a otimiza\u00e7\u00e3o de problemas em espa\u00e7os de par\u00e2metros cont\u00ednuos. Desenvolvidas independentemente dos AGs na Alemanha nos anos 1960 e 1970 por Ingo Rechenberg e Hans-Paul Schwefel, as ES trabalham diretamente com vetores de n\u00fameros reais.</p> <p>A caracter\u00edstica central das ES \u00e9 o uso da muta\u00e7\u00e3o como principal motor de busca, frequentemente modelada por distribui\u00e7\u00f5es de probabilidade como a Gaussiana (Normal). Al\u00e9m dos par\u00e2metros do problema (vari\u00e1veis de objeto), as ES modernas frequentemente co-evoluem par\u00e2metros da pr\u00f3pria estrat\u00e9gia, como as vari\u00e2ncias (ou desvios padr\u00e3o) e, \u00e0s vezes, as covari\u00e2ncias da distribui\u00e7\u00e3o de muta\u00e7\u00e3o. Isso permite que o algoritmo adapte a intensidade e a dire\u00e7\u00e3o da busca ao longo do processo de otimiza\u00e7\u00e3o, um conceito conhecido como auto-adapta\u00e7\u00e3o.</p> <p>Existem v\u00e1rias nota\u00e7\u00f5es para descrever diferentes ES, como <code>(\u03bc/\u03c1, \u03bb)-ES</code> ou <code>(\u03bc/\u03c1 + \u03bb)-ES</code>:</p> <ul> <li><code>\u03bc</code>: N\u00famero de pais selecionados para gerar descendentes.</li> <li><code>\u03bb</code>: N\u00famero de descendentes gerados em cada gera\u00e7\u00e3o.</li> <li><code>\u03c1</code>: (Opcional) N\u00famero de pais usados para recombinar e gerar um descendente (geralmente 1 ou 2).</li> <li><code>,</code>: Indica sele\u00e7\u00e3o n\u00e3o-elitista (apenas os descendentes formam a pr\u00f3xima gera\u00e7\u00e3o de pais).</li> <li><code>+</code>: Indica sele\u00e7\u00e3o elitista (pais e descendentes competem juntos para formar a pr\u00f3xima gera\u00e7\u00e3o de pais).</li> </ul> <p>A forma mais simples \u00e9 a <code>(1+1)-ES</code>, onde um pai gera um descendente por muta\u00e7\u00e3o, e o melhor dos dois (pai ou filho) sobrevive para a pr\u00f3xima gera\u00e7\u00e3o. Formas mais complexas como <code>(\u03bc, \u03bb)-ES</code> ou <code>(\u03bc + \u03bb)-ES</code> usam popula\u00e7\u00f5es maiores e podem incluir recombina\u00e7\u00e3o (geralmente m\u00e9dia aritm\u00e9tica ou intermedi\u00e1ria) entre os pais selecionados antes da muta\u00e7\u00e3o para gerar descendentes.</p>"},{"location":"portfolio2/portfolio2/#341-implementacao-de-uma-estrategia-de-evolucao-simples-11-es","title":"3.4.1 Implementa\u00e7\u00e3o de uma Estrat\u00e9gia de Evolu\u00e7\u00e3o Simples (1+1)-ES","text":"<p>Vamos implementar uma (1+1)-ES b\u00e1sica com adapta\u00e7\u00e3o de passo (tamanho da muta\u00e7\u00e3o) para minimizar a fun\u00e7\u00e3o Esfera em 2D.</p> <pre><code>import random\nimport math\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef estrategia_evolucao_1_mais_1(funcao_objetivo, dimensoes, limites, \n                                 sigma_inicial=1.0, taxa_aprendizado=None, \n                                 max_geracoes=1000, tol=1e-6):\n    \"\"\"\n    Implementa\u00e7\u00e3o de uma Estrat\u00e9gia de Evolu\u00e7\u00e3o (1+1)-ES simples com \n    adapta\u00e7\u00e3o de passo da regra 1/5 para minimiza\u00e7\u00e3o.\n\n    Args:\n        funcao_objetivo: Fun\u00e7\u00e3o a ser minimizada (recebe lista/array, retorna float).\n        dimensoes: N\u00famero de dimens\u00f5es do vetor de par\u00e2metros.\n        limites: Tupla (min_val, max_val) para os par\u00e2metros.\n        sigma_inicial: Desvio padr\u00e3o inicial para a muta\u00e7\u00e3o Gaussiana.\n        taxa_aprendizado: Fator para ajustar sigma (default: 1 / sqrt(dimensoes)).\n        max_geracoes: N\u00famero m\u00e1ximo de gera\u00e7\u00f5es.\n        tol: Toler\u00e2ncia para crit\u00e9rio de parada (mudan\u00e7a no valor).\n\n    Returns:\n        Tupla (melhor_individuo, melhor_fitness, historico)\n        historico: Lista de tuplas (geracao, fitness_atual, sigma_atual)\n    \"\"\"\n    min_val, max_val = limites\n    if taxa_aprendizado is None:\n        taxa_aprendizado = 1.0 / math.sqrt(dimensoes)\n\n    # Indiv\u00edduo pai inicial (aleat\u00f3rio dentro dos limites)\n    pai = np.random.uniform(min_val, max_val, dimensoes)\n    fitness_pai = funcao_objetivo(pai)\n\n    # Par\u00e2metro de estrat\u00e9gia (desvio padr\u00e3o da muta\u00e7\u00e3o)\n    sigma = sigma_inicial\n\n    melhor_global = pai\n    melhor_fitness_global = fitness_pai\n\n    historico = [(0, fitness_pai, sigma)]\n    sucessos_ultimas_k_geracoes = 0\n    k = 10 # Janela para a regra 1/5\n\n    print(f\"\ud83d\ude80 Iniciando (1+1)-ES para {dimensoes} dimens\u00f5es\")\n    print(f\"   Pai inicial: {pai}, Fitness: {fitness_pai:.4f}, Sigma: {sigma:.4f}\")\n    print(f\"   Taxa aprendizado (1/5 regra): {taxa_aprendizado:.4f}\")\n\n    for geracao in range(1, max_geracoes + 1):\n        # Gera filho por muta\u00e7\u00e3o Gaussiana\n        mutacao_vetor = np.random.normal(0, sigma, dimensoes)\n        filho = pai + mutacao_vetor\n\n        # Garante que o filho permane\u00e7a dentro dos limites\n        filho = np.clip(filho, min_val, max_val)\n\n        fitness_filho = funcao_objetivo(filho)\n\n        # Sele\u00e7\u00e3o (1+1): O melhor entre pai e filho sobrevive\n        sucesso = False\n        if fitness_filho &lt; fitness_pai:\n            pai = filho\n            fitness_pai = fitness_filho\n            sucesso = True\n            print(f\"  Ger {geracao}: Sucesso! Novo pai fitness: {fitness_pai:.4f}, Sigma: {sigma:.4f}\")\n            # Atualiza melhor global\n            if fitness_pai &lt; melhor_fitness_global:\n                 melhor_global = pai\n                 melhor_fitness_global = fitness_pai\n                 print(f\"    \u2728 Novo melhor global encontrado! Fitness: {melhor_fitness_global:.4f}\")\n        else:\n            print(f\"  Ger {geracao}: Falha. Fitness filho: {fitness_filho:.4f} &gt;= Pai: {fitness_pai:.4f}. Sigma: {sigma:.4f}\")\n\n        # Adapta\u00e7\u00e3o de Sigma (Regra 1/5 de Rechenberg)\n        # A cada k gera\u00e7\u00f5es, verifica a taxa de sucesso.\n        if geracao % k == 0:\n            taxa_sucesso = sucessos_ultimas_k_geracoes / k\n            fator_ajuste = math.exp(taxa_aprendizado * (taxa_sucesso - 1/5) / (1 - 1/5))\n            sigma *= fator_ajuste\n            print(f\"    Adapta\u00e7\u00e3o Sigma (Regra 1/5): Taxa sucesso={taxa_sucesso:.2f} -&gt; Novo sigma={sigma:.4f}\")\n            sucessos_ultimas_k_geracoes = 0 # Reseta contador\n        elif sucesso:\n            sucessos_ultimas_k_geracoes += 1\n\n        # Garante que sigma n\u00e3o fique muito pequeno\n        sigma = max(sigma, 1e-8)\n\n        historico.append((geracao, fitness_pai, sigma))\n\n        # Crit\u00e9rio de parada por toler\u00e2ncia (opcional)\n        if geracao &gt; 1 and abs(historico[-1][1] - historico[-2][1]) &lt; tol:\n             print(f\"\\nConverg\u00eancia atingida (toler\u00e2ncia {tol}). Parando.\")\n             break\n\n    print(f\"\\n\ud83c\udfc1 (1+1)-ES conclu\u00edda ap\u00f3s {geracao} gera\u00e7\u00f5es\")\n    print(f\"   Melhor indiv\u00edduo: {melhor_global}\")\n    print(f\"   Melhor fitness: {melhor_fitness_global:.6f}\")\n    print(f\"   Sigma final: {sigma:.6f}\")\n\n    return melhor_global, melhor_fitness_global, historico\n\n# Exemplo: Minimizar a fun\u00e7\u00e3o Esfera f(x,y) = x^2 + y^2\n# M\u00ednimo global em (0,0) com valor 0.\ndef funcao_esfera(ponto):\n    return sum(x**2 for x in ponto)\n\n# Executa o algoritmo\nif __name__ == \"__main__\":\n    dim = 2\n    limites_esfera = (-5.0, 5.0)\n\n    melhor_individuo_es, melhor_fitness_es, historico_es = estrategia_evolucao_1_mais_1(\n        funcao_esfera, \n        dimensoes=dim,\n        limites=limites_esfera,\n        sigma_inicial=2.0,\n        max_geracoes=200,\n        tol=1e-8\n    )\n\n    # Visualiza o progresso\n    geracoes_es = [h[0] for h in historico_es]\n    fitness_es = [h[1] for h in historico_es]\n    sigmas_es = [h[2] for h in historico_es]\n\n    plt.figure(figsize=(12, 8))\n\n    # Evolu\u00e7\u00e3o do Fitness\n    ax1 = plt.subplot(2, 1, 1)\n    ax1.plot(geracoes_es, fitness_es, 'b-', linewidth=1)\n    ax1.set_xlabel('Gera\u00e7\u00e3o')\n    ax1.set_ylabel('Fitness (Fun\u00e7\u00e3o Esfera)')\n    ax1.set_title('Evolu\u00e7\u00e3o do Fitness na (1+1)-ES')\n    ax1.set_yscale('log') # Escala log ajuda a ver a converg\u00eancia\n    ax1.grid(True)\n\n    # Evolu\u00e7\u00e3o de Sigma\n    ax2 = plt.subplot(2, 1, 2)\n    ax2.plot(geracoes_es, sigmas_es, 'm-', linewidth=1)\n    ax2.set_xlabel('Gera\u00e7\u00e3o')\n    ax2.set_ylabel('Sigma (Desvio Padr\u00e3o da Muta\u00e7\u00e3o)')\n    ax2.set_title('Adapta\u00e7\u00e3o do Par\u00e2metro de Estrat\u00e9gia Sigma')\n    ax2.set_yscale('log')\n    ax2.grid(True)\n\n    plt.tight_layout()\n    plt.savefig('evolution_strategy_progress.png')\n    plt.close()\n\n    print(f\"\\nVisualiza\u00e7\u00e3o do progresso salva como 'evolution_strategy_progress.png'\")\n</code></pre> <p>Explica\u00e7\u00e3o do C\u00f3digo (1+1)-ES:</p> <ol> <li><code>estrategia_evolucao_1_mais_1(...)</code>: Fun\u00e7\u00e3o principal da ES.<ul> <li>Inicializa um pai aleat\u00f3rio e seu fitness.</li> <li>Inicializa o par\u00e2metro de estrat\u00e9gia <code>sigma</code> (desvio padr\u00e3o da muta\u00e7\u00e3o).</li> <li>Entra no loop de gera\u00e7\u00f5es:<ul> <li>Cria um filho mutando o pai com ru\u00eddo Gaussiano de desvio padr\u00e3o <code>sigma</code>.</li> <li>Garante que o filho esteja dentro dos limites definidos.</li> <li>Avalia o fitness do filho.</li> <li>Sele\u00e7\u00e3o (1+1): Se o filho for melhor ou igual ao pai (para minimiza\u00e7\u00e3o), o filho se torna o novo pai.</li> <li>Adapta\u00e7\u00e3o de Sigma (Regra 1/5): A cada <code>k</code> gera\u00e7\u00f5es (aqui <code>k=10</code>), calcula a taxa de sucesso (propor\u00e7\u00e3o de muta\u00e7\u00f5es bem-sucedidas). Se a taxa for maior que 1/5, aumenta <code>sigma</code> (explora\u00e7\u00e3o); se for menor, diminui <code>sigma</code> (explota\u00e7\u00e3o). O fator de ajuste usa <code>taxa_aprendizado</code>.</li> <li>Registra o fitness e sigma no hist\u00f3rico.</li> <li>Verifica crit\u00e9rio de parada por toler\u00e2ncia.</li> </ul> </li> </ul> </li> <li>Exemplo de Uso (Fun\u00e7\u00e3o Esfera): O algoritmo \u00e9 usado para minimizar a fun\u00e7\u00e3o <code>f(x, y) = x^2 + y^2</code>, cujo m\u00ednimo \u00e9 0 em (0,0). A (1+1)-ES com adapta\u00e7\u00e3o de passo converge eficientemente para o \u00f3timo.</li> <li>Visualiza\u00e7\u00e3o: Gera gr\u00e1ficos mostrando a converg\u00eancia do fitness (em escala logar\u00edtmica) e a adapta\u00e7\u00e3o do par\u00e2metro <code>sigma</code> ao longo das gera\u00e7\u00f5es, salvando em <code>evolution_strategy_progress.png</code>.</li> </ol>"},{"location":"portfolio2/portfolio2/#4-comparacao-de-algoritmos-e-aplicacoes-praticas","title":"4. Compara\u00e7\u00e3o de Algoritmos e Aplica\u00e7\u00f5es Pr\u00e1ticas","text":""},{"location":"portfolio2/portfolio2/#41-tabela-comparativa-dos-algoritmos-implementados","title":"4.1 Tabela Comparativa dos Algoritmos Implementados","text":"<p>Tabela 1: Compara\u00e7\u00e3o dos Algoritmos de Busca Implementados</p> Algoritmo Tipo Completude Otimalidade Complexidade de Espa\u00e7o Aplica\u00e7\u00f5es T\u00edpicas IDDFS Cega Sim Sim (custos unif.) O(bd) Problemas com profundidade desconhecida, mem\u00f3ria limitada RBFS Informada Sim (se sol. alcan\u00e7\u00e1vel) Sim (heur. admiss\u00edvel) O(bd) Planejamento com heur\u00edsticas, mem\u00f3ria muito limitada Recozimento Simulado Local (Estoc\u00e1stico) N\u00e3o (probabil\u00edstico) N\u00e3o (probabil\u00edstico) O(1) Otimiza\u00e7\u00e3o global (combinat\u00f3ria/cont\u00ednua), problemas com muitos \u00f3timos locais (1+1)-ES Evolucion\u00e1rio (Local/Global) N\u00e3o (probabil\u00edstico) N\u00e3o (probabil\u00edstico) O(1) Otimiza\u00e7\u00e3o de par\u00e2metros cont\u00ednuos, auto-adapta\u00e7\u00e3o <p>Onde: - b: fator de ramifica\u00e7\u00e3o - d: profundidade da solu\u00e7\u00e3o mais rasa</p>"},{"location":"portfolio2/portfolio2/#42-discussao-sobre-aplicacoes","title":"4.2 Discuss\u00e3o sobre Aplica\u00e7\u00f5es","text":"<p>Os algoritmos implementados t\u00eam nichos de aplica\u00e7\u00e3o distintos:</p> <ul> <li>IDDFS: Excelente para buscas em \u00e1rvores ou grafos muito grandes onde a profundidade da solu\u00e7\u00e3o \u00e9 desconhecida e a mem\u00f3ria \u00e9 uma restri\u00e7\u00e3o severa, mas o custo das a\u00e7\u00f5es \u00e9 uniforme. Jogos simples, quebra-cabe\u00e7as.</li> <li>RBFS: \u00datil quando se tem uma boa heur\u00edstica (como em A), mas a mem\u00f3ria \u00e9 extremamente limitada, impedindo o armazenamento da fronteira completa de A. Pode ser mais lento que A* devido \u00e0 re-explora\u00e7\u00e3o.</li> <li>Recozimento Simulado: Poderoso para problemas de otimiza\u00e7\u00e3o (combinat\u00f3ria ou cont\u00ednua) onde a paisagem de busca \u00e9 complexa, com muitos \u00f3timos locais dos quais algoritmos como a Subida de Encosta n\u00e3o conseguiriam escapar. Exemplos: design de VLSI, problema do caixeiro viajante, treinamento de redes neurais (embora menos comum hoje).</li> <li>Estrat\u00e9gias de Evolu\u00e7\u00e3o (ES): Particularmente fortes na otimiza\u00e7\u00e3o de par\u00e2metros em espa\u00e7os cont\u00ednuos, especialmente quando a fun\u00e7\u00e3o objetivo \u00e9 ruidosa, n\u00e3o-diferenci\u00e1vel ou complexa. Usadas em design de engenharia, ajuste de controladores, otimiza\u00e7\u00e3o de par\u00e2metros de algoritmos de aprendizado de m\u00e1quina.</li> </ul>"},{"location":"portfolio2/portfolio2/#5-conclusao-e-perspectivas-futuras","title":"5. Conclus\u00e3o e Perspectivas Futuras","text":"<p>Este portf\u00f3lio explorou quatro algoritmos de busca distintos, cada um oferecendo uma abordagem diferente para navegar em espa\u00e7os de estados ou otimizar fun\u00e7\u00f5es: IDDFS, RBFS, Recozimento Simulado e Estrat\u00e9gias de Evolu\u00e7\u00e3o. A sele\u00e7\u00e3o destes algoritmos visou apresentar alternativas aos m\u00e9todos mais comuns, destacando solu\u00e7\u00f5es para desafios como limita\u00e7\u00f5es de mem\u00f3ria (IDDFS, RBFS) e otimiza\u00e7\u00e3o em paisagens complexas (Recozimento Simulado, ES).</p> <p>A IDDFS combina a otimalidade da BFS com a efici\u00eancia de mem\u00f3ria da DFS. A RBFS tenta emular a A* sob restri\u00e7\u00f5es severas de mem\u00f3ria, sacrificando potencialmente tempo de execu\u00e7\u00e3o. O Recozimento Simulado introduz aleatoriedade controlada para escapar de \u00f3timos locais em problemas de otimiza\u00e7\u00e3o. As Estrat\u00e9gias de Evolu\u00e7\u00e3o se destacam na otimiza\u00e7\u00e3o cont\u00ednua, com mecanismos de auto-adapta\u00e7\u00e3o para ajustar a busca dinamicamente.</p> <p>A escolha do algoritmo apropriado continua sendo crucial e depende intrinsecamente das caracter\u00edsticas do problema: a estrutura do espa\u00e7o de busca, a disponibilidade de heur\u00edsticas, as restri\u00e7\u00f5es computacionais (tempo e mem\u00f3ria) e a natureza da fun\u00e7\u00e3o objetivo (para otimiza\u00e7\u00e3o).</p>"},{"location":"portfolio2/portfolio2/#51-tendencias-e-desenvolvimentos-recentes","title":"5.1 Tend\u00eancias e Desenvolvimentos Recentes","text":"<p>(Esta se\u00e7\u00e3o pode ser mantida da vers\u00e3o anterior, pois as tend\u00eancias gerais s\u00e3o relevantes)</p> <ol> <li> <p>Integra\u00e7\u00e3o com Aprendizado de M\u00e1quina: Algoritmos de busca est\u00e3o sendo combinados com t\u00e9cnicas de aprendizado de m\u00e1quina para aprender heur\u00edsticas automaticamente a partir de dados, como no caso do AlphaGo da DeepMind, que combina busca em \u00e1rvore Monte Carlo com redes neurais profundas.</p> </li> <li> <p>Busca em Ambientes Parcialmente Observ\u00e1veis: Desenvolvimento de algoritmos mais robustos para lidar com incerteza e informa\u00e7\u00e3o parcial, essenciais para aplica\u00e7\u00f5es em rob\u00f3tica e sistemas aut\u00f4nomos.</p> </li> <li> <p>Algoritmos Anytime: Algoritmos que podem fornecer uma solu\u00e7\u00e3o a qualquer momento, melhorando-a progressivamente se mais tempo for disponibilizado, s\u00e3o cada vez mais importantes em aplica\u00e7\u00f5es de tempo real.</p> </li> <li> <p>Paraleliza\u00e7\u00e3o e Distribui\u00e7\u00e3o: Implementa\u00e7\u00f5es paralelas e distribu\u00eddas de algoritmos de busca para aproveitar arquiteturas de computa\u00e7\u00e3o modernas e lidar com problemas de escala muito grande.</p> </li> <li> <p>Busca Multi-objetivo: Algoritmos que podem otimizar m\u00faltiplos objetivos simultaneamente, essenciais para problemas do mundo real onde frequentemente h\u00e1 trade-offs entre diferentes crit\u00e9rios.</p> </li> </ol>"},{"location":"portfolio2/portfolio2/#desafios-e-oportunidades","title":"Desafios e Oportunidades","text":"<p>Apesar dos avan\u00e7os significativos, v\u00e1rios desafios permanecem:</p> <ol> <li> <p>Escalabilidade: Muitos problemas do mundo real t\u00eam espa\u00e7os de estados enormes que desafiam at\u00e9 mesmo os algoritmos mais eficientes.</p> </li> <li> <p>Representa\u00e7\u00e3o de Conhecimento: A efic\u00e1cia dos algoritmos de busca depende fortemente de como o problema \u00e9 representado e formulado.</p> </li> <li> <p>Equil\u00edbrio entre Explora\u00e7\u00e3o e Explota\u00e7\u00e3o: Encontrar o equil\u00edbrio certo entre explorar novas \u00e1reas do espa\u00e7o de estados e explotar conhecimento j\u00e1 adquirido continua sendo um desafio fundamental.</p> </li> <li> <p>Interpretabilidade: \u00c0 medida que os algoritmos se tornam mais complexos, garantir que suas decis\u00f5es sejam compreens\u00edveis para humanos torna-se mais dif\u00edcil, mas tamb\u00e9m mais importante.</p> </li> </ol> <p>A resolu\u00e7\u00e3o de problemas por busca continua sendo uma \u00e1rea vibrante de pesquisa e aplica\u00e7\u00e3o em IA, com novas t\u00e9cnicas e abordagens surgindo regularmente. O futuro provavelmente ver\u00e1 uma integra\u00e7\u00e3o ainda maior com outras \u00e1reas da IA, como aprendizado de m\u00e1quina e racioc\u00ednio probabil\u00edstico, levando a sistemas cada vez mais capazes de resolver problemas complexos de forma eficiente e robusta.</p>"},{"location":"portfolio2/portfolio2/#referencias-bibliograficas","title":"Refer\u00eancias Bibliogr\u00e1ficas","text":"<p>RUSSELL, S. J.; NORVIG, P. Intelig\u00eancia artificial. 3. ed. Rio de Janeiro: Elsevier Campus, 2013. (Fonte principal para a teoria)</p> <p>KORF, R. E. Depth-first iterative-deepening: An optimal admissible tree search. Artificial Intelligence, v. 27, n. 1, p. 97-109, 1985. (Refer\u00eancia chave para IDDFS)</p> <p>KORF, R. E. Linear-space best-first search. Artificial Intelligence, v. 62, n. 1, p. 41-78, 1993. (Refer\u00eancia chave para RBFS e outras buscas com mem\u00f3ria limitada)</p> <p>KIRKPATRICK, S.; GELATT, C. D.; VECCHI, M. P. Optimization by simulated annealing. Science, v. 220, n. 4598, p. 671-680, 1983. (Refer\u00eancia seminal para Recozimento Simulado)</p> <p>RECHENBERG, I. Evolutionsstrategie: Optimierung technischer Systeme nach Prinzipien der biologischen Evolution. Stuttgart: Frommann-Holzboog, 1973. (Refer\u00eancia seminal para Estrat\u00e9gias de Evolu\u00e7\u00e3o)</p> <p>SCHWEFEL, H.-P. Numerical Optimization of Computer Models. Chichester: Wiley, 1981. (Trabalho importante sobre ES)</p> <p>B\u00c4CK, T.; FOGEL, D. B.; MICHALEWICZ, Z. (Eds.). Handbook of Evolutionary Computation. Bristol: IOP Publishing Ltd. and Oxford University Press, 1997. (Vis\u00e3o geral de computa\u00e7\u00e3o evolucion\u00e1ria)</p> <p>CORMEN, T. H.; LEISERSON, C. E.; RIVEST, R. L.; STEIN, C. Introduction to Algorithms. 3. ed. Cambridge: MIT Press, 2009.</p> <p>LAVALLE, S. M. Planning Algorithms. Cambridge: Cambridge University Press, 2006.</p>"},{"location":"portfolio3/Introducao/","title":"Introdu\u00e7\u00e3o","text":""},{"location":"portfolio3/Introducao/#introducao-problemas-de-satisfacao-de-restricoes","title":"Introdu\u00e7\u00e3o Problemas de Satisfa\u00e7\u00e3o de Restri\u00e7\u00f5es","text":"<p>No vasto campo da Intelig\u00eancia Artificial, os Problemas de Satisfa\u00e7\u00e3o de Restri\u00e7\u00f5es (Constraint Satisfaction Problems - CSPs) surgem como uma classe fundamental e poderosa de problemas (LUGER, 2008). Sua relev\u00e2ncia reside na capacidade de modelar e resolver uma ampla gama de desafios pr\u00e1ticos, desde o planejamento de hor\u00e1rios e aloca\u00e7\u00e3o de recursos at\u00e9 a configura\u00e7\u00e3o de produtos e o cl\u00e1ssico quebra-cabe\u00e7a de colora\u00e7\u00e3o de mapas. A ess\u00eancia dos CSPs reside na identifica\u00e7\u00e3o de um estado ou conjunto de valores para vari\u00e1veis que satisfa\u00e7a um conjunto predefinido de limita\u00e7\u00f5es ou restri\u00e7\u00f5es.</p> <p>Uma caracter\u00edstica distintiva dos CSPs \u00e9 a sua estrutura inerente. Ao contr\u00e1rio de abordagens de busca gen\u00e9ricas que exploram um espa\u00e7o de estados de forma at\u00f4mica, os algoritmos de CSPs exploram a estrutura das restri\u00e7\u00f5es para eliminar grandes por\u00e7\u00f5es do espa\u00e7o de busca de maneira eficiente. Isso \u00e9 frequentemente alcan\u00e7ado atrav\u00e9s da propaga\u00e7\u00e3o de restri\u00e7\u00f5es, uma t\u00e9cnica que ajusta os poss\u00edveis valores de vari\u00e1veis com base nas restri\u00e7\u00f5es existentes e nas atribui\u00e7\u00f5es j\u00e1 feitas, garantindo a consist\u00eancia local e podando ramos invi\u00e1veis da \u00e1rvore de busca (RUSSELL; NORVIG, 2010).</p> <p>A representa\u00e7\u00e3o de um CSP \u00e9 frequentemente visualizada atrav\u00e9s de um grafo de restri\u00e7\u00f5es, onde os n\u00f3s simbolizam as vari\u00e1veis e as arestas (ou hiperarestas) representam as restri\u00e7\u00f5es que envolvem essas vari\u00e1veis. Essa abstra\u00e7\u00e3o n\u00e3o apenas facilita a compreens\u00e3o do problema, mas tamb\u00e9m orienta a aplica\u00e7\u00e3o de heur\u00edsticas e algoritmos espec\u00edficos. Exemplos cl\u00e1ssicos, como a colora\u00e7\u00e3o de mapas (onde regi\u00f5es adjacentes n\u00e3o podem ter a mesma cor), o problema das N-Rainhas (posicionar N rainhas em um tabuleiro NxN sem que se ataquem) e o planejamento de tarefas em linhas de montagem (respeitando preced\u00eancias e recursos), ilustram a versatilidade e aplicabilidade dos CSPs.</p> <p>Este portf\u00f3lio explora os conceitos fundamentais dos CSPs, suas t\u00e9cnicas de resolu\u00e7\u00e3o e sua conex\u00e3o com o paradigma de agentes inteligentes, demonstrando como essa abordagem contribui significativamente para a constru\u00e7\u00e3o de sistemas capazes de raciocinar e encontrar solu\u00e7\u00f5es em ambientes complexos e restritos.</p>"},{"location":"portfolio3/Introducao/#bibliografia","title":"Bibliografia","text":"<p>LUGER, George F. Artificial Intelligence: Structures and Strategies for Complex Problem Solving. 6th ed. Boston: Addison-Wesley, 2008.</p> <p>RUSSELL, Stuart J.; NORVIG, Peter. Artificial Intelligence: A Modern Approach. 3rd ed. Upper Saddle River, NJ: Prentice Hall, 2010.</p> <p>SUTTON, Richard S.; BARTO, Andrew G. Reinforcement Learning: An Introduction. 2nd ed. Cambridge, MA: MIT Press, 2018.</p> Vers\u00e3o Data Modifica\u00e7\u00e3o Nome GitHub <code>1.0</code> 03/06/2025 Cria\u00e7\u00e3o do documento Ana Beatriz Norberto @ananorberto"},{"location":"portfolio3/conceitos/","title":"Conceitos","text":""},{"location":"portfolio3/conceitos/#aprofundando-em-csps-conceitos-e-aplicacao","title":"Aprofundando em CSPs: Conceitos e Aplica\u00e7\u00e3o","text":""},{"location":"portfolio3/conceitos/#definicao-formal","title":"Defini\u00e7\u00e3o Formal","text":"<p>Um Problema de Satisfa\u00e7\u00e3o de Restri\u00e7\u00f5es (CSP) \u00e9 formalmente definido por tr\u00eas componentes:</p> <ul> <li>Vari\u00e1veis (X): Um conjunto de vari\u00e1veis {X\u2081, X\u2082, ..., Xn}.</li> <li>Dom\u00ednios (D): Um conjunto de dom\u00ednios {D\u2081, D\u2082, ..., Dn}, onde cada Di \u00e9 o conjunto finito de valores poss\u00edveis para a vari\u00e1vel Xi.</li> <li>Restri\u00e7\u00f5es (C): Um conjunto de restri\u00e7\u00f5es {C\u2081, C\u2082, ..., Ck}. Cada restri\u00e7\u00e3o Cj especifica uma combina\u00e7\u00e3o permitida de valores para um subconjunto de vari\u00e1veis.</li> </ul> <p>Uma solu\u00e7\u00e3o para um CSP \u00e9 uma atribui\u00e7\u00e3o completa e consistente de valores para todas as vari\u00e1veis, ou seja, uma atribui\u00e7\u00e3o onde cada vari\u00e1vel Xi recebe um valor de seu dom\u00ednio Di, e todas as restri\u00e7\u00f5es Cj s\u00e3o satisfeitas (RUSSELL; NORVIG, 2010).</p>"},{"location":"portfolio3/conceitos/#exemplo-pratico-coloracao-de-mapas","title":"Exemplo Pr\u00e1tico: Colora\u00e7\u00e3o de Mapas","text":"<p>Consideremos o problema cl\u00e1ssico de colorir um mapa de forma que regi\u00f5es adjacentes n\u00e3o tenham a mesma cor, usando um n\u00famero limitado de cores (por exemplo, Vermelho, Verde, Azul).</p> <ul> <li>Vari\u00e1veis (X): Cada regi\u00e3o do mapa (ex: Regi\u00e3o A, Regi\u00e3o B, ...).</li> <li>Dom\u00ednios (D): O conjunto de cores dispon\u00edveis para cada regi\u00e3o (ex: {Vermelho, Verde, Azul}).</li> <li>Restri\u00e7\u00f5es (C): Para cada par de regi\u00f5es adjacentes (ex: Regi\u00e3o A e Regi\u00e3o B), a restri\u00e7\u00e3o \u00e9 que suas cores atribu\u00eddas devem ser diferentes (Cor(A) \u2260 Cor(B)).</li> </ul> <p>O grafo de restri\u00e7\u00f5es neste caso teria as regi\u00f5es como n\u00f3s e uma aresta entre duas regi\u00f5es se elas forem adjacentes.</p>"},{"location":"portfolio3/conceitos/#modelagem-peas-performance-environment-actuators-sensors","title":"Modelagem PEAS (Performance, Environment, Actuators, Sensors)","text":"<p>Podemos modelar um agente que resolve o problema de colora\u00e7\u00e3o de mapas usando o framework PEAS (RUSSELL; NORVIG, 2010):</p> <ul> <li>P (Performance Measure - Medida de Desempenho): Completa a colora\u00e7\u00e3o do mapa satisfazendo todas as restri\u00e7\u00f5es (regi\u00f5es adjacentes com cores diferentes). Idealmente, minimiza o n\u00famero de cores usadas ou o tempo de resolu\u00e7\u00e3o.</li> <li>E (Environment - Ambiente): O mapa a ser colorido, definido por suas regi\u00f5es e adjac\u00eancias. O ambiente \u00e9 est\u00e1tico (o mapa n\u00e3o muda), discreto (n\u00famero finito de regi\u00f5es e cores) e conhecido (a estrutura do mapa \u00e9 dada).</li> <li>A (Actuators - Atuadores): A capacidade de atribuir uma cor a uma regi\u00e3o espec\u00edfica.</li> <li>S (Sensors - Sensores): A capacidade de perceber o estado atual da colora\u00e7\u00e3o, incluindo quais regi\u00f5es s\u00e3o adjacentes e quais cores j\u00e1 foram atribu\u00eddas a elas e a seus vizinhos.</li> </ul>"},{"location":"portfolio3/conceitos/#34-tecnicas-de-resolucao-e-propagacao-de-restricoes","title":"3.4 T\u00e9cnicas de Resolu\u00e7\u00e3o e Propaga\u00e7\u00e3o de Restri\u00e7\u00f5es","text":"<p>A resolu\u00e7\u00e3o de CSPs frequentemente envolve algoritmos de busca, como o Backtracking Search (RUSSELL; NORVIG, 2010). No entanto, a efici\u00eancia desses algoritmos \u00e9 drasticamente melhorada pela propaga\u00e7\u00e3o de restri\u00e7\u00f5es. Essa t\u00e9cnica usa as restri\u00e7\u00f5es para reduzir o n\u00famero de valores legais para uma vari\u00e1vel, o que pode, por sua vez, reduzir os valores legais para outras vari\u00e1veis.</p> <ul> <li>Forward Checking: Quando uma vari\u00e1vel X recebe um valor, o Forward Checking verifica cada vari\u00e1vel Y n\u00e3o atribu\u00edda que est\u00e1 conectada a X por uma restri\u00e7\u00e3o e remove de Dy qualquer valor inconsistente com o valor atribu\u00eddo a X.</li> <li>Consist\u00eancia de Arco (AC-3): Este algoritmo busca tornar o grafo de restri\u00e7\u00f5es arco-consistente. Um arco (Xi, Xj) \u00e9 consistente se, para cada valor x no dom\u00ednio Di, existe algum valor y no dom\u00ednio Dj que satisfaz a restri\u00e7\u00e3o bin\u00e1ria entre Xi e Xj. O AC-3 remove iterativamente valores dos dom\u00ednios que n\u00e3o podem satisfazer a consist\u00eancia de arco, potencialmente simplificando muito o problema antes ou durante a busca.</li> </ul> <p>A propaga\u00e7\u00e3o de restri\u00e7\u00f5es ajuda a detectar falhas mais cedo no processo de busca, podando sub\u00e1rvores inteiras que n\u00e3o levariam a uma solu\u00e7\u00e3o.</p>"},{"location":"portfolio3/conceitos/#algoritmo-exemplo-backtracking-search-para-csps","title":"Algoritmo Exemplo: Backtracking Search para CSPs","text":"<p>O algoritmo de Backtracking \u00e9 uma abordagem fundamental para resolver CSPs. Ele funciona atribuindo valores \u00e0s vari\u00e1veis uma a uma e, ao encontrar uma atribui\u00e7\u00e3o que viola uma restri\u00e7\u00e3o, ele </p> <p>retrocede (backtracks).</p> <p>Pseudoc\u00f3digo do Algoritmo de Backtracking para CSPs:</p> <pre><code>fun\u00e7\u00e3o BACKTRACKING-SEARCH(csp)\n    retorna BACKTRACK({}, csp)\n\nfun\u00e7\u00e3o BACKTRACK(atribui\u00e7\u00e3o, csp)\n    se atribui\u00e7\u00e3o est\u00e1 completa ent\u00e3o retorna atribui\u00e7\u00e3o\n\n    var \u2190 SELECIONAR-VARI\u00c1VEL-N\u00c3O-ATRIBU\u00cdDA(csp)\n\n    para cada valor em ORDENAR-VALORES-DOM\u00cdNIO(var, atribui\u00e7\u00e3o, csp) fazer\n        se valor \u00e9 consistente com atribui\u00e7\u00e3o de acordo com as restri\u00e7\u00f5es de csp ent\u00e3o\n            adicionar {var = valor} \u00e0 atribui\u00e7\u00e3o\n            infer\u00eancias \u2190 INFER\u00caNCIA(csp, var, valor) // Ex: Forward Checking, AC-3\n            se infer\u00eancias \u2260 falha ent\u00e3o\n                adicionar infer\u00eancias \u00e0 atribui\u00e7\u00e3o\n                resultado \u2190 BACKTRACK(atribui\u00e7\u00e3o, csp)\n                se resultado \u2260 falha ent\u00e3o\n                    retorna resultado\n            remover {var = valor} e infer\u00eancias da atribui\u00e7\u00e3o\n\n    retorna falha\n</code></pre> <p>Explica\u00e7\u00e3o do Pseudoc\u00f3digo:</p> <ol> <li><code>BACKTRACKING-SEARCH(csp)</code>: Inicia a busca com uma atribui\u00e7\u00e3o vazia.</li> <li><code>BACKTRACK(atribui\u00e7\u00e3o, csp)</code>:<ul> <li>Verifica\u00e7\u00e3o de Conclus\u00e3o: Se todas as vari\u00e1veis receberam valores consistentes, a solu\u00e7\u00e3o foi encontrada e \u00e9 retornada.</li> <li>Sele\u00e7\u00e3o de Vari\u00e1vel: Escolhe uma vari\u00e1vel ainda n\u00e3o atribu\u00edda (heur\u00edsticas como Minimum Remaining Values - MRV podem ser usadas aqui).</li> <li>Itera\u00e7\u00e3o de Valores: Para cada valor poss\u00edvel no dom\u00ednio da vari\u00e1vel selecionada (heur\u00edsticas como Least Constraining Value - LCV podem ordenar os valores):<ul> <li>Verifica\u00e7\u00e3o de Consist\u00eancia: Verifica se atribuir o valor atual \u00e0 vari\u00e1vel viola alguma restri\u00e7\u00e3o com as vari\u00e1veis j\u00e1 atribu\u00eddas.</li> <li>Atribui\u00e7\u00e3o e Infer\u00eancia: Se consistente, o valor \u00e9 temporariamente atribu\u00eddo. T\u00e9cnicas de infer\u00eancia (propaga\u00e7\u00e3o de restri\u00e7\u00f5es como Forward Checking ou AC-3) s\u00e3o aplicadas para deduzir consequ\u00eancias dessa atribui\u00e7\u00e3o e reduzir dom\u00ednios de outras vari\u00e1veis.</li> <li>Chamada Recursiva: Se a infer\u00eancia n\u00e3o detectou inconsist\u00eancias, a fun\u00e7\u00e3o <code>BACKTRACK</code> \u00e9 chamada recursivamente para a pr\u00f3xima vari\u00e1vel.</li> <li>Backtracking: Se a chamada recursiva falhar (n\u00e3o encontrar solu\u00e7\u00e3o a partir dali) ou se o valor inicial n\u00e3o for consistente ou a infer\u00eancia falhar, a atribui\u00e7\u00e3o tempor\u00e1ria e as infer\u00eancias s\u00e3o removidas, e o algoritmo tenta o pr\u00f3ximo valor. Se nenhum valor funcionar para a vari\u00e1vel atual, a fun\u00e7\u00e3o retorna falha, indicando a necessidade de retroceder na chamada anterior.</li> </ul> </li> </ul> </li> </ol> <p>Este algoritmo, combinado com heur\u00edsticas eficientes de sele\u00e7\u00e3o de vari\u00e1veis/valores e t\u00e9cnicas de propaga\u00e7\u00e3o de restri\u00e7\u00f5es, forma a base para resolver muitos CSPs complexos de forma eficaz.</p>"},{"location":"portfolio3/conceitos/#bibliografia","title":"Bibliografia","text":"<p>LUGER, George F. Artificial Intelligence: Structures and Strategies for Complex Problem Solving. 6th ed. Boston: Addison-Wesley, 2008.</p> <p>RUSSELL, Stuart J.; NORVIG, Peter. Artificial Intelligence: A Modern Approach. 3rd ed. Upper Saddle River, NJ: Prentice Hall, 2010.</p> <p>SUTTON, Richard S.; BARTO, Andrew G. Reinforcement Learning: An Introduction. 2nd ed. Cambridge, MA: MIT Press, 2018.</p> Vers\u00e3o Data Modifica\u00e7\u00e3o Nome GitHub <code>1.0</code> 03/06/2025 Cria\u00e7\u00e3o do documento Ana Beatriz Norberto @ananorberto"},{"location":"portfolio3/conclusao/","title":"Conclus\u00e3o","text":""},{"location":"portfolio3/conclusao/#conclusao-a-relevancia-dos-csps-na-ia-moderna","title":"Conclus\u00e3o: A Relev\u00e2ncia dos CSPs na IA Moderna","text":"<p>A an\u00e1lise dos Problemas de Satisfa\u00e7\u00e3o de Restri\u00e7\u00f5es (CSPs) revela sua import\u00e2ncia fundamental como uma metodologia robusta e vers\u00e1til dentro da Intelig\u00eancia Artificial. A capacidade de modelar problemas atrav\u00e9s de vari\u00e1veis, dom\u00ednios e restri\u00e7\u00f5es permite uma representa\u00e7\u00e3o estruturada que facilita a aplica\u00e7\u00e3o de algoritmos de busca especializados. A grande vantagem dos CSPs reside na explora\u00e7\u00e3o eficiente do espa\u00e7o de busca, principalmente atrav\u00e9s da propaga\u00e7\u00e3o de restri\u00e7\u00f5es, que poda ramos invi\u00e1veis e acelera a converg\u00eancia para uma solu\u00e7\u00e3o ou a determina\u00e7\u00e3o de sua inexist\u00eancia.</p> <p>A aplica\u00e7\u00e3o de t\u00e9cnicas como Backtracking Search, aprimorada por heur\u00edsticas (MRV, LCV) e mecanismos de infer\u00eancia (Forward Checking, AC-3), demonstra a sofistica\u00e7\u00e3o alcan\u00e7ada na resolu\u00e7\u00e3o desses problemas. A modelagem PEAS contextualiza a aplica\u00e7\u00e3o de CSPs no desenvolvimento de agentes inteligentes, conectando a teoria \u00e0 pr\u00e1tica de construir sistemas que percebem, raciocinam e agem em ambientes restritos.</p> <p>O estudo cont\u00ednuo e o aprimoramento das t\u00e9cnicas de CSPs s\u00e3o essenciais para avan\u00e7ar em \u00e1reas como planejamento, escalonamento, design e diagn\u00f3stico autom\u00e1tico. A compreens\u00e3o profunda desses conceitos n\u00e3o apenas enriquece a forma\u00e7\u00e3o do estudante de IA, mas tamb\u00e9m fornece ferramentas poderosas para enfrentar desafios complexos do mundo real, refor\u00e7ando o papel central da IA na solu\u00e7\u00e3o de problemas intrincados.</p>"},{"location":"portfolio3/conclusao/#bibliografia","title":"Bibliografia","text":"<p>LUGER, George F. Artificial Intelligence: Structures and Strategies for Complex Problem Solving. 6th ed. Boston: Addison-Wesley, 2008.</p> <p>RUSSELL, Stuart J.; NORVIG, Peter. Artificial Intelligence: A Modern Approach. 3rd ed. Upper Saddle River, NJ: Prentice Hall, 2010.</p> <p>SUTTON, Richard S.; BARTO, Andrew G. Reinforcement Learning: An Introduction. 2nd ed. Cambridge, MA: MIT Press, 2018.</p> Vers\u00e3o Data Modifica\u00e7\u00e3o Nome GitHub <code>1.0</code> 03/06/2025 Cria\u00e7\u00e3o do documento Ana Beatriz Norberto @ananorberto"},{"location":"portfolio4/1introducao/","title":"Introdu\u00e7\u00e3o aos Agentes L\u00f3gicos na Intelig\u00eancia Artificial","text":"<p>A Intelig\u00eancia Artificial (IA) \u00e9 um campo muito vasto intrigante, cujo objetivo principal \u00e9 estudar e construir agentes inteligentes capazes de perceber o ambiente e realizar a\u00e7\u00f5es (Russell &amp; Norvig, 2010, p. 5). Dentre as diversas abordagens para se alcan\u00e7ar a intelig\u00eancia artificial, a dos agentes l\u00f3gicos se destaca por focar na capacidade de um agente de raciocinar sobre o conhecimento. Para mim, o mais interessante \u00e9 como essa abordagem permite que os agentes formem representa\u00e7\u00f5es complexas do mundo, utilizem processos de infer\u00eancia para derivar novas informa\u00e7\u00f5es e, a partir delas, deduzam a melhor forma de agir.</p> <p>A hist\u00f3ria dos agentes l\u00f3gicos remonta a ra\u00edzes profundas na filosofia. Tudo come\u00e7ou, em certa medida, com Arist\u00f3teles (384-322 a.C.), que foi o primeiro a formalizar um conjunto de leis que governavam a parte racional da mente, estabelecendo as bases para o racioc\u00ednio l\u00f3gico (Russell &amp; Norvig, 2010, p. 36). S\u00e9culos depois, no contexto da IA, um marco importante foi o trabalho de Warren McCulloch e Walter Pitts em 1943, que propuseram um modelo de neur\u00f4nios artificiais baseado na l\u00f3gica proposicional (Russell &amp; Norvig, 2010). Posteriormente, Allen Newell e Herbert Simon apresentaram o Logic Theorist (LT) em 1956, um dos primeiros programas de racioc\u00ednio, e as contribui\u00e7\u00f5es de John McCarthy em 1958, com a linguagem Lisp e a concep\u00e7\u00e3o do Advice Taker, foram cruciais. McCarthy defendia a ideia central de ter uma representa\u00e7\u00e3o formal e expl\u00edcita do mundo e a capacidade de manipul\u00e1-la com processos dedutivos, inaugurando o que se conhece como a abordagem declarativa para a constru\u00e7\u00e3o de sistemas (Russell &amp; Norvig, 2010).</p> <p>A principal caracter\u00edstica de um agente l\u00f3gico \u00e9 sua Base de Conhecimento (KB), que \u00e9 um conjunto de senten\u00e7as expressas em uma linguagem de representa\u00e7\u00e3o de conhecimento (Russell &amp; Norvig, 2010, p. 118, 133). O agente interage com essa base de conhecimento por meio de duas opera\u00e7\u00f5es fundamentais: TELL, que informa \u00e0 KB o que o agente percebe ou as a\u00e7\u00f5es que executa, e ASK, que consulta a KB para determinar qual a\u00e7\u00e3o deve ser realizada (Russell &amp; Norvig, 2010, p. 119). Para ilustrar esses conceitos, Russell e Norvig (2010) apresentam o Mundo do Wumpus, um ambiente simples que permite demonstrar como um agente l\u00f3gico pode inferir informa\u00e7\u00f5es (como a localiza\u00e7\u00e3o de po\u00e7os ou do Wumpus) a partir de seus perceptos (brisa, fedor), garantindo que as conclus\u00f5es s\u00e3o corretas se as informa\u00e7\u00f5es iniciais tamb\u00e9m forem, uma propriedade fundamental do racioc\u00ednio l\u00f3gico (Russell &amp; Norvig, 2010).</p> <p>No entanto, a complexidade do mundo real logo imp\u00f5e desafios a esses agentes puramente l\u00f3gicos. Algo que me chamou a aten\u00e7\u00e3o, e que \u00e9 refor\u00e7ado pelos slides da disciplina, \u00e9 que agentes no mundo real precisam lidar com a incerteza, seja por observabilidade parcial, n\u00e3o determinismo ou adversidades (FGA0221 \u2013 IA, s.d.). Assim como visto em sala, os agentes l\u00f3gicos e solucionadores de problemas, tendem a lidar com a incerteza acompanhando todos os estados de mundo poss\u00edveis, o que pode levar a um crescimento arbitr\u00e1rio dos planos de conting\u00eancia (FGA0221 \u2013 IA, s.d.). Russell e Norvig (2010, p. 369, 370) refor\u00e7am essa ideia ao afirmar que tentar usar a l\u00f3gica proposicional para dom\u00ednios complexos, como o diagn\u00f3stico m\u00e9dico, \u00e9 impratic\u00e1vel devido \u00e0 necessidade de listar um conjunto exaustivo de antecedentes e consequentes (o problema da qualifica\u00e7\u00e3o), e \u00e0 ignor\u00e2ncia te\u00f3rica e pr\u00e1tica inerente a esses dom\u00ednios. A l\u00f3gica proposicional, por si s\u00f3, n\u00e3o tem expressividade suficiente para ambientes de tamanho ilimitado, como o tempo, o espa\u00e7o e os padr\u00f5es universais (Russell &amp; Norvig, 2010, p. 134).</p> <p>Para superar essas limita\u00e7\u00f5es, foi poss\u00edvel que a IA evoluiu para integrar a teoria da probabilidade. De acordo com o conte\u00fado da aula, a teoria da probabilidade fornece uma maneira de resumir a incerteza que vem da nossa falta de tempo e ignor\u00e2ncia, resolvendo assim o problema da qualifica\u00e7\u00e3o, ao permitir que o agente tenha um grau num\u00e9rico de cren\u00e7a entre 0 e 1 (FGA0221 \u2013 IA, s.d.). Essa transi\u00e7\u00e3o \u00e9 fundamental, e a pr\u00f3xima etapa natural \u00e9 a utiliza\u00e7\u00e3o da L\u00f3gica de Primeira Ordem, uma linguagem muito mais poderosa capaz de representar conhecimento de forma mais concisa e expressiva (Russell &amp; Norvig, 2010).</p> <p>Neste portf\u00f3lio, pretendo aprofundar a compreens\u00e3o sobre os agentes l\u00f3gicos, desde seus fundamentos em l\u00f3gica proposicional at\u00e9 a necessidade de linguagens mais expressivas. Al\u00e9m disso, explorarei como o racioc\u00ednio probabil\u00edstico, em particular as Redes Bayesianas, se torna uma ferramenta indispens\u00e1vel para lidar com a incerteza, permitindo que os agentes tomem decis\u00f5es racionais mesmo em ambientes complexos e imprevis\u00edveis.</p>"},{"location":"portfolio4/1introducao/#referencias","title":"Refer\u00eancias","text":"<p>FGA0221 \u2013 Intelig\u00eancia Artificial. (s.d.). Quantificando Incertezas. Slides da disciplina.</p> <p>FGA0221 \u2013 Intelig\u00eancia Artificial. (s.d.). Quantificando Incertezas \u2013 2\u00aa Parte. Slides da disciplina.</p> <p>FGA0221 \u2013 Intelig\u00eancia Artificial. (s.d.). Redes Bayesianas. Slides da disciplina.</p> <p>Russell, S. J., &amp; Norvig, P. (2010). Artificial Intelligence: A Modern Approach (3rd ed.). Prentice Hall.</p> Vers\u00e3o Data Modifica\u00e7\u00e3o Nome GitHub <code>1.0</code> 23/06/2025 Cria\u00e7\u00e3o do documento Ana Beatriz Norberto @ananorberto"},{"location":"portfolio4/2conceitos/","title":"Agentes L\u00f3gicos: Representando o Conhecimento e Raciocinando sobre o Mundo","text":"<p>Este t\u00f3pico do portf\u00f3lio aprofundar\u00e1 o conceito de agentes l\u00f3gicos, uma abordagem fundamental na Intelig\u00eancia Artificial que visa construir sistemas capazes de raciocinar sobre o conhecimento. Os agentes inteligentes no mundo real precisam lidar com a incerteza e tomar decis\u00f5es baseadas em informa\u00e7\u00f5es, e os agentes l\u00f3gicos oferecem uma base para isso atrav\u00e9s da representa\u00e7\u00e3o expl\u00edcita de conhecimento e do uso de processos de infer\u00eancia para derivar novas conclus\u00f5es.</p>"},{"location":"portfolio4/2conceitos/#1-definicao-e-importancia-dos-agentes-logicos","title":"1. Defini\u00e7\u00e3o e Import\u00e2ncia dos Agentes L\u00f3gicos","text":"<p>Agentes l\u00f3gicos s\u00e3o sistemas de IA que utilizam a l\u00f3gica para representar o conhecimento sobre o mundo e para raciocinar sobre esse conhecimento, a fim de tomar decis\u00f5es. A ideia central \u00e9 que a intelig\u00eancia pode ser alcan\u00e7ada por meio de representa\u00e7\u00f5es internas de conhecimento e processos de racioc\u00ednio que operam sobre essas representa\u00e7\u00f5es (RUSSELL; NORVIG, 2010, p. 234).</p> <p>A import\u00e2ncia dessa abordagem \u00e9 imensa. Ao inv\u00e9s de meros mecanismos reflexivos, agentes l\u00f3gicos podem combinar e recombinar informa\u00e7\u00f5es para m\u00faltiplos prop\u00f3sitos, adaptar-se a mudan\u00e7as no ambiente atualizando seu conhecimento e aceitar novas tarefas na forma de objetivos explicitamente descritos (RUSSELL; NORVIG, 2010, p. 235). Essa capacidade de racioc\u00ednio simb\u00f3lico foi um dos pilares iniciais da IA e continua sendo relevante para a compreens\u00e3o de como sistemas inteligentes podem funcionar.</p>"},{"location":"portfolio4/2conceitos/#2-arquitetura-geral-dos-agentes-baseados-em-conhecimento","title":"2. Arquitetura Geral dos Agentes Baseados em Conhecimento","text":"<p>A estrutura de um agente l\u00f3gico \u00e9 centrada em sua Base de Conhecimento (KB), que \u00e9 um conjunto de senten\u00e7as que representam assertions sobre o mundo. Russell e Norvig (2010, p. 235) definem uma senten\u00e7a como um termo t\u00e9cnico, expressa em uma linguagem de representa\u00e7\u00e3o de conhecimento. O agente interage com essa KB por meio de duas opera\u00e7\u00f5es b\u00e1sicas:</p> <ul> <li>TELL: Adiciona novas senten\u00e7as \u00e0 KB, informando o agente sobre o que ele percebe no ambiente (seus perceptos) ou as a\u00e7\u00f5es que executa.</li> <li>ASK: Consulta a KB para determinar que a\u00e7\u00e3o deve ser realizada, fazendo perguntas sobre o estado do mundo e poss\u00edveis consequ\u00eancias.</li> </ul> <p>Essa arquitetura b\u00e1sica pode ser visualizada no pseudoc\u00f3digo <code>KB-AGENT</code> (RUSSELL; NORVIG, 2010, p. 236):</p> <pre><code>function KB-AGENT(percept) returns an action\n  persistent: KB, a knowledge base\n              t, a counter, initially 0, indicating time\n  TELL(KB, MAKE-PERCEPT-SENTENCE(percept, t))\n  action &lt;- ASK(KB, MAKE-ACTION-QUERY(t))\n  TELL(KB, MAKE-ACTION-SENTENCE(action, t))\n  t &lt;- t + 1\n  return action\n</code></pre> <p>Como visto em sala nos slides (FGA0221 \u2013IA, s.d., Redes Bayesianas), a base de conhecimento de uma rede Bayesiana tamb\u00e9m carrega informa\u00e7\u00f5es de probabilidade em seus n\u00f3s. Essa arquitetura permite uma abordagem declarativa para a constru\u00e7\u00e3o de sistemas, onde o designer \"diz\" ao agente o que ele precisa saber, ao inv\u00e9s de codificar diretamente os comportamentos desejados (RUSSELL; NORVIG, 2010, p. 236).</p>"},{"location":"portfolio4/2conceitos/#3-o-mundo-do-wumpus-como-exemplo-de-ambiente","title":"3. O Mundo do Wumpus como Exemplo de Ambiente","text":"<p>Para ilustrar o funcionamento de um agente l\u00f3gico, Russell e Norvig (2010, p. 236) introduzem um ambiente simples, mas desafiador: o Mundo do Wumpus. Este ambiente, geralmente representado como uma grade de quadrados, cont\u00e9m um Wumpus (um monstro que come quem entrar em seu quadrado), po\u00e7os (que matam quem cair neles) e ouro (o objetivo do agente). O agente tem sensores limitados:</p> <ul> <li>Brisa: Sentida em quadrados adjacentes a um po\u00e7o.</li> <li>Fedor: Sentido em quadrados adjacentes ao Wumpus.</li> <li>Brilho: Sentido no quadrado que cont\u00e9m o ouro.</li> <li>Batida: Sentida ao bater em uma parede.</li> <li>Grito: Ouvido quando o Wumpus morre.</li> </ul> <p>O ambiente do Wumpus \u00e9 caracterizado como discreto, est\u00e1tico e de agente \u00fanico, mas tamb\u00e9m \u00e9 parcialmente observ\u00e1vel, pois o agente n\u00e3o pode ver diretamente a localiza\u00e7\u00e3o dos po\u00e7os ou do Wumpus, apenas seus efeitos indiretos (RUSSELL; NORVIG, 2010, p. 237).</p> <p>A partir dos perceptos, o agente usa seu racioc\u00ednio l\u00f3gico para inferir informa\u00e7\u00f5es sobre o ambiente e tomar decis\u00f5es seguras. Por exemplo, se o agente est\u00e1 no quadrado e n\u00e3o sente brisa nem fedor, ele pode inferir que os quadrados adjacentes e s\u00e3o seguros (RUSSELL; NORVIG, 2010, p. 238). Uma propriedade fundamental do racioc\u00ednio l\u00f3gico, crucial para o agente do Wumpus, \u00e9 que as conclus\u00f5es s\u00e3o garantidas como corretas se as informa\u00e7\u00f5es iniciais forem corretas (RUSSELL; NORVIG, 2010, p. 240).</p>"},{"location":"portfolio4/2conceitos/#4-elementos-da-logica-proposicional","title":"4. Elementos da L\u00f3gica Proposicional","text":"<p>A l\u00f3gica proposicional \u00e9 uma das linguagens l\u00f3gicas mais simples, mas j\u00e1 permite ilustrar todos os conceitos b\u00e1sicos da l\u00f3gica (RUSSELL; NORVIG, 2010, p. 243).</p>"},{"location":"portfolio4/2conceitos/#41-sintaxe","title":"4.1. Sintaxe","text":"<p>A sintaxe da l\u00f3gica proposicional define as senten\u00e7as permitidas. Ela \u00e9 composta por: *   S\u00edmbolos de proposi\u00e7\u00e3o: Representam proposi\u00e7\u00f5es que podem ser verdadeiras ou falsas (ex: <code>P1,2</code>, <code>B2,1</code>, <code>WumpusAlive</code>). Existem tamb\u00e9m <code>True</code> (sempre verdadeiro) e <code>False</code> (sempre falso) (RUSSELL; NORVIG, 2010, p. 244). *   Conectivos l\u00f3gicos: Permitem construir senten\u00e7as complexas a partir de senten\u00e7as mais simples, utilizando par\u00eanteses. Os conectivos s\u00e3o:</p> <pre><code>*   `\u00ac` (nega\u00e7\u00e3o)\n*   `\u2227` (conjun\u00e7\u00e3o)\n*   `\u2228` (disjun\u00e7\u00e3o)\n*   `\u21d2` (implica\u00e7\u00e3o)\n*   `\u21d4` (bicondicional)\n</code></pre>"},{"location":"portfolio4/2conceitos/#42-semantica","title":"4.2. Sem\u00e2ntica","text":"<p>A sem\u00e2ntica de uma linguagem l\u00f3gica define o significado das senten\u00e7as, ou seja, como a verdade de uma senten\u00e7a \u00e9 determinada (RUSSELL; NORVIG, 2010, p. 243). Na l\u00f3gica proposicional, isso \u00e9 feito atrav\u00e9s de modelos. Um modelo \u00e9 uma atribui\u00e7\u00e3o de valores de verdade (verdadeiro/falso) para cada s\u00edmbolo de proposi\u00e7\u00e3o (RUSSELL; NORVIG, 2010, p. 245). Por exemplo, para um pequeno conjunto de s\u00edmbolos, podemos listar todos os 2^n poss\u00edveis modelos. Uma senten\u00e7a \u00e9 verdadeira em um modelo se a atribui\u00e7\u00e3o de valores de verdade a seus s\u00edmbolos resulta em \"verdadeiro\" de acordo com as regras dos conectivos l\u00f3gicos.</p> <p>Russell e Norvig (2010, p. 242) tamb\u00e9m discutem o conceito de grounding, que \u00e9 a conex\u00e3o entre os processos de racioc\u00ednio l\u00f3gico e o ambiente real. Nossos sensores criam essa conex\u00e3o: se o agente detecta um fedor, ele cria uma senten\u00e7a que afirma \"h\u00e1 fedor\". Essa senten\u00e7a, ao ser adicionada \u00e0 base de conhecimento, passa a ser considerada verdadeira no mundo real.</p>"},{"location":"portfolio4/2conceitos/#43-entailment","title":"4.3. Entailment","text":"<p>O conceito de entailment (implica\u00e7\u00e3o l\u00f3gica) \u00e9 central para o racioc\u00ednio. Uma senten\u00e7a <code>\u03b1</code> \u00e9 entailed por uma base de conhecimento <code>KB</code> (escrito <code>KB |= \u03b1</code>) se <code>\u03b1</code> \u00e9 verdadeira em todos os modelos em que <code>KB</code> \u00e9 verdadeira (RUSSELL; NORVIG, 2010, p. 247). Isso significa que se tudo na <code>KB</code> for verdade, ent\u00e3o <code>\u03b1</code> tamb\u00e9m deve ser verdade. O objetivo dos algoritmos de infer\u00eancia \u00e9 determinar se <code>KB |= \u03b1</code>.</p>"},{"location":"portfolio4/2conceitos/#5-processos-de-inferencia","title":"5. Processos de Infer\u00eancia","text":"<p>A infer\u00eancia \u00e9 o processo de derivar novas senten\u00e7as a partir da base de conhecimento. Para agentes l\u00f3gicos, essa \u00e9 a capacidade de \"pensar\" e tirar conclus\u00f5es.</p>"},{"location":"portfolio4/2conceitos/#51-model-checking","title":"5.1. Model Checking","text":"<p>Uma forma direta de verificar o entailment \u00e9 o model checking. Isso envolve enumerar todos os modelos poss\u00edveis, e para cada modelo em que a KB \u00e9 verdadeira, verificar se a senten\u00e7a <code>\u03b1</code> tamb\u00e9m \u00e9 verdadeira (RUSSELL; NORVIG, 2010, p. 247). O algoritmo <code>TT-ENTAILS?</code> (Truth-Table Enumeration) faz exatamente isso.</p> <p><pre><code>function TT-ENTAILS?(KB, alpha) returns true or false\n  symbols &lt;- a list of all proposition symbols in KB and alpha\n  return TT-CHECK-ALL(KB, alpha, symbols, {})\n\nfunction TT-CHECK-ALL(KB, alpha, symbols, model) returns true or false\n  if EMPTY?(symbols) then\n    if PL-TRUE?(KB, model) then return PL-TRUE?(alpha, model)\n    else return true // KB is false in this model, so it doesn't matter\n  else\n    P &lt;- FIRST(symbols)\n    rest &lt;- REST(symbols)\n    return TT-CHECK-ALL(KB, alpha, rest, model UNION {P=true}) and\n           TT-CHECK-ALL(KB, alpha, rest, model UNION {P=false})\n</code></pre> Pseudoc\u00f3digo adaptado de Russell e Norvig (2010, p. 249).</p> <p>A desvantagem do model checking \u00e9 sua complexidade exponencial no n\u00famero de s\u00edmbolos de proposi\u00e7\u00e3o (2^n) (RUSSELL; NORVIG, 2010, p. 248). Para ambientes com muitos s\u00edmbolos, como um Mundo do Wumpus maior, isso se torna impratic\u00e1vel.</p>"},{"location":"portfolio4/2conceitos/#52-encadeamento-direto-forward-chaining","title":"5.2. Encadeamento Direto (Forward Chaining)","text":"<p>O encadeamento direto (ou forward chaining) \u00e9 um m\u00e9todo de infer\u00eancia que funciona aplicando regras de infer\u00eancia (como Modus Ponens) de forma exaustiva para derivar todas as novas senten\u00e7as poss\u00edveis a partir da KB (RUSSELL; NORVIG, 2010, p. 157). Ele come\u00e7a com os fatos conhecidos e adiciona todas as conclus\u00f5es que podem ser inferidas diretamente. \u00c9 completo para bases de conhecimento em forma de cl\u00e1usula de Horn, o que significa que se uma senten\u00e7a \u00e9 entailed pela KB, o encadeamento direto a encontrar\u00e1 (RUSSELL; NORVIG, 2010, p. 157).</p>"},{"location":"portfolio4/2conceitos/#53-encadeamento-reverso-backward-chaining","title":"5.3. Encadeamento Reverso (Backward Chaining)","text":"<p>O encadeamento reverso (ou backward chaining) \u00e9 uma estrat\u00e9gia de infer\u00eancia orientada a objetivos. Ele come\u00e7a com a consulta que se deseja provar e procura por senten\u00e7as na KB que possam concluir essa consulta. Se essas senten\u00e7as dependem de outras, o processo continua recursivamente at\u00e9 que todas as premissas sejam fatos conhecidos na KB ou possam ser provadas. Como visto nos slides da disciplina, a infer\u00eancia em redes Bayesianas pode ser realizada tanto de forma causal (predi\u00e7\u00e3o) quanto diagn\u00f3stica (inferindo causas a partir de efeitos), o que tem uma semelhan\u00e7a conceitual com o encadeamento direto e reverso, respectivamente (FGA0221 \u2013 Intelig\u00eancia Artificial, s.d., Regra de Bayes, slide 12).</p>"},{"location":"portfolio4/2conceitos/#54-inferencia-por-refutacao-dpll","title":"5.4. Infer\u00eancia por Refuta\u00e7\u00e3o (DPLL)","text":"<p>A infer\u00eancia por refuta\u00e7\u00e3o busca provar que <code>KB |= \u03b1</code> mostrando que <code>KB \u2227 \u00ac\u03b1</code> \u00e9 insatisfaz\u00edvel (uma contradi\u00e7\u00e3o). O algoritmo DPLL (Davis\u2013Putnam\u2013Logemann\u2013Loveland) \u00e9 um m\u00e9todo eficiente para verificar a satisfatibilidade de senten\u00e7as na l\u00f3gica proposicional (RUSSELL; NORVIG, 2010, p. 263). Ele combina backtracking com heur\u00edsticas para podar o espa\u00e7o de busca, como a propaga\u00e7\u00e3o de unidades (RUSSELL; NORVIG, 2010, p. 264).</p> <p><pre><code>function DPLL(clauses, symbols, model) returns true or false\n  if every clause in clauses is true in model then return true\n  if some clause in clauses is false in model then return false\n\n  // Find a pure symbol (always appears with same truth value)\n  P, value &lt;- FIND-PURE-SYMBOL(clauses, symbols, model)\n  if P is not null then\n    return DPLL(clauses, symbols - {P}, model UNION {P=value})\n\n  // Find a unit clause (clause with only one literal whose truth value is not determined)\n  P, value &lt;- FIND-UNIT-CLAUSE(clauses, symbols, model)\n  if P is not null then\n    return DPLL(clauses, symbols - {P}, model UNION {P=value})\n\n  P &lt;- FIRST(symbols)\n  rest &lt;- REST(symbols)\n  return DPLL(clauses, rest, model UNION {P=true}) or\n         DPLL(clauses, rest, model UNION {P=false})\n</code></pre> Pseudoc\u00f3digo adaptado de Russell e Norvig (2010, p. 264).</p>"},{"location":"portfolio4/2conceitos/#6-pseudocodigos-e-exemplo-de-agente-hibrido","title":"6. Pseudoc\u00f3digos e Exemplo de Agente H\u00edbrido","text":"<p>O livro de Russell e Norvig (2010) apresenta pseudoc\u00f3digos importantes para a compreens\u00e3o dos agentes l\u00f3gicos. Al\u00e9m do <code>KB-AGENT</code> e do <code>DPLL</code> j\u00e1 citados, um exemplo interessante \u00e9 o <code>HYBRID-WUMPUS-AGENT</code>, que mostra como um agente pode combinar a dedu\u00e7\u00e3o de aspectos do estado do mundo com regras de condi\u00e7\u00e3o-a\u00e7\u00e3o e algoritmos de resolu\u00e7\u00e3o de problemas (RUSSELL; NORVIG, 2010, p. 269).</p> <p><pre><code>function HYBRID-WUMPUS-AGENT(percept) returns an action\n  persistent: KB, a knowledge base\n              t, a counter, initially 0, indicating time\n              plan, an action sequence, initially empty\n              safe_squares, a set of squares known to be safe\n              unvisited_squares, a set of squares not yet visited\n\n  // Update knowledge base\n  TELL(KB, MAKE-PERCEPT-SENTENCE(percept, t))\n  TELL(KB, MAKE-ACTION-SENTENCE(last_action, t - 1)) // If applicable\n\n  // Deduce new facts (using logical inference, e.g., DPLL for queries)\n  // For each square [x,y]:\n  //   Infer if it is safe, infer if it has a pit, infer if it has wumpus, etc.\n  //   Add these inferences to KB (e.g., TELL(KB, OKx,y), TELL(KB, \u00acPx,y), etc.)\n\n  // Update safe and unvisited squares based on new inferences\n\n  // If there's no current plan or it's completed\n  if plan is empty then\n    // 1. Try to find gold\n    if ASK(KB, HAS-GLITTER(current_location, t)) then\n      action &lt;- GRAB\n    // 2. Try to move to an unvisited safe square\n    else if unvisited_safe_square exists then\n      plan &lt;- ROUTE-PROBLEM(current_location, unvisited_safe_square, safe_squares)\n      action &lt;- FIRST(plan)\n      plan &lt;- REST(plan)\n    // 3. Try to move to a previously visited safe square (explore more)\n    else if visited_safe_square exists then\n      plan &lt;- ROUTE-PROBLEM(current_location, visited_safe_square, safe_squares)\n      action &lt;- FIRST(plan)\n      plan &lt;- REST(plan)\n    // 4. No safe moves, shoot or climb out\n    else if ASK(KB, HAS-WUMPUS(current_location, t)) and HAS-ARROW() then\n      action &lt;- SHOOT\n    else\n      action &lt;- CLIMB_OUT\n  else\n    action &lt;- FIRST(plan)\n    plan &lt;- REST(plan)\n\n  last_action &lt;- action\n  return action\n</code></pre> Pseudoc\u00f3digo adaptado de Russell e Norvig (2010, p. 269-270).</p> <p>Este pseudoc\u00f3digo demonstra como um agente pode usar a l\u00f3gica proposicional para inferir o estado do mundo e, em seguida, combinar essa informa\u00e7\u00e3o com um algoritmo de busca (<code>ROUTE-PROBLEM</code> e <code>A*-GRAPH-SEARCH</code> seriam definidos separadamente) para planejar uma rota, garantindo que suas a\u00e7\u00f5es sejam baseadas no conhecimento mais seguro poss\u00edvel.</p>"},{"location":"portfolio4/2conceitos/#7-limitacoes-dos-agentes-logicos-e-necessidade-de-agentes-probabilisticos","title":"7. Limita\u00e7\u00f5es dos Agentes L\u00f3gicos e Necessidade de Agentes Probabil\u00edsticos","text":"<p>Apesar de sua eleg\u00e2ncia e rigor, a l\u00f3gica proposicional, e os agentes puramente l\u00f3gicos baseados nela, possuem limita\u00e7\u00f5es significativas em ambientes complexos e incertos.</p> <p>1. Problema da Qualifica\u00e7\u00e3o: Como discutido nos slides da disciplina (FGA0221 \u2013 Intelig\u00eancia Artificial, s.d., Quantificando Incertezas, slide 2), \u00e9 extremamente dif\u00edcil listar todas as qualifica\u00e7\u00f5es necess\u00e1rias para que uma regra l\u00f3gica seja totalmente exaustiva e sem exce\u00e7\u00f5es. Por exemplo, \"Dor de dente \u21d2 C\u00e1rie\" \u00e9 uma regra falha, e tentar adicionar todas as exce\u00e7\u00f5es a ela torna a base de conhecimento impratic\u00e1vel (RUSSELL; NORVIG, 2010, p. 268, 480). Russell e Norvig (2010, p. 369) refor\u00e7am essa ideia, mencionando que a l\u00f3gica proposicional \u00e9 impratic\u00e1vel para dom\u00ednios complexos como o diagn\u00f3stico m\u00e9dico devido \u00e0 necessidade de uma listagem exaustiva de antecedentes e consequentes.</p> <p>2. Expressividade Limitada para Ambientes de Tamanho Ilimitado: A l\u00f3gica proposicional carece de poder expressivo para lidar concisamente com tempo, espa\u00e7o e padr\u00f5es universais de relacionamento entre objetos (RUSSELL; NORVIG, 2010, p. 273, 134). Por exemplo, expressar \"se h\u00e1 um po\u00e7o em [x,y], ent\u00e3o h\u00e1 uma brisa em [x-1,y], [x+1,y], [x,y-1] e [x,y+1]\" de forma universal para qualquer <code>x</code> e <code>y</code> \u00e9 imposs\u00edvel na l\u00f3gica proposicional sem escrever uma senten\u00e7a separada para cada quadrado. Isso leva a bases de conhecimento com milh\u00f5es de senten\u00e7as em ambientes maiores, tornando-as impratic\u00e1veis (RUSSELL; NORVIG, 2010, p. 273).</p> <p>3. Lidar com a Incerteza: A principal limita\u00e7\u00e3o, como bem destacado nos slides (FGA0221 \u2013 Intelig\u00eancia Artificial, s.d., Quantificando Incertezas, slide 1), \u00e9 que agentes no mundo real precisam lidar com a incerteza devido \u00e0 observabilidade parcial, n\u00e3o determinismo ou adversidades. Agentes l\u00f3gicos puros lidam com a incerteza acompanhando todos os estados de mundo poss\u00edveis, mas isso pode levar a planos de conting\u00eancia que crescem arbitrariamente, considerando eventualidades improv\u00e1veis (FGA0221 \u2013 Intelig\u00eancia Artificial, s.d., Quantificando Incertezas, slide 1). Em muitos casos, n\u00e3o h\u00e1 um plano que garanta o sucesso, e o agente precisa comparar os m\u00e9ritos de planos n\u00e3o garantidos (FGA0221 \u2013 Intelig\u00eancia Artificial, s.d., Quantificando Incertezas, slide 1).</p> <p>Para superar essas limita\u00e7\u00f5es, a Intelig\u00eancia Artificial evoluiu para abordagens que quantificam a incerteza. Como vimos em sala, a teoria da probabilidade fornece a principal ferramenta para lidar com graus de cren\u00e7a, permitindo que um agente tenha um grau num\u00e9rico de cren\u00e7a entre 0 e 1 em uma senten\u00e7a, resolvendo assim o problema da qualifica\u00e7\u00e3o (FGA0221 \u2013 Intelig\u00eancia Artificial, s.d., Quantificando Incertezas, slide 4, 5). Russell e Norvig (2010, p. 481) tamb\u00e9m mencionam que a teoria da probabilidade permite que o agente tenha um \"grau de cren\u00e7a\" nos resultados.</p> <p>Al\u00e9m disso, para aprimorar a expressividade, foi desenvolvida a L\u00f3gica de Primeira Ordem, que permite representar conhecimento sobre objetos e rela\u00e7\u00f5es de forma muito mais concisa e universal (RUSSELL; NORVIG, 2010, p. 285). Essa transi\u00e7\u00e3o para a l\u00f3gica de primeira ordem e, posteriormente, para o racioc\u00ednio probabil\u00edstico com Redes Bayesianas (como as discutidas nos slides FGA0221 \u2013 Intelig\u00eancia Artificial, s.d., Redes Bayesianas, slides 1-3), \u00e9 essencial para a constru\u00e7\u00e3o de agentes verdadeiramente robustos em ambientes complexos. As redes Bayesianas, por exemplo, oferecem um m\u00e9todo sistem\u00e1tico para representar rela\u00e7\u00f5es de independ\u00eancia condicional explicitamente e realizar infer\u00eancia probabil\u00edstica de forma eficiente (RUSSELL; NORVIG, 2010, p. 510).</p> <p>Em suma, embora os agentes l\u00f3gicos forne\u00e7am uma base s\u00f3lida para a representa\u00e7\u00e3o do conhecimento e o racioc\u00ednio dedutivo, a complexidade e a incerteza do mundo real exigem a integra\u00e7\u00e3o com ferramentas mais poderosas, como a l\u00f3gica de primeira ordem e a teoria da probabilidade, que ser\u00e3o exploradas em detalhes nos pr\u00f3ximos t\u00f3picos do portf\u00f3lio.</p>"},{"location":"portfolio4/2conceitos/#referencias","title":"Refer\u00eancias","text":"<p>FGA0221 \u2013 Intelig\u00eancia Artificial. (s.d.). Quantificando Incertezas. Slides da disciplina.</p> <p>FGA0221 \u2013 Intelig\u00eancia Artificial. (s.d.). Quantificando Incertezas \u2013 2\u00aa Parte. Slides da disciplina.</p> <p>FGA0221 \u2013 Intelig\u00eancia Artificial. (s.d.). Redes Bayesianas. Slides da disciplina.</p> <p>RUSSELL, S. J.; NORVIG, P. Artificial Intelligence: A Modern Approach. 3. ed. Upper Saddle River: Prentice Hall, 2010.</p> Vers\u00e3o Data Modifica\u00e7\u00e3o Nome GitHub <code>1.0</code> 24/06/2025 Cria\u00e7\u00e3o do documento Ana Beatriz Norberto @ananorberto"},{"location":"portfolio4/3conclusao/","title":"Conclus\u00e3o","text":"<p>Explorar os agentes l\u00f3gicos ao longo deste portf\u00f3lio foi uma oportunidade de entender como a intelig\u00eancia artificial come\u00e7ou a construir sistemas capazes de raciocinar, n\u00e3o apenas agir mecanicamente. Esses agentes, ao manterem uma base de conhecimento e usarem a l\u00f3gica para inferir a\u00e7\u00f5es a partir do que percebem, demonstram uma abordagem declarativa que busca simular o pensamento humano de forma estruturada.</p> <p>Durante as aulas, especialmente nos slides 14, 15 e 16, vimos como essa ideia funciona bem em dom\u00ednios simples e totalmente observ\u00e1veis, como o Mundo do Wumpus. No entanto, ao nos aprofundarmos no livro de Russell e Norvig (2010), fica claro que, apesar de serem e logicamente s\u00f3lidos, os agentes puramente l\u00f3gicos enfrentam limita\u00e7\u00f5es importantes quando o ambiente se torna incerto ou parcialmente conhecido. A necessidade de considerar todos os poss\u00edveis estados do mundo e de lidar com exce\u00e7\u00f5es torna invi\u00e1vel o uso exclusivo da l\u00f3gica proposicional em aplica\u00e7\u00f5es complexas.</p> <p>\u00c9 justamente a\u00ed que os conte\u00fados das aulas e o cap\u00edtulo 7 do livro convergem: os agentes l\u00f3gicos foram essenciais para fundamentar o campo, mas hoje caminham lado a lado com abordagens probabil\u00edsticas. O racioc\u00ednio baseado em probabilidade e utilidade, como vimos nos slides e em cap\u00edtulos posteriores da obra, surge como uma continua\u00e7\u00e3o natural, mais adequada a muitos dos desafios do mundo real.</p> <p>Concluir esse quarto portf\u00f3lio \u00e9 reconhecer o valor hist\u00f3rico e conceitual dos agentes l\u00f3gicos, mas tamb\u00e9m entender que eles fazem parte de um caminho maior dentro da IA, um caminho que continua evoluindo, misturando l\u00f3gica, estat\u00edstica e aprendizado para alcan\u00e7ar sistemas realmente inteligentes.</p>"},{"location":"portfolio4/3conclusao/#referencias","title":"Refer\u00eancias","text":"<ul> <li>RUSSELL, Stuart J.; NORVIG, Peter. Artificial Intelligence: A Modern Approach. 3. ed. New Jersey: Pearson Education, 2010.</li> <li>FGA0221 \u2013 Intelig\u00eancia Artificial. Quantificando Incertezas. Slides 14, 15 e 16. [S. l.: s. n.].</li> </ul> Vers\u00e3o Data Modifica\u00e7\u00e3o Nome GitHub <code>1.0</code> 24/06/2025 Cria\u00e7\u00e3o do documento Ana Beatriz Norberto @ananorberto"},{"location":"portfolio5/1introducao/","title":"1. Introdu\u00e7\u00e3o","text":"<p>No campo da Intelig\u00eancia Artificial (IA), nossa objetivo maior \u00e9 desenvolver sistemas que n\u00e3o apenas emulem a intelig\u00eancia humana, mas que tamb\u00e9m consigam perceber, compreender, prever e interagir com um mundo que \u00e9 inerentemente vasto e complexo. Por\u00e9m, a realidade de grande parte dos ambientes em que os agentes de IA operam est\u00e1 longe de ser perfeita. \u00c9 nesse ponto que a incerteza se torna um aspecto crucial e inescap\u00e1vel para o estudo da IA.</p> <p>Como visto nas aulas, os agentes inteligentes s\u00e3o projetados para tomar as \"melhores\" a\u00e7\u00f5es poss\u00edveis, visando maximizar seu desempenho. No entanto, o mundo real normalmente \u00e9, nondetermin\u00edstico e parcialmente observ\u00e1vel. As informa\u00e7\u00f5es que os agentes recebem, por exemplo, de seus sistemas sensoriais como vis\u00e3o ou sonar, n\u00e3o s\u00e3o muito confi\u00e1veis. Essa limita\u00e7\u00e3o gera uma ignor\u00e2ncia e pregui\u00e7a, o que torna a incerteza uma caracter\u00edstica fundamental na tomada de decis\u00f5es. Quando um agente n\u00e3o consegue deduzir uma situa\u00e7\u00e3o com certeza, ele precisa de uma forma de raciocinar e planejar sob essa ambiguidade. Por isso, Russell e Norvig (2010) destacam que \"sistemas de racioc\u00ednio e planejamento devem ser capazes de lidar com a incerteza\", uma vez que as informa\u00e7\u00f5es sensoriais n\u00e3o s\u00e3o totalmente seguras. Al\u00e9m disso, a busca pela racionalidade perfeita pode ser computacionalmente invi\u00e1vel em cen\u00e1rios complexos, exigindo abordagens que integrem a incerteza.</p> <p>Este portf\u00f3lio foi estruturado em quatro partes principais, explorando os conceitos e t\u00e9cnicas que nos permitem construir agentes mais robustos e adapt\u00e1veis:</p> <ul> <li> <p>Incerteza e Probabilidade: Aqui, investigaremos a base te\u00f3rica para quantificar a incerteza, fundamental para qualquer agente que opera em ambientes imprevis\u00edveis. Como vimos nas aulas (slides 16 e 17), a probabilidade nos oferece as ferramentas necess\u00e1rias para expressar as cren\u00e7as de um agente em rela\u00e7\u00e3o \u00e0 evid\u00eancia dispon\u00edvel . O trabalho de Thomas Bayes, com sua famosa regra para atualizar probabilidades diante de novas evid\u00eancias, \u00e9 um pilar dessa \u00e1rea, sendo a base da maioria das abordagens modernas em sistemas de IA.</p> </li> <li> <p>Redes Bayesianas: Aprofundando o estudo da probabilidade, as Redes Bayesianas nos fornecem uma maneira sistem\u00e1tica e eficiente de representar rela\u00e7\u00f5es de independ\u00eancia condicional. Como estudamos nas aulas (slides 17), uma Rede Bayesiana \u00e9 um grafo direcionado onde cada n\u00f3 representa uma vari\u00e1vel aleat\u00f3ria, e as setas indicam rela\u00e7\u00f5es de causalidade ou depend\u00eancia, permitindo que a distribui\u00e7\u00e3o conjunta seja expressa como um produto de probabilidades condicionais locais. Segundo Russell e Norvig (2010), a formaliza\u00e7\u00e3o das Redes Bayesianas foi criada para permitir a \"representa\u00e7\u00e3o eficiente e racioc\u00ednio rigoroso com conhecimento incerto\".</p> </li> <li> <p>Racioc\u00ednio Probabil\u00edstico ao Longo do Tempo: Em muitos problemas de IA, o ambiente muda dinamicamente, e o estado atual do agente pode depender de eventos passados e influenciar eventos futuros. Esta ser\u00e1 abordado modelos probabil\u00edsticos podem ser estendidos para raciocinar sobre sequ\u00eancias de eventos ao longo do tempo, um t\u00f3pico central da disciplina (slides 18 e 19). Fun\u00e7\u00f5es como filtragem, predi\u00e7\u00e3o e suaviza\u00e7\u00e3o s\u00e3o cruciais para manter uma estimativa atualizada do estado do mundo, prever seu futuro ou entender seu passado. Os Modelos Ocultos de Markov (HMMs) s\u00e3o um exemplo not\u00e1vel de modelo probabil\u00edstico temporal, onde o estado do processo \u00e9 descrito por uma \u00fanica vari\u00e1vel aleat\u00f3ria discreta.</p> </li> <li> <p>Filtros de Kalman: Por fim, exploraremos os Filtros de Kalman, uma ferramenta poderosa para infer\u00eancia em sistemas din\u00e2micos lineares com ru\u00eddo gaussiano. Como vimos nas aulas (slides 20), desenvolvido por Rudolf E. K\u00e1lm\u00e1n em 1960, este filtro \u00e9 amplamente utilizado em aplica\u00e7\u00f5es como sistemas de navega\u00e7\u00e3o, piloto autom\u00e1tico e vis\u00e3o computacional. Ele nos permite estimar o estado de um sistema com base em medi\u00e7\u00f5es ruidosas e um modelo de processo incerto, modelando o conhecimento do estado como uma distribui\u00e7\u00e3o gaussiana e lidando com o ru\u00eddo do sensor.</p> </li> </ul> <p>Em resumo, este portf\u00f3lio tem como objetivo aprofundar e consolidar nosso entendimento sobre como a IA pode prosperar em um mundo de incerteza, fornecendo uma base s\u00f3lida nas t\u00e9cnicas probabil\u00edsticas essenciais para o desenvolvimento de agentes inteligentes. Todo o material ser\u00e1 baseado nos conceitos abordados nas aulas e aprofundado com base na literatura, principalmente no livro de Russell e Norvig (2010).</p> <p>Refer\u00eancias</p> <p>RUSSELL, Stuart J.; NORVIG, Peter. Artificial Intelligence: A Modern Approach. 3. ed. Upper Saddle River: Prentice Hall, 2010.</p> Vers\u00e3o Data Modifica\u00e7\u00e3o Nome GitHub <code>1.0</code> 16/07/2025 Cria\u00e7\u00e3o do documento Ana Beatriz Norberto @ananorberto"},{"location":"portfolio5/2incerteza%26prob/","title":"2. Incerteza e Probabilidade","text":"<p>Na Intelig\u00eancia Artificial (IA), um dos maiores desafios \u00e9 construir agentes que operem de forma eficaz em ambientes que s\u00e3o, por natureza, imprevis\u00edveis e complexos. A realidade \u00e9 que o mundo raramente \u00e9 t\u00e3o organizado e determin\u00edstico quanto gostar\u00edamos. \u00c9 aqui que entra a incerteza, um elemento fundamental que os agentes de IA precisam aprender a quantificar e gerenciar.</p>"},{"location":"portfolio5/2incerteza%26prob/#por-que-a-ia-precisa-lidar-com-incerteza","title":"Por que a IA precisa lidar com incerteza?","text":"<p>Como vimos nas aulas e como Russell e Norvig (2010, p. 54) destacam, \"agentes podem precisar lidar com incerteza, seja devido a observabilidade parcial, n\u00e3o determinismo ou uma combina\u00e7\u00e3o dos dois\". Imagine um rob\u00f4 explorando um ambiente desconhecido: seus sensores podem falhar ou fornecer dados imprecisos (observabilidade parcial), e suas a\u00e7\u00f5es podem n\u00e3o ter resultados garantidos (n\u00e3o determinismo). Por exemplo, um sistema de navega\u00e7\u00e3o aut\u00f4noma em um carro n\u00e3o pode ter certeza absoluta de que um pedestre parado continuar\u00e1 parado ou que um sem\u00e1foro verde permanecer\u00e1 verde tempo suficiente.</p> <p>Essa incerteza n\u00e3o \u00e9 apenas um \"problema t\u00e9cnico\"; \u00e9 uma caracter\u00edstica intr\u00ednseca do mundo real. Ela surge da nossa \"pregui\u00e7a\" em especificar cada detalhe do universo e da nossa \"ignor\u00e2ncia\" sobre todas as condi\u00e7\u00f5es que afetam um resultado (RUSSELL; NORVIG, 2010, p. 72). Al\u00e9m disso, \"sistemas de racioc\u00ednio e planejamento devem ser capazes de lidar com a incerteza\", pois as informa\u00e7\u00f5es sensoriais raramente s\u00e3o perfeitamente confi\u00e1veis (RUSSELL; NORVIG, 2010). A busca por uma racionalidade perfeita, que exigiria modelar cada min\u00facia do mundo e calcular todas as consequ\u00eancias, \u00e9 muitas vezes computacionalmente invi\u00e1vel.</p>"},{"location":"portfolio5/2incerteza%26prob/#a-transicao-dos-agentes-logicos-para-agentes-que-tomam-decisoes-com-base-em-graus-de-crenca","title":"A transi\u00e7\u00e3o dos agentes l\u00f3gicos para agentes que tomam decis\u00f5es com base em graus de cren\u00e7a","text":"<p>Tradicionalmente, muitos agentes de IA, especialmente os agentes l\u00f3gicos, operam com base em verdades absolutas: uma proposi\u00e7\u00e3o \u00e9 verdadeira, falsa ou desconhecida. Eles mant\u00eam um \"estado de cren\u00e7a\" que representa o conjunto de todos os estados poss\u00edveis do mundo em que o agente poderia estar e, a partir da\u00ed, geram planos de conting\u00eancia para cada eventualidade. Contudo, essa abordagem, embora rigorosa, possui desvantagens significativas. Ela pode levar ao que chamamos de \"problema da qualifica\u00e7\u00e3o\", onde \u00e9 imposs\u00edvel listar todas as exce\u00e7\u00f5es ou condi\u00e7\u00f5es que podem impedir uma regra de ser aplicada com certeza. Al\u00e9m disso, em ambientes complexos, manter um conjunto completo de todos os estados poss\u00edveis pode ser invi\u00e1vel.</p> <p>\u00c9 nesse ponto que a probabilidade se apresenta como uma alternativa mais flex\u00edvel e realista. Enquanto um agente l\u00f3gico pode ter uma opini\u00e3o bin\u00e1ria (verdadeiro/falso/desconhecido) sobre uma senten\u00e7a, \"um agente probabil\u00edstico pode ter um grau num\u00e9rico de cren\u00e7a entre 0 (para senten\u00e7as que s\u00e3o certamente falsas) e 1 (certamente verdadeiras)\" (RUSSELL; NORVIG, 2010, p. 56). Essa capacidade de expressar \"graus de cren\u00e7a\" permite que o agente tome decis\u00f5es mais nuances e racionais, mesmo diante de informa\u00e7\u00f5es incompletas ou ruidosas. Como ilustrado pelo exemplo do Mundo do Wumpus, um agente probabil\u00edstico pode calcular as chances de um buraco em diferentes quadrados, permitindo-lhe evitar \u00e1reas de alta probabilidade de risco, algo que um agente puramente l\u00f3gico n\u00e3o conseguiria discernir (RUSSELL; NORVIG, 2010, p. 71).</p>"},{"location":"portfolio5/2incerteza%26prob/#conceitos-fundamentais-para-quantificar-incertezas","title":"Conceitos fundamentais para quantificar incertezas","text":"<p>A ferramenta central para lidar com graus de cren\u00e7a \u00e9 a teoria da probabilidade (RUSSELL; NORVIG, 2010, p. 56). Segundo Laplace, \"A teoria da probabilidade n\u00e3o \u00e9 nada mais do que o senso comum reduzido a c\u00e1lculo\" (LAPLACE, 1819, citado em RUSSELL; NORVIG, 2010, p. 95). Ela nos fornece uma linguagem formal para quantificar a incerteza, expressando a incapacidade de um agente de chegar a uma decis\u00e3o definitiva sobre a verdade de uma senten\u00e7a e sumarizando suas cren\u00e7as em rela\u00e7\u00e3o \u00e0s evid\u00eancias (RUSSELL; NORVIG, 2010, p. 72).</p> <p>Alguns conceitos fundamentais para entender essa quantifica\u00e7\u00e3o s\u00e3o:</p> <ul> <li> <p>Vari\u00e1veis Aleat\u00f3rias, Espa\u00e7o Amostral e Eventos:</p> <ul> <li>Uma vari\u00e1vel aleat\u00f3ria \u00e9 uma fun\u00e7\u00e3o que associa um resultado num\u00e9rico a cada poss\u00edvel desfecho de um evento (LUGER, p. 380). Por exemplo, \"Chuva\" \u00e9 uma vari\u00e1vel aleat\u00f3ria que pode assumir os valores 'Verdadeiro' ou 'Falso'.</li> <li>Um espa\u00e7o amostral \u00e9 o conjunto de todos os resultados poss\u00edveis de um experimento ou situa\u00e7\u00e3o. Por exemplo, ao lan\u00e7ar um dado, o espa\u00e7o amostral \u00e9 {1, 2, 3, 4, 5, 6} (LUGER, p. 375).</li> <li>Um evento \u00e9 um subconjunto do espa\u00e7o amostral. A probabilidade de um evento \u00e9 a soma das probabilidades dos \"mundos\" (ou seja, atribui\u00e7\u00f5es de valores a todas as vari\u00e1veis aleat\u00f3rias) em que esse evento ocorre (RUSSELL; NORVIG, 2010, p. 59).</li> </ul> </li> <li> <p>Princ\u00edpio da Utilidade M\u00e1xima Esperada (MEU - Maximum Expected Utility):</p> <ul> <li>A decis\u00e3o racional para um agente n\u00e3o se baseia apenas no que ele acredita ser verdadeiro, mas tamb\u00e9m no que ele deseja que aconte\u00e7a. Essa \"vontade\" \u00e9 capturada pela utilidade, uma medida num\u00e9rica da desejabilidade dos resultados (RUSSELL; NORVIG, 2010, p. 57).</li> <li>O princ\u00edpio do MEU afirma que um agente racional deve escolher a a\u00e7\u00e3o que maximiza sua utilidade esperada (RUSSELL; NORVIG, 2010, p. 57). A utilidade esperada \u00e9 a m\u00e9dia dos resultados poss\u00edveis de uma a\u00e7\u00e3o, ponderada pela probabilidade de cada resultado ocorrer.</li> <li>Como Russell e Norvig (2010, p. 115) sumarizam, \"a teoria da probabilidade descreve o que um agente deve acreditar com base na evid\u00eancia, a teoria da utilidade descreve o que um agente quer, e a teoria da decis\u00e3o une as duas para descrever o que um agente deve fazer\". Esse princ\u00edpio forma a base para a tomada de decis\u00f5es em ambientes incertos, e seu uso foi amplamente promovido por trabalhos como o de Judea Pearl (1988).</li> </ul> </li> </ul>"},{"location":"portfolio5/2incerteza%26prob/#exemplos-simples-o-paradoxo-de-monty-hall","title":"Exemplos simples: O Paradoxo de Monty Hall","text":"<p>Para ilustrar como a intui\u00e7\u00e3o pode falhar e como o racioc\u00ednio probabil\u00edstico \u00e9 essencial, podemos considerar o Paradoxo de Monty Hall. Este problema, que inclusive foi abordado nos slides da Aula 16, demonstra claramente a import\u00e2ncia de atualizar as cren\u00e7as probabil\u00edsticas diante de novas evid\u00eancias.</p> <p>No problema, um participante escolhe uma porta (digamos, Porta 1) entre tr\u00eas, sabendo que atr\u00e1s de uma delas h\u00e1 um carro e atr\u00e1s das outras duas, bodes. O apresentador, que sabe onde o carro est\u00e1, abre uma das outras duas portas (digamos, Porta 3), revelando um bode. Ele ent\u00e3o pergunta ao participante se ele gostaria de trocar sua escolha inicial (Porta 1) pela porta restante (Porta 2).</p> <p>Intuitivamente, muitas pessoas pensam que, com duas portas restantes, a probabilidade de o carro estar atr\u00e1s de cada uma delas se torna 50%. No entanto, a an\u00e1lise probabil\u00edstica revela que trocar de porta dobra as chances de ganhar o carro.</p> <ul> <li>No in\u00edcio, cada porta tem 1/3 de chance de ter o carro.</li> <li>Quando o participante escolhe a Porta 1, ela tem 1/3 de chance de ter o carro.</li> <li>As Portas 2 e 3, juntas, t\u00eam 2/3 de chance de ter o carro.</li> <li>Quando Monty Hall abre a Porta 3 e revela um bode, ele concentra os 2/3 de probabilidade restantes na Porta 2 (se o carro n\u00e3o estiver na Porta 1). Isso ocorre porque Monty sempre abrir\u00e1 uma porta com um bode. Se o carro estivesse na Porta 2, ele teria que abrir a Porta 3. Se estivesse na Porta 3, ele teria que abrir a Porta 2. Se estivesse na Porta 1 (sua escolha inicial), ele poderia abrir aleatoriamente a Porta 2 ou 3, mas de qualquer forma, a porta que ele n\u00e3o abriu (Porta 2, em nosso exemplo) ret\u00e9m a maior probabilidade (2/3).</li> </ul> <p>Este exemplo, embora simples, sublinha como a formaliza\u00e7\u00e3o probabil\u00edstica \u00e9 crucial para tomar as melhores decis\u00f5es em situa\u00e7\u00f5es de incerteza, mesmo quando a intui\u00e7\u00e3o pode levar a erros.</p> <p> Figura 1: Distribui\u00e7\u00e3o de probabilidades no problema de Monty Hall ap\u00f3s m\u00faltiplas simula\u00e7\u00f5es (Monte Carlo). </p> <p>Em resumo, a quantifica\u00e7\u00e3o da incerteza por meio da probabilidade n\u00e3o \u00e9 um luxo, mas uma necessidade para a Intelig\u00eancia Artificial. Ela permite que agentes operem de forma mais robusta e racional em um mundo imprevis\u00edvel, transformando dados incompletos e ruidosos em decis\u00f5es inteligentes. Como visto nos slides da Aula 16, as Redes Bayesianas, que estudaremos a seguir, fornecem uma formaliza\u00e7\u00e3o gr\u00e1fica para representar e raciocinar com essa incerteza de forma eficiente.</p> <p>Refer\u00eancias</p> <p>RUSSELL, Stuart J.; NORVIG, Peter. Artificial Intelligence: A Modern Approach. 3. ed. Upper Saddle River: Prentice Hall, 2010.</p> <p>LUGER, George F. Artificial Intelligence: Structures and Strategies for Complex Problem Solving. 6. ed. Boston: Pearson Education, 2009.</p> <p>Erzbischof, CC BY-SA 3.0 https://creativecommons.org/licenses/by-sa/3.0, via Wikimedia Commons</p> Vers\u00e3o Data Modifica\u00e7\u00e3o Nome GitHub <code>1.0</code> 16/07/2025 Cria\u00e7\u00e3o do documento Ana Beatriz Norberto @ananorberto"},{"location":"portfolio5/3redesBayesianas/","title":"3. Redes Bayesianas","text":"<p>Em Intelig\u00eancia Artificial (IA), a capacidade de lidar com a incerteza \u00e9 crucial para que os agentes possam operar de forma eficaz em ambientes complexos e imprevis\u00edveis. Embora os agentes l\u00f3gicos baseados em verdades absolutas tenham seu lugar, a realidade do mundo exige uma abordagem que permita expressar graus de cren\u00e7a e tomar decis\u00f5es racionais mesmo com informa\u00e7\u00f5es incompletas [RUSSELL; NORVIG, 2010, p. 56]. \u00c9 neste cen\u00e1rio que as Redes Bayesianas emergem como uma ferramenta poderosa e eficiente.</p>"},{"location":"portfolio5/3redesBayesianas/#definicao-e-motivacao-para-o-uso-de-redes-bayesianas","title":"Defini\u00e7\u00e3o e Motiva\u00e7\u00e3o para o Uso de Redes Bayesianas","text":"<p>As Redes Bayesianas, tamb\u00e9m conhecidas como redes de cren\u00e7a Bayesianas (Bayesian belief networks - BBNs) [LUGER, 2009, p. 390], s\u00e3o modelos gr\u00e1ficos que representam as rela\u00e7\u00f5es probabil\u00edsticas entre um conjunto de vari\u00e1veis. Russell e Norvig (2010, p. 55) explicam que elas fornecem uma \"maneira sistem\u00e1tica de representar essas rela\u00e7\u00f5es explicitamente na forma de redes Bayesianas\" para capturar o conhecimento incerto de forma natural e eficiente [RUSSELL; NORVIG, 2010, p. 55].</p> <p>A motiva\u00e7\u00e3o para o uso de redes Bayesianas deriva das limita\u00e7\u00f5es das abordagens anteriores:</p> <ul> <li>Incerteza Inerente ao Mundo Real: Agentes de IA frequentemente precisam lidar com informa\u00e7\u00f5es incompletas ou ruidosas, seja por observabilidade parcial do ambiente ou por um comportamento n\u00e3o determin\u00edstico de suas a\u00e7\u00f5es [RUSSELL; NORVIG, 2010, p. 54]. A l\u00f3gica proposicional e de primeira ordem, que opera com certezas (verdadeiro/falso), \u00e9 insuficiente para modelar esses graus de incerteza [LUGER, 2009, p. 292].</li> <li>Transi\u00e7\u00e3o de Agentes L\u00f3gicos para Probabil\u00edsticos: Enquanto um agente l\u00f3gico mant\u00e9m um estado de cren\u00e7a baseado em verdades absolutas, o que pode levar ao \"problema da qualifica\u00e7\u00e3o\" (onde \u00e9 imposs\u00edvel listar todas as exce\u00e7\u00f5es a uma regra), um \"agente probabil\u00edstico pode ter um grau num\u00e9rico de cren\u00e7a entre 0 (para senten\u00e7as que s\u00e3o certamente falsas) e 1 (certamente verdadeiras)\" [RUSSELL; NORVIG, 2010, p. 56]. As Redes Bayesianas fornecem a estrutura para representar e raciocinar com esses graus de cren\u00e7a.</li> <li>Complexidade da Distribui\u00e7\u00e3o Conjunta Completa: Representar o conhecimento incerto atrav\u00e9s de uma distribui\u00e7\u00e3o conjunta completa de todas as vari\u00e1veis do dom\u00ednio se torna invi\u00e1vel para problemas realistas, pois a tabela resultante teria um tamanho exponencial em rela\u00e7\u00e3o ao n\u00famero de vari\u00e1veis [LUGER, 2009, p. 347]. Russell e Norvig (2010, p. 55) apontam que as redes Bayesianas foram inventadas para permitir a \"representa\u00e7\u00e3o eficiente e o racioc\u00ednio rigoroso com conhecimento incerto\". Elas \"superam muitos problemas dos sistemas de racioc\u00ednio probabil\u00edstico das d\u00e9cadas de 1960 e 1970\" [RUSSELL; NORVIG, 2010, p. 19].</li> </ul>"},{"location":"portfolio5/3redesBayesianas/#conceitos-centrais","title":"Conceitos Centrais","text":"<p>As Redes Bayesianas s\u00e3o fundamentadas em tr\u00eas conceitos centrais que lhes conferem poder e efici\u00eancia:</p> <ul> <li>Estrutura de Grafo Ac\u00edclico Dirigido (DAG - Directed Acyclic Graph):<ul> <li>Uma rede Bayesiana \u00e9 um grafo direcionado no qual cada n\u00f3 carrega informa\u00e7\u00f5es de probabilidade.</li> <li>Cada n\u00f3 corresponde a uma vari\u00e1vel aleat\u00f3ria, que pode ser discreta ou cont\u00ednua.</li> <li>Liga\u00e7\u00f5es por setas conectam pares de n\u00f3s, indicando rela\u00e7\u00f5es de \"genitor-filho\" (causa-efeito).</li> <li>Crucialmente, o grafo n\u00e3o tem ciclos direcionados e, portanto, \u00e9 um grafo ac\u00edclico dirigido. Essa propriedade garante que n\u00e3o h\u00e1 depend\u00eancias circulares e que a rede define uma distribui\u00e7\u00e3o de probabilidade consistente e \u00fanica. Luger (2009, p. 391) enfatiza que \"influ\u00eancias causais s\u00e3o direcionadas\" e \"o racioc\u00ednio de influ\u00eancia causal n\u00e3o \u00e9 circular\".</li> </ul> </li> </ul> <p> Figura 2: Exemplo de Rede Bayesiana simples. </p> <p>Nesta figura 2 , cada n\u00f3 representa uma vari\u00e1vel aleat\u00f3ria, e as setas indicam depend\u00eancia condicional entre elas. Essa estrutura permite fatorar a distribui\u00e7\u00e3o conjunta e realizar infer\u00eancia probabil\u00edstica eficiente.</p> <ul> <li>Independ\u00eancia Condicional:<ul> <li>Este \u00e9 o pilar da efici\u00eancia das Redes Bayesianas. \"Cada n\u00f3 \u00e9 condicionalmente independente de seus n\u00e3o descendentes, dados seus genitores\".</li> <li>Russell e Norvig (2010, p. 55) ressaltam a import\u00e2ncia da \"independ\u00eancia e relacionamentos de independ\u00eancia condicional\" para simplificar as representa\u00e7\u00f5es probabil\u00edsticas. Nos slides, o exemplo de MaryCalls e JohnCalls ilustra que, dado o estado do alarme, a chamada de John n\u00e3o influencia a chamada de Mary, mesmo que ambos sejam influenciados indiretamente por roubos ou terremotos.</li> <li>Essa propriedade permite que a probabilidade de um n\u00f3 dependa apenas de seus genitores diretos, e n\u00e3o de todas as outras vari\u00e1veis na rede, o que reduz drasticamente o n\u00famero de par\u00e2metros necess\u00e1rios para representar a distribui\u00e7\u00e3o conjunta.</li> </ul> </li> <li>Fatora\u00e7\u00e3o da Distribui\u00e7\u00e3o Conjunta:<ul> <li>A sem\u00e2ntica de uma Rede Bayesiana \u00e9 definida pela forma como ela representa uma distribui\u00e7\u00e3o conjunta espec\u00edfica sobre todas as vari\u00e1veis.</li> <li>As redes Bayes definem cada entrada na distribui\u00e7\u00e3o conjunta da seguinte forma: $P(X_1, ..., X_n) = \\prod_{i=1}^{n} P(X_i | Parents(X_i))$. Esta \u00e9 uma fatora\u00e7\u00e3o compacta da distribui\u00e7\u00e3o conjunta.</li> <li>Como demonstrado na aula 16 e por Russell e Norvig (2010, p. 58), essa fatora\u00e7\u00e3o \u00e9 uma aplica\u00e7\u00e3o da regra da cadeia da probabilidade, onde a independ\u00eancia condicional permite que cada termo $P(X_i | X_{i-1}, ..., X_1)$ seja simplificado para $P(X_i | Parents(X_i))$, desde que os n\u00f3s sejam ordenados de forma consistente com a estrutura do grafo.</li> </ul> </li> </ul>"},{"location":"portfolio5/3redesBayesianas/#construcao-e-inferencia-em-redes-bayesianas","title":"Constru\u00e7\u00e3o e Infer\u00eancia em Redes Bayesianas","text":"<p>A constru\u00e7\u00e3o de uma Rede Bayesiana segue um processo sistem\u00e1tico que aproveita a estrutura de depend\u00eancias causais:</p> <ul> <li> <p>Constru\u00e7\u00e3o da Rede:</p> <ol> <li>N\u00f3s: Primeiro, determine o conjunto de vari\u00e1veis aleat\u00f3rias necess\u00e1rias para modelar o dom\u00ednio. A ordem dessas vari\u00e1veis ($X_1, ..., X_n$) \u00e9 importante; uma ordem em que as causas precedem os efeitos geralmente resulta em uma rede mais compacta e esparsa.</li> <li>Liga\u00e7\u00f5es: Para cada vari\u00e1vel $X_i$ (de $i=1$ a $n$), escolha um conjunto m\u00ednimo de genitores de $X_1, ..., X_{i-1}$ que a influenciam diretamente. Para cada genitor selecionado, insira uma liga\u00e7\u00e3o direcionada para $X_i$. Esse passo garante a propriedade de independ\u00eancia condicional.</li> <li>CPTs (Tabelas de Probabilidade Condicional): Para cada n\u00f3 $X_i$, escreva a tabela de probabilidade condicional $P(X_i | Parents(X_i))$. Essas tabelas quantificam o efeito dos genitores no n\u00f3 com um n\u00famero finito de par\u00e2metros. Este m\u00e9todo de constru\u00e7\u00e3o garante que a rede \u00e9 ac\u00edclica e minimiza redund\u00e2ncias, assegurando a consist\u00eancia.</li> </ol> </li> <li> <p>Infer\u00eancia na Rede:</p> <ul> <li>A tarefa prim\u00e1ria da infer\u00eancia probabil\u00edstica \u00e9 calcular a distribui\u00e7\u00e3o de probabilidade a posteriori para um conjunto de vari\u00e1veis de consulta, dada alguma evid\u00eancia observada. Por exemplo, no cen\u00e1rio do alarme, podemos perguntar a probabilidade de um roubo dado que John ligou e Mary ligou, ou seja, $P(\\text{Roubo} | \\text{JohnLigou}, \\text{MaryLigou})$.</li> <li>Infer\u00eancia por Enumera\u00e7\u00e3o: A aula 17 e Russell e Norvig (2010, p. 522) explicam que qualquer probabilidade condicional pode ser calculada somando-se os termos da distribui\u00e7\u00e3o conjunta completa. Uma vez que a Rede Bayesiana fornece uma representa\u00e7\u00e3o fatorada da distribui\u00e7\u00e3o conjunta, uma consulta pode ser respondida calculando-se somas de produtos de probabilidades condicionais da rede.</li> <li>Complexidade e Efici\u00eancia: Embora a infer\u00eancia por enumera\u00e7\u00e3o seja conceitualmente simples, ela pode ser computacionalmente cara para redes grandes. Para redes complexas, como uma rede de seguro de carro com 27 vari\u00e1veis, a infer\u00eancia exata pode exigir milh\u00f5es de opera\u00e7\u00f5es. A chave para uma infer\u00eancia eficiente \u00e9 evitar c\u00e1lculos repetidos.</li> <li>Infer\u00eancia Aproximada: Para lidar com a intratabilidade da infer\u00eancia exata em grandes redes, s\u00e3o utilizados m\u00e9todos de infer\u00eancia aproximada, como os algoritmos de Monte Carlo. Esses m\u00e9todos geram eventos aleat\u00f3rios baseados nas probabilidades da rede e, com amostras suficientes, podem se aproximar arbitrariamente da verdadeira distribui\u00e7\u00e3o de probabilidade. Os slides da aula 17 mencionam a amostragem direta e a Cadeia de Markov Monte Carlo (MCMC) como exemplos.</li> </ul> </li> </ul>"},{"location":"portfolio5/3redesBayesianas/#a-regra-de-bayes-como-base-para-raciocinio-diagnostico","title":"A Regra de Bayes como Base para Racioc\u00ednio Diagn\u00f3stico","text":"<p>A Regra de Bayes \u00e9 fundamental para o racioc\u00ednio diagn\u00f3stico e para o funcionamento das Redes Bayesianas. Como afirmam Russell e Norvig (2010, p. 496), a equa\u00e7\u00e3o $P(b | a) = P(a | b)P(b) / P(a)$ (ou suas formas mais gerais) \"subjaz a maioria dos sistemas modernos de IA para infer\u00eancia probabil\u00edstica\".</p> <p>Em contextos de diagn\u00f3stico, frequentemente temos informa\u00e7\u00f5es causais (qual a probabilidade de um sintoma dado uma doen\u00e7a, $P(\\text{sintoma} | \\text{doen\u00e7a})$) e desejamos inferir a causa (qual a probabilidade de uma doen\u00e7a dado um sintoma, $P(\\text{doen\u00e7a} | \\text{sintoma})$). A Regra de Bayes permite essa invers\u00e3o de probabilidades, tornando-a essencial para sistemas de diagn\u00f3stico, como os aplicados em medicina ou para identificar falhas em sistemas [LUGER, 2009, p. 338].</p> <p>A rede bayesiana apresentada nos slides ilustra o problema do alarme, onde o objetivo \u00e9 diagnosticar um roubo ou terremoto dadas as chamadas de John e Mary. Calcular $P(\\text{Roubo} | \\text{JohnLigou}, \\text{MaryLigou})$ \u00e9 um exemplo cl\u00e1ssico de racioc\u00ednio diagn\u00f3stico que utiliza os princ\u00edpios da Regra de Bayes sobre a estrutura da rede para inferir as causas a partir dos efeitos observados.</p>"},{"location":"portfolio5/3redesBayesianas/#comparacao-com-logica-proposicional-em-termos-de-escalabilidade","title":"Compara\u00e7\u00e3o com L\u00f3gica Proposicional em Termos de Escalabilidade","text":"<p>A principal vantagem das Redes Bayesianas sobre a l\u00f3gica proposicional (e mesmo a l\u00f3gica de primeira ordem em certos aspectos) em termos de escalabilidade reside na sua capacidade de lidar com incerteza de forma compacta e eficiente.</p> <ul> <li>L\u00f3gica Proposicional: Agentes baseados em l\u00f3gica proposicional constroem o que Russell e Norvig (2010, p. 265) chamam de \"modelo l\u00f3gico completo dos efeitos das a\u00e7\u00f5es\" para inferir o estado do mundo. No entanto, em dom\u00ednios reais, a quantidade de informa\u00e7\u00f5es necess\u00e1rias para ter certeza absoluta sobre cada proposi\u00e7\u00e3o \u00e9 esmagadora. Isso leva a um \"problema de qualifica\u00e7\u00e3o\" onde \"\u00e9 invi\u00e1vel enumerar todas as exce\u00e7\u00f5es\" [RUSSELL; NORVIG, 2010, p. 72]. Al\u00e9m disso, a representa\u00e7\u00e3o do estado de cren\u00e7a pode se tornar muito grande para ser gerenciada.</li> <li>Redes Bayesianas: Ao explorar a independ\u00eancia condicional, as Redes Bayesianas superam a complexidade exponencial da distribui\u00e7\u00e3o conjunta. Em vez de uma \u00fanica tabela gigantesca, elas utilizam tabelas de probabilidade condicional (CPTs) menores para cada n\u00f3, dependendo apenas de seus genitores diretos. \"O fato de que cada par\u00e2metro da rede tem um significado preciso em termos de apenas um pequeno conjunto de vari\u00e1veis \u200b\u200b\u00e9 crucial para a robustez e facilidade de especifica\u00e7\u00e3o dos modelos\". Isso permite que modelos de dom\u00ednios complexos sejam constru\u00eddos de forma modular e escal\u00e1vel, tornando o racioc\u00ednio probabil\u00edstico computacionalmente vi\u00e1vel em muitas situa\u00e7\u00f5es pr\u00e1ticas. A transi\u00e7\u00e3o para modelos probabil\u00edsticos tamb\u00e9m permite que os sistemas de IA aprendam com a experi\u00eancia e combinem o melhor da IA cl\u00e1ssica e das redes neurais [RUSSELL; NORVIG, 2010, p. 19].</li> </ul>"},{"location":"portfolio5/3redesBayesianas/#exemplos-discutidos-em-aula-e-referencias","title":"Exemplos Discutidos em Aula e Refer\u00eancias","text":"<p>Diversos exemplos e aplica\u00e7\u00f5es foram abordados, refor\u00e7ando a relev\u00e2ncia das Redes Bayesianas:</p> <ul> <li>Exemplo do Alarme de Bruce Banner: Este foi o exemplo central usado nos slides da aula 16 e 17. Ele ilustra como construir uma rede simples para um sistema de alarme que pode ser ativado por roubo ou terremoto, e como as chamadas de vizinhos (John e Mary) dependem do alarme. O exemplo detalha o c\u00e1lculo da probabilidade de um roubo dadas as chamadas dos vizinhos, demonstrando a infer\u00eancia exata por enumera\u00e7\u00e3o.</li> <li>Redes Bayesianas H\u00edbridas: Os slides da aula 16 e 17 mencionam como lidar com vari\u00e1veis cont\u00ednuas (como temperatura ou press\u00e3o) em Redes Bayesianas, seja atrav\u00e9s da discretiza\u00e7\u00e3o, do uso de distribui\u00e7\u00f5es de probabilidade conhecidas (como a distribui\u00e7\u00e3o Gaussiana), ou de m\u00e9todos n\u00e3o param\u00e9tricos. Tamb\u00e9m \u00e9 discutido como integrar vari\u00e1veis cont\u00ednuas e discretas (Redes Bayesianas H\u00edbridas), por exemplo, usando uma distribui\u00e7\u00e3o condicional linear-gaussiana. Russell e Norvig (2010, p. 520) tamb\u00e9m discutem a inclus\u00e3o de vari\u00e1veis cont\u00ednuas em Redes Bayesianas.</li> <li>Modelos Ocultos de Markov (HMMs): Como demonstrado na aula 19, os HMMs s\u00e3o um tipo espec\u00edfico de modelo probabil\u00edstico temporal, onde o estado do processo \u00e9 descrito por uma \u00fanica vari\u00e1vel aleat\u00f3ria discreta. Eles s\u00e3o abordados como um caso especial de Redes Bayesianas Din\u00e2micas para racioc\u00ednio ao longo do tempo. As aplica\u00e7\u00f5es de HMMs incluem reconhecimento de fala e processamento de linguagem natural. Os slides mencionam materiais complementares como <code>UmbrellaWorld.py</code> e <code>DanielJurafsky2021.pdf</code>.</li> <li>Filtros de Kalman: Apresentados na aula 20, os Filtros de Kalman s\u00e3o outro exemplo de racioc\u00ednio probabil\u00edstico ao longo do tempo, focados em problemas de estima\u00e7\u00e3o e predi\u00e7\u00e3o de estados em sistemas din\u00e2micos, como o rastreamento de objetos (e.g., avi\u00f5es). Eles modelam o conhecimento do estado como uma \"mancha gaussiana\" (Gaussian blob) e atualizam a estimativa combinando a predi\u00e7\u00e3o do estado com as leituras dos sensores. Russell e Norvig (2010, p. 584) os incluem no cap\u00edtulo sobre racioc\u00ednio probabil\u00edstico ao longo do tempo.</li> </ul> <p>A flexibilidade e o rigor matem\u00e1tico das Redes Bayesianas as tornam uma das ferramentas mais importantes e amplamente utilizadas em IA para lidar com a incerteza, sendo aplicadas em campos como diagn\u00f3stico m\u00e9dico, sistemas de recomenda\u00e7\u00e3o, bioinform\u00e1tica e monitoramento de sistemas complexos [RUSSELL; NORVIG, 2010, p. 70, 74].</p>"},{"location":"portfolio5/3redesBayesianas/#projeto","title":"Projeto","text":""},{"location":"portfolio5/3redesBayesianas/#cenario-aula-particular-de-piano","title":"Cen\u00e1rio: Aula Particular de Piano","text":"<p>Para refor\u00e7ar os conceitos, implementamos um exemplo pr\u00e1tico de Rede Bayesiana utilizando a biblioteca pgmpy.</p> <p>O cen\u00e1rio modelado envolve uma situa\u00e7\u00e3o did\u00e1tica em que um(a) aluno(a) de piano pode se sentir frustrado(a) ou at\u00e9 desistir das aulas, dependendo de dois fatores principais: se estudou e se a m\u00fasica \u00e9 complexa.</p> <p>As vari\u00e1veis consideradas foram:</p> <ul> <li>AlunoSemPratica: indica se o(a) aluno(a) chegou \u00e0 aula sem ter praticado.</li> <li>MusicaComplexa: indica se a m\u00fasica proposta para a aula \u00e9 de dif\u00edcil execu\u00e7\u00e3o.</li> <li>Frustracao: representa o estado emocional do aluno frente \u00e0 aula.</li> <li>Desistencia: vari\u00e1vel que indica se o(a) aluno(a) desiste das aulas de piano.</li> </ul> <p>As depend\u00eancias entre as vari\u00e1veis seguem uma estrutura de grafo ac\u00edclico dirigido (DAG):</p> <pre><code>AlunoSemPratica   MusicaComplexa\n        \\              /\n         \\            /\n           -&gt; Frustracao -&gt; Desistencia\n</code></pre>"},{"location":"portfolio5/3redesBayesianas/#construcao-do-modelo","title":"Constru\u00e7\u00e3o do Modelo","text":"<ol> <li> <p>Defini\u00e7\u00e3o da estrutura (DAG):</p> </li> <li> <p>AlunoSemPratica e MusicaComplexa influenciam Frustracao.</p> </li> <li> <p>Frustracao influencia Desistencia.</p> </li> <li> <p>Tabelas de Probabilidade Condicional (CPDs):</p> </li> <li> <p>S\u00e3o definidas para todas as vari\u00e1veis, considerando as depend\u00eancias.</p> </li> <li> <p>Exemplo: \\$P(\\text{Frustracao} \\mid \\text{AlunoSemPratica}, \\text{MusicaComplexa})\\$ quantifica a chance de frustra\u00e7\u00e3o dependendo das outras duas vari\u00e1veis.</p> </li> <li> <p>Verifica\u00e7\u00e3o e Infer\u00eancia:</p> </li> <li> <p>O modelo \u00e9 verificado quanto \u00e0 sua consist\u00eancia com <code>.check_model()</code>.</p> </li> <li> <p>Utiliza-se o algoritmo de Elimina\u00e7\u00e3o de Vari\u00e1veis para responder perguntas probabil\u00edsticas, como:</p> <ul> <li>Qual a probabilidade de desist\u00eancia se o aluno n\u00e3o praticou e a m\u00fasica \u00e9 complexa?</li> <li>Qual a chance de frustra\u00e7\u00e3o se o aluno praticou e a m\u00fasica \u00e9 simples?</li> <li>Qual a probabilidade de desist\u00eancia mesmo sem frustra\u00e7\u00e3o?</li> </ul> </li> </ol>"},{"location":"portfolio5/3redesBayesianas/#codigo-python","title":"C\u00f3digo Python","text":"<pre><code>#import pandas as pd\nfrom pgmpy.models import DiscreteBayesianNetwork\nfrom pgmpy.factors.discrete import TabularCPD\nfrom pgmpy.inference import VariableElimination\n\n# 1. Definindo a estrutura da rede - Contexto: Aula Particular de Piano\n# As arestas representam as depend\u00eancias: (causa, efeito)\nmodel = DiscreteBayesianNetwork([\n    ('AlunoSemPratica', 'Frustracao'),\n    ('MusicaComplexa', 'Frustracao'),\n    ('Frustracao', 'Desistencia')\n])\n\n# 2. Definindo as Tabelas de Probabilidade Condicional (CPDs)\n# AlunoSemPratica: P(ASP) - Probabilidade do aluno n\u00e3o ter praticado\ncpd_aluno_sem_pratica = TabularCPD(variable='AlunoSemPratica', variable_card=2, values=[[0.3], [0.7]])\n# Card = 2 significa que a vari\u00e1vel tem 2 estados (True/False ou 0/1)\n# Values = [[P(AlunoSemPratica=True)], [P(AlunoSemPratica=False)]]\n\n# MusicaComplexa: P(MC) - Probabilidade da m\u00fasica ser complexa\ncpd_musica_complexa = TabularCPD(variable='MusicaComplexa', variable_card=2, values=[[0.4], [0.6]])\n\n# Frustracao: P(F | ASP, MC) - Probabilidade de frustra\u00e7\u00e3o dadas as condi\u00e7\u00f5es\n# A ordem dos valores segue: (ASP=T, MC=T), (ASP=T, MC=F), (ASP=F, MC=T), (ASP=F, MC=F)\ncpd_frustracao = TabularCPD(variable='Frustracao', variable_card=2,\n                           values=[[0.85, 0.6, 0.5, 0.1],   # P(Frustracao=True | ASP, MC)\n                                   [0.15, 0.4, 0.5, 0.9]],  # P(Frustracao=False | ASP, MC)\n                           evidence=['AlunoSemPratica', 'MusicaComplexa'],\n                           evidence_card=[2, 2])\n\n# Desistencia: P(D | F) - Probabilidade de desistir dada a frustra\u00e7\u00e3o\ncpd_desistencia = TabularCPD(variable='Desistencia', variable_card=2,\n                            values=[[0.7, 0.05],   # P(Desistencia=True | F)\n                                    [0.3, 0.95]],  # P(Desistencia=False | F)\n                            evidence=['Frustracao'],\n                            evidence_card=[2])\n\n# 3. Adicionando as CPDs ao modelo\nmodel.add_cpds(cpd_aluno_sem_pratica, cpd_musica_complexa, cpd_frustracao, cpd_desistencia)\n\n# 4. Verificando a consist\u00eancia do modelo\n# \u00c9 sempre bom verificar se as CPDs foram adicionadas corretamente e se o modelo \u00e9 v\u00e1lido.\nprint(\"Modelo v\u00e1lido?\", model.check_model())\n\n# 5. Realizando Infer\u00eancia\n# Agora, a parte divertida! Vamos fazer perguntas ao nosso modelo.\n# Criamos um objeto de infer\u00eancia a partir do nosso modelo.\ninfer = VariableElimination(model)\n\n# Pergunta 1: Qual a probabilidade de Desist\u00eancia se o Aluno n\u00e3o praticou e a M\u00fasica \u00e9 Complexa?\n# P(Desistencia | AlunoSemPratica=True, MusicaComplexa=True)\nprint(\"\\n--- Infer\u00eancia 1 ---\")\nprob_desistencia_aluno_musica = infer.query(variables=['Desistencia'],\n                                           evidence={'AlunoSemPratica': 0, 'MusicaComplexa': 0})\n# 0 geralmente representa True, 1 representa False na pgmpy por padr\u00e3o, mas pode variar.\n# \u00c9 importante verificar a ordem dos estados definidos na CPD.\n# No nosso caso, 0 \u00e9 True e 1 \u00e9 False para todas as vari\u00e1veis.\nprint(prob_desistencia_aluno_musica)\n\n# Pergunta 2: Qual a probabilidade de Frustra\u00e7\u00e3o se o Aluno praticou e a M\u00fasica \u00e9 Simples?\n# P(Frustracao | AlunoSemPratica=False, MusicaComplexa=False)\nprint(\"\\n--- Infer\u00eancia 2 ---\")\nprob_frustracao_aluno_preparado = infer.query(variables=['Frustracao'],\n                                             evidence={'AlunoSemPratica': 1, 'MusicaComplexa': 1})\nprint(prob_frustracao_aluno_preparado)\n\n# Pergunta 3: Qual a probabilidade de Desist\u00eancia se n\u00e3o h\u00e1 Frustra\u00e7\u00e3o?\n# P(Desistencia | Frustracao=False)\nprint(\"\\n--- Infer\u00eancia 3 ---\")\nprob_desistencia_sem_frustracao = infer.query(variables=['Desistencia'],\n                                             evidence={'Frustracao': 1})\nprint(prob_desistencia_sem_frustracao)\n</code></pre>"},{"location":"portfolio5/3redesBayesianas/#resultado","title":"Resultado","text":""},{"location":"portfolio5/3redesBayesianas/#consideracoes-finais","title":"Considera\u00e7\u00f5es Finais","text":"<p>Esse projeto exemplifica o poder das Redes Bayesianas para modelar situa\u00e7\u00f5es do mundo real que envolvem incerteza, permitindo decis\u00f5es informadas a partir de evid\u00eancias parciais. Ele tamb\u00e9m evidencia a escalabilidade do modelo: novos fatores poderiam ser adicionados ao DAG (como motiva\u00e7\u00e3o, feedback dos pais etc.), sem reconstruir todo o sistema, o que \u00e9  uma caracter\u00edstica crucial para agentes de IA operando em dom\u00ednios complexos e din\u00e2micos.</p> <p>Refer\u00eancias</p> <p>LUGER, George F. Artificial Intelligence: Structures and Strategies for Complex Problem Solving. 6. ed. Boston: Pearson Education, 2009.</p> <p>RUSSELL, Stuart J.; NORVIG, Peter. Artificial Intelligence: A Modern Approach. 3. ed. Upper Saddle River: Prentice Hall, 2010.</p> <p>AnAj, Public domain, via Wikimedia Commons</p> <p>JURAFSKY, Daniel; MARTIN, James H. Speech and Language Processing. [S. l.]: Stanford University, 2021.</p> <p>FGA0221 \u2013 IA - 16. Redes Bayesianas. Material de aula. [S. l.: s. n.], [entre 2023 e 2025].</p> <p>FGA0221 \u2013 IA - 17. Redes Bayesianas \u2013 2\u00aa Parte. Material de aula. [S. l.: s. n.], [entre 2023 e 2025].</p> <p>FGA0221 \u2013 IA - 19. Racioc\u00ednio probabil\u00edstico ao longo do tempo \u2013 Parte 2. Material de aula. [S. l.: s. n.], [entre 2023 e 2025].</p> <p>FGA0221 \u2013 IA - 20. Filtro de Kalman: Algoritmo. Material de aula. [S. l.: s. n.], [entre 2023 e 2025].</p> <p>BEST, Kalman filter Expanation. [S. l.: s. n.], [entre 2023 e 2025]. (BEST, Kalman filter Expanation.pdf) ```</p> Vers\u00e3o Data Modifica\u00e7\u00e3o Nome GitHub <code>1.0</code> 16/07/2025 Cria\u00e7\u00e3o do documento Ana Beatriz Norberto @ananorberto"},{"location":"portfolio5/4raciocinioProb/","title":"4. Racioc\u00ednio probabil\u00edstico ao longo do tempo","text":"<p>Este portf\u00f3lio explora o racioc\u00ednio probabil\u00edstico ao longo do tempo, um conceito fundamental na Intelig\u00eancia Artificial (IA) para lidar com ambientes din\u00e2micos e incertos. Abordaremos a evolu\u00e7\u00e3o dos estados, a introdu\u00e7\u00e3o de modelos como os Modelos Ocultos de Markov (HMMs), as principais tarefas de infer\u00eancia temporal e suas vastas aplica\u00e7\u00f5es, utilizando como base o material de Russell e Norvig (2010), os slides da aula 19, e exemplos pr\u00e1ticos.</p>"},{"location":"portfolio5/4raciocinioProb/#1-modelos-dinamicos-e-processos-de-markov","title":"1. Modelos Din\u00e2micos e Processos de Markov","text":"<p>Em contraste com problemas est\u00e1ticos, onde o estado do mundo permanece constante ao longo do tempo, os problemas din\u00e2micos exigem que o sistema acompanhe e preveja mudan\u00e7as, como o n\u00edvel de insulina de um paciente ou a trajet\u00f3ria de um rob\u00f4. Para modelar a evolu\u00e7\u00e3o do mundo, a IA utiliza modelos de transi\u00e7\u00e3o, que descrevem a distribui\u00e7\u00e3o de probabilidade dos estados mais recentes dadas as observa\u00e7\u00f5es anteriores.</p> <p>A suposi\u00e7\u00e3o de Markov \u00e9 crucial para tornar esses modelos trat\u00e1veis, afirmando que o estado atual de um processo depende apenas de um n\u00famero fixo e finito de estados anteriores. A forma mais comum \u00e9 o processo de Markov de primeira ordem, onde o estado atual ($X_t$) depende exclusivamente do estado imediatamente anterior ($X_{t-1}$), ou seja, $P(X_t|X_{t-1})$. Os slides da aula 19 reiteram essa simplicidade. Al\u00e9m disso, a suposi\u00e7\u00e3o de processo de tempo homog\u00eaneo postula que as leis que governam as mudan\u00e7as de estado n\u00e3o variam ao longo do tempo. O modelo de sensor (ou modelo de observa\u00e7\u00e3o) complementar especifica como as vari\u00e1veis de evid\u00eancia ($E_t$) s\u00e3o geradas a partir do estado atual, $P(E_t|X_t)$.</p> <p>A distribui\u00e7\u00e3o conjunta completa sobre todas as vari\u00e1veis do sistema ao longo do tempo \u00e9 definida pelo modelo de estado inicial $P(X_0)$, o modelo de transi\u00e7\u00e3o $P(X_i|X_{i-1})$ e o modelo de sensor $P(E_i|X_i)$, conforme a equa\u00e7\u00e3o $P(X_{0:t}, E_{1:t}) = P(X_0) \\prod_{i=1}^t P(X_i | X_{i-1}) P(E_i | X_i)$.</p>"},{"location":"portfolio5/4raciocinioProb/#2-conceito-de-raciocinio-temporal-evolucao-de-estados-ao-longo-do-tempo","title":"2. Conceito de Racioc\u00ednio Temporal: Evolu\u00e7\u00e3o de Estados ao Longo do Tempo","text":"<p>O racioc\u00ednio temporal em IA envolve a an\u00e1lise e previs\u00e3o de como os estados do ambiente evoluem e como os agentes podem interagir com eles ao longo do tempo. Russell e Norvig (2010, p. ix) introduzem o racioc\u00ednio probabil\u00edstico ao longo do tempo como um componente essencial para sistemas inteligentes que operam em ambientes din\u00e2micos.</p> <p>As principais tarefas de infer\u00eancia em modelos temporais incluem:</p> <ul> <li>Filtragem (ou Estima\u00e7\u00e3o de Estados): Calcula a distribui\u00e7\u00e3o de probabilidade a posteriori do estado mais recente, dado todas as evid\u00eancias observadas at\u00e9 o momento, $P(X_t|e_{1:t})$. Russell e Norvig (2010, p. 572) apresentam a equa\u00e7\u00e3o recursiva para a filtragem: $P(X_{t+1} | e_{1:t+1}) = \\alpha P(e_{t+1} | X_{t+1}) \\sum_{x_t} P(X_{t+1} | x_t) P(x_t | e_{1:t})$. O exemplo do \"mundo do guarda-chuva\", detalhado na aula 19, ilustra o processo passo a passo, mostrando como a probabilidade de chuva \u00e9 atualizada com base na observa\u00e7\u00e3o do guarda-chuva.</li> <li>Predi\u00e7\u00e3o: Calcula a distribui\u00e7\u00e3o de probabilidade de um estado futuro, dadas as evid\u00eancias at\u00e9 o momento atual, $P(X_{t+k} | e_{1:t})$ para $k &gt; 0$.</li> <li>Suaviza\u00e7\u00e3o: Calcula a distribui\u00e7\u00e3o de probabilidade de um estado passado, dadas todas as evid\u00eancias at\u00e9 o instante de tempo atual, $P(X_k|e_{1:t})$ para $0 \\le k &lt; t$. A suaviza\u00e7\u00e3o \u00e9 mais precisa que a filtragem para estados passados, pois incorpora informa\u00e7\u00f5es futuras. O algoritmo de suaviza\u00e7\u00e3o tamb\u00e9m pode ser dividido em uma fase de propaga\u00e7\u00e3o para frente e outra para tr\u00e1s. A complexidade temporal da suaviza\u00e7\u00e3o \u00e9 $O(t)$ para uma \u00fanica etapa $k$, e $O(t)$ para a sequ\u00eancia completa usando programa\u00e7\u00e3o din\u00e2mica (o algoritmo forward-backward).</li> <li>Explica\u00e7\u00e3o Mais Prov\u00e1vel (Decodifica\u00e7\u00e3o): Encontra a sequ\u00eancia de estados mais prov\u00e1vel que gerou uma sequ\u00eancia de observa\u00e7\u00f5es dada, $\\arg \\max_{x_{1:t}} P(x_{1:t} | e_{1:t})$. Esta tarefa \u00e9 tipicamente resolvida pelo Algoritmo de Viterbi. Ele funciona encontrando o caminho mais prov\u00e1vel atrav\u00e9s de um grafo de estados poss\u00edveis em cada etapa de tempo.</li> <li>Aprendizado: Refere-se \u00e0 capacidade de aprender ou corrigir os modelos de transi\u00e7\u00e3o e sensor a partir de observa\u00e7\u00f5es.</li> </ul>"},{"location":"portfolio5/4raciocinioProb/#3-introducao-aos-modelos-ocultos-de-markov-hmm","title":"3. Introdu\u00e7\u00e3o aos Modelos Ocultos de Markov (HMM)","text":"<p> Figura 3: Representa\u00e7\u00e3o de um Modelo Oculto de Markov (HMM), com estados ocultos e observa\u00e7\u00f5es vis\u00edveis. </p> <p>O Modelo Oculto de Markov (HMM) \u00e9 um modelo probabil\u00edstico temporal onde o estado do processo \u00e9 descrito por uma \u00fanica vari\u00e1vel aleat\u00f3ria discreta. Os valores poss\u00edveis dessa vari\u00e1vel representam os diferentes estados do mundo. Russell e Norvig (2010, p. 578) explicam que, mesmo que um modelo tenha m\u00faltiplas vari\u00e1veis de estado, ele pode ser adaptado ao framework HMM combinando-as em uma \u00fanica \"megavari\u00e1vel\".</p> <p>Russell e Norvig (2010, p. 553) e Jurafsky e Martin (2021, p. A.2) fornecem uma defini\u00e7\u00e3o formal dos HMMs, que incluem:</p> <ul> <li>Q: Um conjunto de estados discretos.</li> <li>A: Uma matriz de probabilidades de transi\u00e7\u00e3o ($a_{ij}$), indicando a probabilidade de mover do estado $i$ para o estado $j$.</li> <li>O: Uma sequ\u00eancia de observa\u00e7\u00f5es.</li> <li>B: Um conjunto de probabilidades de observa\u00e7\u00e3o (tamb\u00e9m chamadas de probabilidades de emiss\u00e3o, $b_i(o_t)$), que expressam a probabilidade de uma observa\u00e7\u00e3o $o_t$ ser gerada por um estado $i$.</li> <li>$\\pi$: Uma distribui\u00e7\u00e3o de probabilidade inicial sobre os estados.</li> </ul> <p>Os HMMs de primeira ordem baseiam-se em duas premissas simplificadoras: a suposi\u00e7\u00e3o de Markov, onde a probabilidade de um estado depende apenas do estado anterior, e a independ\u00eancia de sa\u00edda, onde a probabilidade de uma observa\u00e7\u00e3o depende apenas do estado que a produziu.</p> <p>O exemplo do \"mundo do guarda-chuva\" \u00e9 um HMM can\u00f4nico, com a vari\u00e1vel de estado \"chuva\" e a observa\u00e7\u00e3o \"guarda-chuva\". Outro exemplo \u00e9 o problema do sorvete de Jason Eisner (2002), onde as observa\u00e7\u00f5es s\u00e3o o n\u00famero de sorvetes consumidos, e os estados ocultos s\u00e3o as temperaturas (quente ou frio).</p> <p>A aprendizagem dos par\u00e2metros de um HMM (as matrizes A e B) \u00e9 tipicamente realizada pelo algoritmo Forward-Backward, que \u00e9 uma inst\u00e2ncia do algoritmo Expectation-Maximization (EM). Este algoritmo utiliza a suaviza\u00e7\u00e3o para estimar as contagens esperadas de transi\u00e7\u00f5es e emiss\u00f5es.</p>"},{"location":"portfolio5/4raciocinioProb/#4-calculo-de-distribuicoes-marginais-filtragem-previsao-suavizacao-e-explicacao","title":"4. C\u00e1lculo de Distribui\u00e7\u00f5es Marginais, Filtragem, Previs\u00e3o, Suaviza\u00e7\u00e3o e Explica\u00e7\u00e3o","text":"<p>As tarefas de infer\u00eancia temporal s\u00e3o cruciais para extrair informa\u00e7\u00f5es \u00fateis dos modelos.</p> <ul> <li>Filtragem: Como descrito anteriormente, calcula $P(X_t | e_{1:t})$. Russell e Norvig (2010, p. 572) demonstram a aplica\u00e7\u00e3o da equa\u00e7\u00e3o de filtragem ao \"mundo do guarda-chuva\".</li> <li>Suaviza\u00e7\u00e3o: Calcula $P(X_k | e_{1:t})$ para estados passados, aproveitando todas as evid\u00eancias at\u00e9 o presente. A figura 15.3 de Russell e Norvig (2010) ilustra visualmente a suaviza\u00e7\u00e3o. A recurs\u00e3o de suaviza\u00e7\u00e3o utiliza mensagens \"forward\" e \"backward\" que se propagam no tempo. O c\u00e1lculo da probabilidade de chuva no dia 1, dadas as observa\u00e7\u00f5es dos dias 1 e 2 no exemplo do guarda-chuva, \u00e9 um exemplo de suaviza\u00e7\u00e3o.</li> <li>Explica\u00e7\u00e3o Mais Prov\u00e1vel (Viterbi): O algoritmo de Viterbi, descrito em Russell e Norvig (2010, p. 576), \u00e9 usado para encontrar a sequ\u00eancia de estados ocultos mais prov\u00e1vel que gerou uma dada sequ\u00eancia de observa\u00e7\u00f5es. Como os slides da aula 19 explicam, ele constr\u00f3i uma \"treli\u00e7a\" (trellis) para identificar o caminho de maior probabilidade, como ilustrado na Figura 15.5a de Russell e Norvig (2010). Este algoritmo possui complexidade linear em $t$ (tempo), mas requer espa\u00e7o linear para armazenar os ponteiros do melhor caminho.</li> </ul>"},{"location":"portfolio5/4raciocinioProb/#5-aplicacoes-praticas-em-robotica-diagnostico-e-pnl","title":"5. Aplica\u00e7\u00f5es Pr\u00e1ticas em Rob\u00f3tica, Diagn\u00f3stico e PNL","text":"<p>O racioc\u00ednio probabil\u00edstico ao longo do tempo \u00e9 aplicado em diversas \u00e1reas da IA:</p> <ul> <li>Rob\u00f3tica: Filtros de Kalman s\u00e3o amplamente utilizados para rastreamento e estima\u00e7\u00e3o de estado em sistemas cont\u00ednuos, como a posi\u00e7\u00e3o e velocidade de avi\u00f5es. Russell e Norvig (2010, p. 979) destacam que a percep\u00e7\u00e3o rob\u00f3tica pode ser vista como infer\u00eancia temporal, onde filtros de Kalman e HMMs representam os modelos de transi\u00e7\u00e3o e sensor. Aplica\u00e7\u00f5es incluem a localiza\u00e7\u00e3o e mapeamento em rob\u00f3tica (SLAM) com filtros de part\u00edculas Rao-Blackwellizados (RBPF), e o controle de rob\u00f4s. O modelo de bateria e movimento de rob\u00f4s \u00e9 um exemplo de rede Bayesiana din\u00e2mica (DBN) em rob\u00f3tica.</li> <li>Diagn\u00f3stico e Racioc\u00ednio Progn\u00f3stico: Modelos probabil\u00edsticos temporais s\u00e3o \u00fateis para diagnosticar condi\u00e7\u00f5es que mudam ao longo do tempo. Redes Bayesianas, por exemplo, s\u00e3o usadas em sistemas de diagn\u00f3stico m\u00e9dico.</li> <li>Processamento de Linguagem Natural (PNL): HMMs s\u00e3o amplamente empregados em reconhecimento de fala e processamento de linguagem em geral. N-gramas s\u00e3o modelos probabil\u00edsticos para sequ\u00eancias de palavras ou caracteres. A extra\u00e7\u00e3o de informa\u00e7\u00e3o de textos ruidosos tamb\u00e9m se beneficia de HMMs. Al\u00e9m disso, o algoritmo de Viterbi \u00e9 aplicado na an\u00e1lise sint\u00e1tica, como no Earley parser. A aula 19 exemplifica o uso de HMMs para identificar o \"speaker\" (palestrante) e datas em an\u00fancios de palestras.</li> </ul>"},{"location":"portfolio5/4raciocinioProb/#6-visualizacao-dos-conceitos-com-exemplos-praticos","title":"6. Visualiza\u00e7\u00e3o dos Conceitos com Exemplos Pr\u00e1ticos","text":"<p>A compreens\u00e3o dos conceitos de racioc\u00ednio probabil\u00edstico ao longo do tempo \u00e9 significativamente aprimorada atrav\u00e9s de exemplos e implementa\u00e7\u00f5es.</p> <ul> <li>Exemplo do Guarda-Chuva (UmbrellaWorld.py): Como vimos no exemplo do guarda-chuva na aula 19, este cen\u00e1rio simples de prever chuva com base na observa\u00e7\u00e3o de um guarda-chuva \u00e9 um exemplo cl\u00e1ssico de HMM. Ele demonstra de forma intuitiva como a filtragem e a suaviza\u00e7\u00e3o funcionam. A disponibilidade do c\u00f3digo <code>UmbrellaWorld.py</code> permite aos alunos visualizar a aplica\u00e7\u00e3o da matem\u00e1tica em um cen\u00e1rio pr\u00e1tico.</li> <li>Exemplo do Sorvete (IceCream.py): Embora o arquivo <code>IceCream.py</code> n\u00e3o tenha sido fornecido nos materiais, o exemplo do sorvete (Jason Eisner, 2002) \u00e9 um HMM did\u00e1tico que relaciona o n\u00famero de sorvetes com a temperatura oculta (quente ou fria). Este exemplo, presente em materiais complementares como Jurafsky e Martin (2021), refor\u00e7a a ideia de infer\u00eancia sobre estados ocultos a partir de observa\u00e7\u00f5es.</li> <li>V\u00eddeos das Aulas: Os slides da aula 19 recomendam v\u00eddeos como \"Hidden Markov Model Clearly Explained!\" e \"Hidden Markov Model in Python\", que s\u00e3o recursos valiosos para a visualiza\u00e7\u00e3o e implementa\u00e7\u00e3o pr\u00e1tica dos algoritmos de HMMs, consolidando o entendimento da teoria com a pr\u00e1tica.</li> </ul>"},{"location":"portfolio5/4raciocinioProb/#projeto","title":"Projeto","text":""},{"location":"portfolio5/4raciocinioProb/#cenario-clima-oculto-e-atividades-observadas","title":"Cen\u00e1rio: Clima Oculto e Atividades Observadas","text":"<p>Nesta se\u00e7\u00e3o, estudo como agentes inteligentes podem lidar com a incerteza que muda com o tempo, utilizando modelos probabil\u00edsticos din\u00e2micos. Com base nos cap\u00edtulos 15 e 16 do livro do Russell e Norvig (2010), v\u00eddeos explicativos e os slides da aula 19, explorei conceitos como Processos de Markov, Modelos Ocultos de Markov (HMMs) e as principais tarefas de infer\u00eancia temporal: filtragem, predi\u00e7\u00e3o, suaviza\u00e7\u00e3o e explica\u00e7\u00e3o.</p> <p>O objetivo foi entender como agentes podem atualizar suas cren\u00e7as ao longo do tempo, mesmo quando n\u00e3o t\u00eam acesso direto ao estado real do mundo. Isso \u00e9 especialmente importante em ambientes parcialmente observ\u00e1veis, como no caso de um rob\u00f4 que tenta se localizar em um mapa apenas com sensores barulhentos, ou em diagn\u00f3sticos m\u00e9dicos com sintomas amb\u00edguos.</p> <p>Al\u00e9m da parte te\u00f3rica, apliquei os conceitos em um exemplo pr\u00e1tico usando a biblioteca hmmlearn em Python, onde implementei um HMM simples, com defini\u00e7\u00e3o de estados ocultos e observa\u00e7\u00f5es, e usei o algoritmo de Viterbi para descobrir a sequ\u00eancia mais prov\u00e1vel de estados escondidos. Essa implementa\u00e7\u00e3o ajudou a consolidar os conceitos vistos nos materiais e mostrou como esses modelos podem ser aplicados em problemas reais.</p>"},{"location":"portfolio5/4raciocinioProb/#construcao-do-modelo","title":"Constru\u00e7\u00e3o do Modelo","text":"<ul> <li> <p>Estados Ocultos:</p> </li> <li> <p><code>0 = Ensolarado</code></p> </li> <li> <p><code>1 = Chuvoso</code></p> </li> <li> <p>Observa\u00e7\u00f5es:</p> </li> <li> <p><code>0 = Caminhar</code></p> </li> <li><code>1 = Fazer Compras</code></li> <li> <p><code>2 = Limpar Casa</code></p> </li> <li> <p>Probabilidades:</p> </li> <li> <p>Inicial:     P(Ensolarado) = 0.6, P(Chuvoso) = 0.4</p> </li> <li> <p>Transi\u00e7\u00e3o entre Estados:</p> <ul> <li>De Ensolarado \u2192 Ensolarado: 0.7</li> <li>De Ensolarado \u2192 Chuvoso: 0.3</li> <li>De Chuvoso \u2192 Ensolarado: 0.4</li> <li>De Chuvoso \u2192 Chuvoso: 0.6</li> <li> <p>Emiss\u00e3o (atividade observada dado o clima):</p> </li> <li> <p>Ensolarado \u2192 [Caminhar: 0.1, Fazer Compras: 0.4, Limpar Casa: 0.5]</p> </li> <li>Chuvoso \u2192 [Caminhar: 0.6, Fazer Compras: 0.3, Limpar Casa: 0.1]</li> </ul> </li> <li> <p>Observa\u00e7\u00f5es registradas durante 7 dias:</p> </li> <li> <p>Caminhar, Fazer Compras, Limpar Casa, Caminhar, Fazer Compras, Caminhar, Limpar Casa</p> </li> </ul>"},{"location":"portfolio5/4raciocinioProb/#codigo-python","title":"C\u00f3digo Python","text":"<pre><code>import numpy as np\nfrom hmmlearn import hmm\n\n# 1. Definindo os par\u00e2metros do HMM\n\n# Estados ocultos: 0 = Ensolarado, 1 = Chuvoso\n# Observa\u00e7\u00f5es: 0 = Caminhar, 1 = Fazer Compras, 2 = Limpar Casa\n\n# Probabilidades Iniciais (start_probability):\n# P(Ensolarado no dia 1), P(Chuvoso no dia 1)\nstart_probability = np.array([0.6, 0.4])\n\n# Probabilidades de Transi\u00e7\u00e3o (transition_probability):\n# P(Estado_t+1 | Estado_t)\n# Linhas: Estado_t (Ensolarado, Chuvoso)\n# Colunas: Estado_t+1 (Ensolarado, Chuvoso)\n# Ex: P(Ensolarado | Ensolarado) = 0.7, P(Chuvoso | Ensolarado) = 0.3\n# Ex: P(Ensolarado | Chuvoso) = 0.4, P(Chuvoso | Chuvoso) = 0.6\ntransition_probability = np.array([\n    [0.7, 0.3],\n    [0.4, 0.6]\n])\n\n# Probabilidades de Emiss\u00e3o (emission_probability):\n# P(Observa\u00e7\u00e3o | Estado Oculto)\n# Linhas: Estado Oculto (Ensolarado, Chuvoso)\n# Colunas: Observa\u00e7\u00e3o (Caminhar, Fazer Compras, Limpar Casa)\n# Ex: P(Caminhar | Ensolarado) = 0.1, P(Fazer Compras | Ensolarado) = 0.4, P(Limpar Casa | Ensolarado) = 0.5\n# Ex: P(Caminhar | Chuvoso) = 0.6, P(Fazer Compras | Chuvoso) = 0.3, P(Limpar Casa | Chuvoso) = 0.1\nemission_probability = np.array([\n    [0.1, 0.4, 0.5],\n    [0.6, 0.3, 0.1]\n])\n\n# 2. Criando o Modelo HMM\n# n_components \u00e9 o n\u00famero de estados ocultos\nmodel = hmm.CategoricalHMM(n_components=2, tol=1e-2, n_iter=100)\nmodel.startprob_ = start_probability\nmodel.transmat_ = transition_probability\nmodel.emissionprob_ = emission_probability\n\n# 3. Sequ\u00eancia de Observa\u00e7\u00f5es\n# Vamos supor que observamos as seguintes atividades ao longo de 7 dias:\n# Dia 1: Caminhar (0)\n# Dia 2: Fazer Compras (1)\n# Dia 3: Limpar Casa (2)\n# Dia 4: Caminhar (0)\n# Dia 5: Fazer Compras (1)\n# Dia 6: Caminhar (0)\n# Dia 7: Limpar Casa (2)\n\n# A sequ\u00eancia de observa\u00e7\u00f5es deve ser um array 2D, onde cada observa\u00e7\u00e3o \u00e9 uma lista de um elemento.\nobservations = np.array([[0], [1], [2], [0], [1], [0], [2]])\n\n# 4. Infer\u00eancia: Descodificando a sequ\u00eancia de estados      ocultos (Algoritmo de Viterbi)\n# O algoritmo de Viterbi nos d\u00e1 a sequ\u00eancia mais prov\u00e1vel de estados ocultos\n# que gerou a sequ\u00eancia de observa\u00e7\u00f5es.\nlogprob, hidden_states = model.decode(observations, algorithm=\"viterbi\")\n\nprint(\"Log-probabilidade da sequ\u00eancia de observa\u00e7\u00f5es:\", logprob)\nprint(\"Sequ\u00eancia mais prov\u00e1vel de estados ocultos (0=Ensolarado, 1=Chuvoso):\")\nprint(hidden_states)\n\n# Vamos mapear os estados para algo mais leg\u00edvel\nstate_map = {0: \"Ensolarado\", 1: \"Chuvoso\"}\nobserved_map = {0: \"Caminhar\", 1: \"Fazer Compras\", 2: \"Limpar Casa\"}\n\nprint(\"\\n--- Detalhes da Infer\u00eancia ---\")\nfor i, obs_idx in enumerate(observations.flatten()):\n    print(f\"Dia {i+1}: Observa\u00e7\u00e3o = {observed_map[obs_idx]}, Clima Inferido = {state_map[hidden_states[i]]}\")\n</code></pre>"},{"location":"portfolio5/4raciocinioProb/#resultado","title":"Resultado","text":""},{"location":"portfolio5/4raciocinioProb/#consideracoes-finais","title":"Considera\u00e7\u00f5es Finais","text":"<p>O projeto demonstrou como modelos ocultos de Markov podem ser usados para lidar com incerteza ao longo do tempo. Atrav\u00e9s do algoritmo de Viterbi, foi poss\u00edvel estimar estados ocultos com base em observa\u00e7\u00f5es, mostrando a utilidade pr\u00e1tica desse tipo de racioc\u00ednio probabil\u00edstico.</p>"},{"location":"portfolio5/4raciocinioProb/#referencias","title":"Refer\u00eancias","text":"<ul> <li> <p>Russell, S., &amp; Norvig, P. (2010). Artificial Intelligence - A Modern Approach (3rd ed.). Prentice Hall. (Observa\u00e7\u00e3o: As cita\u00e7\u00f5es no texto referem-se \u00e0 3\u00aa edi\u00e7\u00e3o, que o usu\u00e1rio especificou como \"Russell e Norvig (2010)\", embora algumas men\u00e7\u00f5es nos materiais originais possam referir-se a edi\u00e7\u00f5es anteriores).</p> </li> <li> <p>Tdunningvectorization: Own work, CC BY 3.0 https://creativecommons.org/licenses/by/3.0, via Wikimedia Commons</p> </li> <li> <p>Jurafsky, D., &amp; Martin, J. H. (2021). Speech and Language Processing (Draft of December 29, 2021). (Dispon\u00edvel em formato PDF como \"Daniel Jurafsky2021.pdf\").</p> </li> <li>FGA0221 \u2013 Intelig\u00eancia Artificial. (s.d.). Redes Bayesianas. (Material de aula em formato PDF: \"FGA0221 \u2013 IA - 16.pdf\").</li> <li>FGA0221 \u2013 Intelig\u00eancia Artificial. (s.d.). Redes Bayesianas \u2013 2\u00aa Parte. (Material de aula em formato PDF: \"FGA0221 \u2013 IA - 17.pdf\").</li> <li>FGA0221 \u2013 Intelig\u00eancia Artificial. (s.d.). Racioc\u00ednio probabil\u00edstico ao longo do tempo. (Material de aula em formato PDF: \"FGA0221 \u2013 IA - 18.pdf\").</li> <li>FGA0221 \u2013 Intelig\u00eancia Artificial. (s.d.). Racioc\u00ednio probabil\u00edstico ao longo do tempo \u2013 Parte 2. (Material de aula em formato PDF: \"FGA0221 \u2013 IA - 19.pdf\").</li> <li>FGA0221 \u2013 Intelig\u00eancia Artificial. (s.d.). Filtro de Kalman Expanation. (Material de aula em formato PDF: \"FGA0221 \u2013 IA - 20.pdf\").</li> <li>Alpaydin, E. (2014). Machine Learning - An Algorithmic Perspective (2nd ed.). Springer. (Dispon\u00edvel em formato PDF como \"Machine Learning - An Algorithmic Perspective 2nd edition 2014.pdf\").</li> <li>Sutton, R. S., &amp; Barto, A. G. (2015). Reinforcement Learning: An Introduction (2nd ed.). A Bradford Book, The MIT Press. (Dispon\u00edvel em formato PDF como \"Reinforcement-Learning:_An_Introduction.pdf\").</li> <li>Luger, G. F. (2008). Artificial intelligence: Structures and strategies for complex problem solving (6th ed.). Pearson Education. (Dispon\u00edvel em formato PDF como \"artificial intelligence structures and strategies for complex problem solving.pdf\").</li> </ul> Vers\u00e3o Data Modifica\u00e7\u00e3o Nome GitHub <code>1.0</code> 16/07/2025 Cria\u00e7\u00e3o do documento Ana Beatriz Norberto @ananorberto"},{"location":"portfolio5/5filtroKalman/","title":"5. Filtro de Kalman","text":""},{"location":"portfolio5/5filtroKalman/#1-o-que-e-o-filtro-de-kalman-e-por-que-ele-e-necessario","title":"1. O que \u00e9 o Filtro de Kalman e por que ele \u00e9 necess\u00e1rio","text":"<p>O Filtro de Kalman \u00e9 um algoritmo de estima\u00e7\u00e3o de estados \u00f3timo que foi desenvolvido por Rudolf E. K\u00e1lm\u00e1n, com a publica\u00e7\u00e3o de seu trabalho em 1960. Ele \u00e9 descrito como um m\u00e9todo para lidar com vari\u00e1veis cont\u00ednuas, estimando vari\u00e1veis de estado (como posi\u00e7\u00e3o e velocidade) a partir de observa\u00e7\u00f5es ruidosas ao longo do tempo.</p> <p>A necessidade do Filtro de Kalman surge da incerteza inerente a sistemas din\u00e2micos. Em cen\u00e1rios pr\u00e1ticos, as medi\u00e7\u00f5es de sensores s\u00e3o ruidosas e imprecisas, e o pr\u00f3prio sistema em observa\u00e7\u00e3o pode sofrer de \"ru\u00eddo de processo\" devido a fatores imprevis\u00edveis, como vento ou atrito. Como demonstrado nos slides da aula 20, o filtro de Kalman permite fazer uma \"suposi\u00e7\u00e3o educada\" sobre o que o sistema din\u00e2mico far\u00e1 a seguir, mesmo com informa\u00e7\u00f5es incertas. Ele se destaca em combinar informa\u00e7\u00f5es incertas para gerar uma estimativa mais precisa do estado do sistema.</p> <p>Kenneth Craik, em um trabalho que influenciou a ideia de agentes baseados em conhecimento, argumentou que se um organismo possui um \"modelo em pequena escala\" da realidade externa e de suas pr\u00f3prias a\u00e7\u00f5es, ele pode testar alternativas, prever situa\u00e7\u00f5es futuras, e reagir de forma mais \"completa, segura e competente\" [13, p. 13]. O filtro de Kalman incorpora essa ideia ao prever e corrigir continuamente suas estimativas, permitindo que um sistema inteligente opere de forma mais robusta em ambientes imprevis\u00edveis.</p>"},{"location":"portfolio5/5filtroKalman/#2-estimativas-de-estados-continuos-com-ruido","title":"2. Estimativas de estados cont\u00ednuos com ru\u00eddo","text":"<p>O Filtro de Kalman \u00e9 projetado para sistemas caracterizados por vari\u00e1veis de estado cont\u00ednuas e medi\u00e7\u00f5es ruidosas. Ele assume que tanto o modelo de transi\u00e7\u00e3o do sistema (como o estado evolui ao longo do tempo) quanto o modelo do sensor (como as medi\u00e7\u00f5es s\u00e3o obtidas) podem ser representados por distribui\u00e7\u00f5es lineares Gaussianas com ru\u00eddo aditivo Gaussiano.</p> <p>Em um modelo Gaussiano, o estado do sistema \u00e9 especificado por uma m\u00e9dia ($\\mu$) e uma matriz de covari\u00e2ncia ($\\Sigma$). A m\u00e9dia representa a melhor estimativa do estado, enquanto a covari\u00e2ncia quantifica a incerteza associada a essa estimativa. Conforme Russell e Norvig (2010, p. 51), a condi\u00e7\u00e3o de que o pr\u00f3ximo estado seja uma fun\u00e7\u00e3o linear do estado atual, mais algum ru\u00eddo Gaussiano, \u00e9 \"bastante razo\u00e1vel na pr\u00e1tica\". O ru\u00eddo, tanto de processo quanto de medi\u00e7\u00e3o, \u00e9 assumido como Gaussiano com m\u00e9dia zero.</p> <p>Como demonstrado nos slides da aula 20, essas distribui\u00e7\u00f5es Gaussianas s\u00e3o representadas como \"borr\u00f5es\" (blobs) no espa\u00e7o de estados, onde o tamanho e a orienta\u00e7\u00e3o do borr\u00e3o indicam a incerteza (vari\u00e2ncia) e a correla\u00e7\u00e3o entre as vari\u00e1veis.</p>"},{"location":"portfolio5/5filtroKalman/#3-a-estrutura-do-filtro-previsao-e-atualizacao","title":"3. A estrutura do filtro: previs\u00e3o e atualiza\u00e7\u00e3o","text":"<p>A opera\u00e7\u00e3o do Filtro de Kalman \u00e9 um ciclo cont\u00ednuo de \"previs\u00e3o-corre\u00e7\u00e3o\". Ele estima o pr\u00f3ximo estado, calcula um termo de erro com base na medi\u00e7\u00e3o real, e usa ambos para refinar a pr\u00f3xima previs\u00e3o.</p> <p></p> <p>Figure 4: The Predict-Correct Cycle of the Kalman Filter Algorithm.</p>"},{"location":"portfolio5/5filtroKalman/#previsao-predict","title":"Previs\u00e3o (Predict)","text":"<p>Nesta etapa, o filtro projeta o estado atual e sua incerteza para o futuro. Como demonstrado nos slides da aula 20, a estimativa do estado anterior ($\\mathbf{\\hat{x}}_{k-1}$) \u00e9 usada para prever o pr\u00f3ximo estado ($\\mathbf{\\hat{x}}_k$), incorporando tamb\u00e9m quaisquer influ\u00eancias externas de controle ($\\mathbf{u}_k$). O \"novo\" ru\u00eddo de processo \u00e9 adicionado para expandir a covari\u00e2ncia. Russell e Norvig (2010, p. 272) descrevem as equa\u00e7\u00f5es de previs\u00e3o da seguinte forma:</p> <ul> <li>Estado previsto: $\\hat{x}_{t+1} = A x_t + B u_t$</li> <li>Covari\u00e2ncia prevista: $\\hat{\\Sigma}_{t+1} = A \\Sigma_t A^T + Q$</li> </ul> <p>Onde $A$ \u00e9 a matriz de transi\u00e7\u00e3o de estados, $B$ \u00e9 a matriz de controle, $u_t$ \u00e9 o vetor de controle, $\\Sigma_t$ \u00e9 a covari\u00e2ncia do estado atual, e $Q$ \u00e9 a matriz de covari\u00e2ncia do ru\u00eddo de processo.</p>"},{"location":"portfolio5/5filtroKalman/#atualizacao-update","title":"Atualiza\u00e7\u00e3o (Update)","text":"<p>Ap\u00f3s a previs\u00e3o, o filtro incorpora a nova medi\u00e7\u00e3o recebida para refinar a estimativa do estado. Como demonstrado nos slides da aula 20, a medi\u00e7\u00e3o ($\\mathbf{z}_k$) \u00e9 comparada com a medi\u00e7\u00e3o esperada com base no estado previsto ($\\mathbf{H}\\mathbf{\\hat{x}}_k$), gerando um res\u00edduo ou erro ($\\varepsilon$). O filtro calcula um Ganho de Kalman ($K$), que determina o quanto a nova medi\u00e7\u00e3o influenciar\u00e1 a estimativa do estado. Se a medi\u00e7\u00e3o for muito ruidosa, o sistema confiar\u00e1 mais em sua estimativa atual; caso contr\u00e1rio, a medi\u00e7\u00e3o ter\u00e1 mais peso. As equa\u00e7\u00f5es de atualiza\u00e7\u00e3o s\u00e3o dadas por Russell e Norvig (2010, p. 272):</p> <ul> <li>Erro na estimativa: $\\varepsilon = y_{t+1} - H A x_{t+1}$</li> <li>Ganho de Kalman: $K = \\hat{\\Sigma}{t+1} H^T (H \\hat{\\Sigma}$} H^T + R)^{-1</li> <li>Estado atualizado: $x_k = x_p + K (z_k - H x_p)$</li> <li>Covari\u00e2ncia atualizada: $P_k = P_p - K H P_p$</li> </ul> <p>Onde $H$ \u00e9 a matriz de observa\u00e7\u00e3o (transforma o estado em medi\u00e7\u00e3o) e $R$ \u00e9 a matriz de covari\u00e2ncia do ru\u00eddo de medi\u00e7\u00e3o. Este processo \u00e9 iterativo, com a estimativa atualizada servindo como base para a pr\u00f3xima previs\u00e3o.</p>"},{"location":"portfolio5/5filtroKalman/#4-relacao-com-o-filtro-bayesiano","title":"4. Rela\u00e7\u00e3o com o filtro Bayesiano","text":"<p>O Filtro de Kalman \u00e9 uma inst\u00e2ncia espec\u00edfica do filtro Bayesiano, aplicado a sistemas que seguem modelos lineares Gaussianos. Russell e Norvig (2010, p. 55) explicam que, se a distribui\u00e7\u00e3o do estado atual \u00e9 Gaussiana e o modelo de transi\u00e7\u00e3o \u00e9 linear Gaussiano, a distribui\u00e7\u00e3o prevista para o pr\u00f3ximo estado tamb\u00e9m ser\u00e1 Gaussiana. Da mesma forma, se a previs\u00e3o \u00e9 Gaussiana e o modelo do sensor \u00e9 linear Gaussiano, a distribui\u00e7\u00e3o atualizada ap\u00f3s a nova evid\u00eancia tamb\u00e9m ser\u00e1 Gaussiana.</p> <p>Como demonstrado nos slides da aula 18, o c\u00e1lculo de filtragem, que busca a distribui\u00e7\u00e3o a posteriori do estado mais recente dadas todas as evid\u00eancias at\u00e9 o momento, \u00e9 decomposto em duas partes: a proje\u00e7\u00e3o para frente da distribui\u00e7\u00e3o de estados e a atualiza\u00e7\u00e3o com a nova evid\u00eancia. Essa abordagem recursiva \u00e9 fundamentada na regra de Bayes e na independ\u00eancia condicional. Assim, o Filtro de Kalman \u00e9 uma forma elegante de aplicar a infer\u00eancia probabil\u00edstica Bayesiana em ambientes din\u00e2micos cont\u00ednuos, onde a representa\u00e7\u00e3o Gaussiana permite que a distribui\u00e7\u00e3o de estado seja mantida de forma compacta ao longo do tempo.</p>"},{"location":"portfolio5/5filtroKalman/#5-vantagens-e-limitacoes","title":"5. Vantagens e limita\u00e7\u00f5es","text":""},{"location":"portfolio5/5filtroKalman/#vantagens","title":"Vantagens","text":"<ul> <li>Estima\u00e7\u00e3o \u00d3tima: O Filtro de Kalman \u00e9 um \"algoritmo de estima\u00e7\u00e3o de estados \u00f3timo\" para sistemas lineares com ru\u00eddo Gaussiano, no sentido de que minimiza a vari\u00e2ncia do erro de estima\u00e7\u00e3o.</li> <li>Efici\u00eancia Computacional: \u00c9 ideal para sistemas que mudam continuamente e s\u00e3o adequados para problemas de tempo real e sistemas embarcados, pois n\u00e3o precisam manter um hist\u00f3rico completo de observa\u00e7\u00f5es.</li> <li>Estimativa de Vari\u00e1veis Ocultas: Pode estimar vari\u00e1veis que n\u00e3o s\u00e3o diretamente observ\u00e1veis, como a velocidade de um objeto a partir de medi\u00e7\u00f5es de posi\u00e7\u00e3o.</li> <li>Combina\u00e7\u00e3o de Dados: Integra dados de m\u00faltiplos sensores e previs\u00f5es do modelo para produzir uma estimativa mais precisa do estado.</li> </ul>"},{"location":"portfolio5/5filtroKalman/#limitacoes","title":"Limita\u00e7\u00f5es","text":"<ul> <li>Pressupostos Fortes: A principal limita\u00e7\u00e3o s\u00e3o as \"suposi\u00e7\u00f5es muito fortes\" de modelos de transi\u00e7\u00e3o e sensor lineares e Gaussianos. Se o sistema n\u00e3o for linear ou o ru\u00eddo n\u00e3o for Gaussiano, a estimativa pode ser \"muito pobre\".</li> <li>N\u00e3o-Linearidades: Para lidar com n\u00e3o-linearidades, s\u00e3o necess\u00e1rias extens\u00f5es como o Filtro de Kalman Estendido (EKF) ou o Filtro de Kalman N\u00e3o-Centrado (UKF). O EKF lineariza o sistema localmente em torno da m\u00e9dia do estado, enquanto o UKF usa uma abordagem baseada em amostragem.</li> <li>Distribui\u00e7\u00f5es Arbitr\u00e1rias: O Filtro de Kalman representa a distribui\u00e7\u00e3o de estado como uma \u00fanica distribui\u00e7\u00e3o Gaussiana. Isso o torna inadequado para modelar situa\u00e7\u00f5es com m\u00faltiplas possibilidades ou distribui\u00e7\u00f5es n\u00e3o-Gaussianas complexas. Nesses casos, o Filtro de Part\u00edculas \u00e9 mais apropriado.</li> </ul>"},{"location":"portfolio5/5filtroKalman/#6-exemplo-simples-com-grafico","title":"6. Exemplo simples com gr\u00e1fico","text":"<p>No contexto de um sistema unidimensional, como um \"caminhada aleat\u00f3ria\" (random walk) com ru\u00eddo, o Filtro de Kalman permite visualizar como a incerteza da estimativa muda ao longo do tempo. Russell e Norvig (2010, p. 57) ilustram isso com um gr\u00e1fico que mostra as etapas do ciclo de atualiza\u00e7\u00e3o do filtro de Kalman. A distribui\u00e7\u00e3o inicial do estado (por exemplo, $P(x_0)$) \u00e9 uma Gaussiana. Ap\u00f3s a previs\u00e3o (incorporando ru\u00eddo de transi\u00e7\u00e3o), a distribui\u00e7\u00e3o ($P(x_1)$) se \"acha\", indicando um aumento na incerteza. Quando uma nova observa\u00e7\u00e3o ($z_1$) \u00e9 incorporada, a distribui\u00e7\u00e3o a posteriori ($P(x_1 | z_1)$) se torna mais estreita, e sua m\u00e9dia \u00e9 um \"m\u00e9dia ponderada\" da previs\u00e3o e da observa\u00e7\u00e3o, movendo-se ligeiramente para a esquerda da observa\u00e7\u00e3o neste exemplo.</p> <p>O c\u00f3digo <code>Kalman_Simple_Exemple.py</code> provavelmente demonstra este comportamento em uma simula\u00e7\u00e3o, mostrando a evolu\u00e7\u00e3o da estimativa e de sua covari\u00e2ncia (incerteza) \u00e0 medida que novas medi\u00e7\u00f5es s\u00e3o processadas. De forma semelhante, o <code>Kalman_Simple_Exemple_2.py</code> deve explorar varia\u00e7\u00f5es ou complexidades adicionais do filtro, talvez em duas dimens\u00f5es ou com diferentes n\u00edveis de ru\u00eddo, como os exemplos visuais de rastreamento em 2D vistos nos slides da aula 20.</p>"},{"location":"portfolio5/5filtroKalman/#7-aplicacoes-em-rastreamento-visao-computacional-robotica","title":"7. Aplica\u00e7\u00f5es em rastreamento, vis\u00e3o computacional, rob\u00f3tica","text":"<p>O Filtro de Kalman e suas extens\u00f5es s\u00e3o amplamente utilizados em uma \"vasta gama de aplica\u00e7\u00f5es\".</p> <ul> <li>Rastreamento: Uma aplica\u00e7\u00e3o \"cl\u00e1ssica\" \u00e9 o rastreamento de alvos, como aeronaves e m\u00edsseis em radares. Inclui tamb\u00e9m o rastreamento ac\u00fastico de submarinos e ve\u00edculos terrestres, e o rastreamento visual de ve\u00edculos e pessoas. O filtro foi implementado para as miss\u00f5es Apollo para estimar as trajet\u00f3rias de foguetes.</li> <li>Vis\u00e3o Computacional e Processamento de Sinais: \u00c9 fundamental para \"rastrear padr\u00f5es complexos de movimento em v\u00eddeo\" e no \"processamento de sinais\" em geral.</li> <li>Rob\u00f3tica: Essencial para a localiza\u00e7\u00e3o e mapeamento de rob\u00f4s (SLAM). Como demonstrado nos slides da aula 20, \u00e9 utilizado em sistemas de navega\u00e7\u00e3o e piloto autom\u00e1tico. A Monte Carlo Localization (MCL), por exemplo, \u00e9 uma aplica\u00e7\u00e3o do filtro de part\u00edculas para a localiza\u00e7\u00e3o de rob\u00f4s.</li> </ul> <p>Al\u00e9m dessas \u00e1reas, Russell e Norvig (2010, p. 59) mencionam a reconstru\u00e7\u00e3o de trajet\u00f3rias de part\u00edculas em fotografias de c\u00e2maras de bolhas, correntes oce\u00e2nicas a partir de medi\u00e7\u00f5es de sat\u00e9lite, e sistemas em ind\u00fastrias como papel e celulose, plantas qu\u00edmicas, reatores nucleares, ecossistemas e economias nacionais.</p>"},{"location":"portfolio5/5filtroKalman/#projeto","title":"Projeto","text":""},{"location":"portfolio5/5filtroKalman/#cenario-estimativa-de-posicao-e-velocidade-com-filtro-de-kalman","title":"Cen\u00e1rio: Estimativa de Posi\u00e7\u00e3o e Velocidade com Filtro de Kalman","text":"<p>Neste projeto, exploramos o uso do Filtro de Kalman para estimar a posi\u00e7\u00e3o e a velocidade de um objeto ao longo do tempo, a partir de medi\u00e7\u00f5es ruidosas de posi\u00e7\u00e3o. Este cen\u00e1rio simula um problema cl\u00e1ssico em controle e rob\u00f3tica, onde o objetivo \u00e9 acompanhar o estado din\u00e2mico de um sistema (posi\u00e7\u00e3o e velocidade) que n\u00e3o pode ser observado diretamente sem ru\u00eddo.</p>"},{"location":"portfolio5/5filtroKalman/#construcao-do-modelo","title":"Constru\u00e7\u00e3o do Modelo","text":"<p>O filtro de Kalman \u00e9 um algoritmo recursivo que combina as medi\u00e7\u00f5es observadas com um modelo de transi\u00e7\u00e3o do sistema para gerar estimativas \u00f3timas do estado, mesmo na presen\u00e7a de ru\u00eddo e incertezas.</p> <ul> <li>O vetor de estado possui duas vari\u00e1veis: posi\u00e7\u00e3o e velocidade.</li> <li>O modelo assume que a posi\u00e7\u00e3o no pr\u00f3ximo instante \u00e9 a posi\u00e7\u00e3o atual mais a velocidade vezes o intervalo de tempo (<code>dt</code>), enquanto a velocidade se mant\u00e9m constante.</li> <li>As medi\u00e7\u00f5es observadas correspondem somente \u00e0 posi\u00e7\u00e3o, que \u00e9 afetada por ru\u00eddo gaussiano.</li> <li>As matrizes do filtro (transi\u00e7\u00e3o de estado, de observa\u00e7\u00e3o, covari\u00e2ncias de ru\u00eddo) s\u00e3o definidas para refletir essas rela\u00e7\u00f5es e incertezas.</li> <li>O filtro inicia com uma grande incerteza inicial sobre o estado para permitir corre\u00e7\u00e3o a partir das medi\u00e7\u00f5es.</li> <li>Durante a execu\u00e7\u00e3o, o filtro realiza previs\u00f5es e atualiza\u00e7\u00f5es iterativas para refinar as estimativas conforme novas medi\u00e7\u00f5es chegam.</li> </ul> <p>Este m\u00e9todo \u00e9 amplamente utilizado em sistemas de navega\u00e7\u00e3o, rastreamento, rob\u00f3tica e qualquer aplica\u00e7\u00e3o que exija estima\u00e7\u00e3o de estados din\u00e2micos a partir de dados ruidosos.</p>"},{"location":"portfolio5/5filtroKalman/#codigo-python","title":"C\u00f3digo Python","text":"<pre><code>import numpy as np\nfrom filterpy.kalman import KalmanFilter\nimport matplotlib.pyplot as plt\n\n# 1. Criando o Filtro de Kalman\n\n# dim_x: n\u00famero de vari\u00e1veis de estado (posi\u00e7\u00e3o e velocidade)\n# dim_z: n\u00famero de vari\u00e1veis de medi\u00e7\u00e3o (posi\u00e7\u00e3o)\nf = KalmanFilter(dim_x=2, dim_z=1)\n\n# 2. Definindo as Matrizes do Filtro\n\n# Matriz de Transi\u00e7\u00e3o de Estado (F)\n# Descreve como o estado evolui de um passo de tempo para o pr\u00f3ximo.\n# [posi\u00e7\u00e3o_nova] = [1 * posi\u00e7\u00e3o_antiga + dt * velocidade_antiga]\n# [velocidade_nova] = [0 * posi\u00e7\u00e3o_antiga + 1 * velocidade_antiga]\ndt = 1.0  # intervalo de tempo\nf.F = np.array([[1., dt],\n                [0., 1.]])\n\n# Matriz de Medi\u00e7\u00e3o (H)\n# Mapeia o estado para o espa\u00e7o de medi\u00e7\u00e3o.\n# [medi\u00e7\u00e3o_posi\u00e7\u00e3o] = [1 * posi\u00e7\u00e3o + 0 * velocidade]\nf.H = np.array([[1., 0.]])\n\n# Covari\u00e2ncia do Ru\u00eddo do Processo (Q)\n# Representa a incerteza no modelo do sistema.\n# Assumimos que a velocidade pode variar um pouco.\nfrom filterpy.common import Q_discrete_white_noise\nf.Q = Q_discrete_white_noise(dim=2, dt=dt, var=0.1)\n\n# Covari\u00e2ncia do Ru\u00eddo da Medi\u00e7\u00e3o (R)\n# Representa a incerteza nas medi\u00e7\u00f5es.\n# Assumimos que nossas medi\u00e7\u00f5es de posi\u00e7\u00e3o t\u00eam um certo ru\u00eddo.\nf.R = np.array([[5.]])\n\n# 3. Estado Inicial e Incerteza Inicial\n\n# Estado Inicial (x)\n# [posi\u00e7\u00e3o_inicial, velocidade_inicial]\nf.x = np.array([[0.],\n                [0.]])\n\n# Covari\u00e2ncia Inicial (P)\n# Representa a incerteza inicial sobre o estado.\n# Come\u00e7amos com uma grande incerteza.\nf.P = np.array([[1000., 0.],\n                [0., 1000.]])\n\n# 4. Simula\u00e7\u00e3o e Filtragem\n\n# Gerando dados simulados com ru\u00eddo\nnp.random.seed(0)\nposicao_real = np.linspace(0, 100, 101)\nvelocidade_real = np.ones(101)\nmedicoes = posicao_real + np.random.normal(0, np.sqrt(f.R[0, 0]), 101)\n\n# Listas para armazenar os resultados\nposicoes_estimadas = []\nvelocidades_estimadas = []\n\nfor z in medicoes:\n    # Previs\u00e3o\n    f.predict()\n\n    # Atualiza\u00e7\u00e3o\n    f.update(z)\n\n    # Salvando a estimativa\n    posicoes_estimadas.append(f.x[0, 0])\n    velocidades_estimadas.append(f.x[1, 0])\n\n# 5. Visualizando os Resultados\n\nplt.figure(figsize=(12, 8))\n\n# Posi\u00e7\u00e3o\nplt.subplot(2, 1, 1)\nplt.plot(posicao_real, label=\"Posi\u00e7\u00e3o Real\")\nplt.plot(medicoes, \".\", label=\"Medi\u00e7\u00f5es\")\nplt.plot(posicoes_estimadas, label=\"Posi\u00e7\u00e3o Estimada (Kalman)\")\nplt.title(\"Estimativa de Posi\u00e7\u00e3o com Filtro de Kalman\")\nplt.xlabel(\"Tempo\")\nplt.ylabel(\"Posi\u00e7\u00e3o\")\nplt.legend()\nplt.grid(True)\n\n# Velocidade\nplt.subplot(2, 1, 2)\nplt.plot(velocidade_real, label=\"Velocidade Real\")\nplt.plot(velocidades_estimadas, label=\"Velocidade Estimada (Kalman)\")\nplt.title(\"Estimativa de Velocidade com Filtro de Kalman\")\nplt.xlabel(\"Tempo\")\nplt.ylabel(\"Velocidade\")\nplt.legend()\nplt.grid(True)\n\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"portfolio5/5filtroKalman/#resultado","title":"Resultado","text":""},{"location":"portfolio5/5filtroKalman/#consideracoes-finais","title":"Considera\u00e7\u00f5es Finais","text":"<p>O filtro de Kalman demonstrou ser uma ferramenta poderosa para estimar estados din\u00e2micos, como posi\u00e7\u00e3o e velocidade, mesmo com medi\u00e7\u00f5es ruidosas e incertezas no modelo. Sua aplica\u00e7\u00e3o pr\u00e1tica \u00e9 essencial em diversas \u00e1reas, destacando-se pela capacidade de fornecer estimativas confi\u00e1veis em tempo real, o que o torna fundamental em rob\u00f3tica, navega\u00e7\u00e3o e sistemas de controle.</p>"},{"location":"portfolio5/5filtroKalman/#referencias","title":"Refer\u00eancias","text":"<ul> <li>Russell, S., &amp; Norvig, P. (2010). Artificial Intelligence - A Modern Approach (3rd ed.). Prentice Hall. (Observa\u00e7\u00e3o: As cita\u00e7\u00f5es no texto referem-se \u00e0 3\u00aa edi\u00e7\u00e3o, que o usu\u00e1rio especificou como \"Russell e Norvig (2010)\", embora algumas men\u00e7\u00f5es nos materiais originais possam referir-se a edi\u00e7\u00f5es anteriores).</li> <li>Jurafsky, D., &amp; Martin, J. H. (2021). Speech and Language Processing (Draft of December 29, 2021). (Dispon\u00edvel em formato PDF como \"Daniel Jurafsky2021.pdf\").</li> <li>FGA0221 \u2013 Intelig\u00eancia Artificial. (s.d.). Redes Bayesianas. (Material de aula em formato PDF: \"FGA0221 \u2013 IA - 16.pdf\").</li> <li>FGA0221 \u2013 Intelig\u00eancia Artificial. (s.d.). Redes Bayesianas \u2013 2\u00aa Parte. (Material de aula em formato PDF: \"FGA0221 \u2013 IA - 17.pdf\").</li> <li>FGA0221 \u2013 Intelig\u00eancia Artificial. (s.d.). Racioc\u00ednio probabil\u00edstico ao longo do tempo. (Material de aula em formato PDF: \"FGA0221 \u2013 IA - 18.pdf\").</li> <li>FGA0221 \u2013 Intelig\u00eancia Artificial. (s.d.). Racioc\u00ednio probabil\u00edstico ao longo do tempo \u2013 Parte 2. (Material de aula em formato PDF: \"FGA0221 \u2013 IA - 19.pdf\").</li> <li>FGA0221 \u2013 Intelig\u00eancia Artificial. (s.d.). Filtro de Kalman Expanation. (Material de aula em formato PDF: \"FGA0221 \u2013 IA - 20.pdf\").</li> <li>Alpaydin, E. (2014). Machine Learning - An Algorithmic Perspective (2nd ed.). Springer. (Dispon\u00edvel em formato PDF como \"Machine Learning - An Algorithmic Perspective 2nd edition 2014.pdf\").</li> <li>Sutton, R. S., &amp; Barto, A. G. (2015). Reinforcement Learning: An Introduction (2nd ed.). A Bradford Book, The MIT Press. (Dispon\u00edvel em formato PDF como \"Reinforcement-Learning:_An_Introduction.pdf\").</li> <li>Luger, G. F. (2008). Artificial intelligence: Structures and strategies for complex problem solving (6th ed.). Pearson Education. (Dispon\u00edvel em formato PDF como \"artificial intelligence structures and strategies for complex problem solving.pdf\").</li> <li>Real-Time Structure from Motion Using Kalman Filtering - Scientific Figure on ResearchGate. Available from: https://www.researchgate.net/figure/The-Predict-Correct-Cycle-of-the-Kalman-Filter-Algorithm_fig5_242369888 [accessed 14 Jul 2025]</li> </ul> Vers\u00e3o Data Modifica\u00e7\u00e3o Nome GitHub <code>1.0</code> 16/07/2025 Cria\u00e7\u00e3o do documento Ana Beatriz Norberto @ananorberto"},{"location":"portfolio5/6conclusao/","title":"6. Conclus\u00e3o","text":"<p>Este portf\u00f3lio aprofundou-se em conceitos fundamentais da Intelig\u00eancia Artificial (IA) que s\u00e3o cruciais para o desenvolvimento de sistemas capazes de operar em ambientes do mundo real: a incerteza e a probabilidade, as Redes Bayesianas, o Racioc\u00ednio Probabil\u00edstico ao Longo do Tempo e os Filtros de Kalman. Estes temas representam um avan\u00e7o crucial da IA rumo a ambientes reais, onde o racioc\u00ednio l\u00f3gico sozinho n\u00e3o \u00e9 suficiente (RUSSELL; NORVIG, 2010, p. 275, 503).</p>"},{"location":"portfolio5/6conclusao/#revisitando-os-conceitos-fundamentais","title":"Revisitando os Conceitos Fundamentais","text":""},{"location":"portfolio5/6conclusao/#incerteza-e-probabilidade","title":"Incerteza e Probabilidade","text":"<p>A incerteza \u00e9 uma caracter\u00edstica inerente a ambientes complexos, n\u00e3o determin\u00edsticos ou parcialmente observ\u00e1veis, tornando-a inescap\u00e1vel em muitos cen\u00e1rios pr\u00e1ticos da IA (RUSSELL; NORVIG, 2010, p. 503). A teoria da probabilidade emerge como a base matem\u00e1tica adequada para lidar com essa incerteza (RUSSELL; NORVIG, 2010, p. 503), expressando a incapacidade de um agente de tomar decis\u00f5es definitivas sobre a verdade de uma senten\u00e7a e sumarizando suas cren\u00e7as em rela\u00e7\u00e3o \u00e0s evid\u00eancias (RUSSELL; NORVIG, 2010, p. 503). O Teorema de Bayes, em particular, \u00e9 fundamental, permitindo a atualiza\u00e7\u00e3o de probabilidades com base em novas evid\u00eancias e subjacente \u00e0 maioria das abordagens modernas para racioc\u00ednio incerto em sistemas de IA (RUSSELL; NORVIG, 2010, p. 20). Agentes racionais, em um contexto de incerteza, buscam maximizar o valor esperado de sua medida de desempenho, ponderando os resultados pela probabilidade de ocorr\u00eancia (RUSSELL; NORVIG, 2010, p. 481, 482).</p>"},{"location":"portfolio5/6conclusao/#redes-bayesianas","title":"Redes Bayesianas","text":"<p>As Redes Bayesianas fornecem uma maneira sistem\u00e1tica e eficiente de representar o conhecimento incerto, capturando explicitamente as rela\u00e7\u00f5es de independ\u00eancia e independ\u00eancia condicional entre vari\u00e1veis (RUSSELL; NORVIG, 2010, p. 510). Conforme detalhado nos materiais de aula, s\u00e3o grafos ac\u00edclicos dirigidos (DAGs) onde cada n\u00f3 representa uma vari\u00e1vel aleat\u00f3ria e as setas indicam rela\u00e7\u00f5es de genitor-filho (FGA0221 \u2013 IA - 16.pdf, p. 3). A especifica\u00e7\u00e3o completa de uma Rede Bayesiana permite definir cada entrada na distribui\u00e7\u00e3o conjunta como um produto de probabilidades condicionais locais (FGA0221 \u2013 IA - 16.pdf, p. 6), tornando a infer\u00eancia probabil\u00edstica mais trat\u00e1vel (RUSSELL; NORVIG, 2010, p. 510). A robustez e facilidade de especifica\u00e7\u00e3o desses modelos derivam do significado preciso de cada par\u00e2metro local (FGA0221 \u2013 IA - 16.pdf, p. 8). Judea Pearl, com sua obra de 1988, foi central na aceita\u00e7\u00e3o generalizada das Redes Bayesianas na IA (RUSSELL; NORVIG, 2010, p. 26).</p> <p> Fonte: Wikimedia Commons. Dom\u00ednio p\u00fablico.</p>"},{"location":"portfolio5/6conclusao/#raciocinio-probabilistico-ao-longo-do-tempo","title":"Racioc\u00ednio Probabil\u00edstico ao Longo do Tempo","text":"<p>Em ambientes din\u00e2micos, onde o estado do mundo muda com o tempo, o racioc\u00ednio probabil\u00edstico se estende para incorporar a dimens\u00e3o temporal (FGA0221 \u2013 IA - 18.pdf, p. 3). Isso envolve a modelagem da evolu\u00e7\u00e3o do mundo (modelo de transi\u00e7\u00e3o) e como as observa\u00e7\u00f5es s\u00e3o geradas (modelo de sensor) (FGA0221 \u2013 IA - 18.pdf, p. 4-5). As tarefas b\u00e1sicas de infer\u00eancia temporal incluem filtragem (estimar o estado atual), predi\u00e7\u00e3o (estimar um estado futuro), suaviza\u00e7\u00e3o (estimar um estado passado) e a explica\u00e7\u00e3o mais prov\u00e1vel (encontrar a sequ\u00eancia de estados mais prov\u00e1vel) (FGA0221 \u2013 IA - 18.pdf, p. 8). Os Modelos Ocultos de Markov (HMMs) s\u00e3o exemplos proeminentes desses modelos temporais, especialmente quando o estado \u00e9 descrito por uma \u00fanica vari\u00e1vel aleat\u00f3ria discreta (FGA0221 \u2013 IA - 19.pdf, p. 5), e algoritmos como o de Viterbi s\u00e3o empregados para encontrar a sequ\u00eancia de estados mais prov\u00e1vel (FGA0221 \u2013 IA - 19.pdf, p. 3, p. 5).</p> <p> Fonte: Wikipedia. Uso livre para fins acad\u00eamicos.</p>"},{"location":"portfolio5/6conclusao/#filtro-de-kalman","title":"Filtro de Kalman","text":"<p>Desenvolvido por Rudolf E. Kalman em 1960 (FGA0221 \u2013 IA - 20.pdf, p. 3; RUSSELL; NORVIG, 2010, p. 604; KALMAN, 1960, p. 35), o Filtro de Kalman \u00e9 uma ferramenta poderosa para estimar estados de sistemas din\u00e2micos a partir de medi\u00e7\u00f5es ruidosas. Ele \u00e9 amplamente utilizado em sistemas de navega\u00e7\u00e3o e piloto autom\u00e1tico, vis\u00e3o computacional e processamento de sinais (FGA0221 \u2013 IA - 20.pdf, p. 3). O filtro opera em um ciclo de predi\u00e7\u00e3o (avan\u00e7ando a estimativa do estado no tempo) e atualiza\u00e7\u00e3o (refinando a estimativa com base em novas medi\u00e7\u00f5es), calculando um \"ganho de Kalman\" para determinar a influ\u00eancia de cada nova medi\u00e7\u00e3o (FGA0221 \u2013 IA - 20.pdf, p. 5-10).</p> <p> Fonte: ResearchGate. Uso acad\u00eamico.</p>"},{"location":"portfolio5/6conclusao/#a-evolucao-da-ia-de-agentes-logicos-a-agentes-probabilisticos","title":"A Evolu\u00e7\u00e3o da IA: De Agentes L\u00f3gicos a Agentes Probabil\u00edsticos","text":"<p>A jornada da Intelig\u00eancia Artificial, conforme articulada por Russell e Norvig (2010), \u00e9 impulsionada pela ideia de construir agentes inteligentes que percebem e agem em um ambiente (RUSSELL; NORVIG, 2010, p. viii). Inicialmente, grande parte da pesquisa em IA, influenciada por figuras como Arist\u00f3teles e por trabalhos em l\u00f3gica e computa\u00e7\u00e3o, focava na capacidade de sistemas usarem regras formais para tirar conclus\u00f5es v\u00e1lidas e realizar racioc\u00ednio mec\u00e2nico (RUSSELL; NORVIG, 2010, p. 18, 19). Isso deu origem aos agentes l\u00f3gicos e sistemas baseados em conhecimento que dependiam de representa\u00e7\u00f5es precisas e infer\u00eancia dedutiva (RUSSELL; NORVIG, 2010, p. 234, 274).</p> <p>No entanto, a limita\u00e7\u00e3o desses sistemas tornou-se evidente: a l\u00f3gica proposicional n\u00e3o escala para ambientes de tamanho ilimitado e carece de poder expressivo para lidar concisamente com tempo, espa\u00e7o e padr\u00f5es universais (RUSSELL; NORVIG, 2010, p. 275, 274). Mais importante, a premissa de um mundo totalmente observ\u00e1vel e determin\u00edstico raramente se sustenta na realidade (RUSSELL; NORVIG, 2010, p. 503). A complexidade combinatorial tamb\u00e9m foi um problema para sistemas l\u00f3gicos (LUGER, 2008, p. 324).</p> <p>Essa lacuna levou a uma mudan\u00e7a de paradigma para a IA probabil\u00edstica. A introdu\u00e7\u00e3o da teoria da probabilidade e, em particular, as Redes Bayesianas, permitiu que os agentes lidassem com a incerteza inerente ao mundo real (RUSSELL; NORVIG, 2010, p. 26, 510). Em vez de tentar inferir tudo com certeza, agentes probabil\u00edsticos mant\u00eam um estado de cren\u00e7a que representa as probabilidades de diferentes estados do mundo, permitindo-lhes fazer previs\u00f5es e tomar decis\u00f5es racionais mesmo com informa\u00e7\u00f5es incompletas (RUSSELL; NORVIG, 2010, p. 482). Essa transi\u00e7\u00e3o reflete uma abordagem mais moderna e pragm\u00e1tica da IA, capaz de atuar em ambientes complexos e din\u00e2micos (RUSSELL; NORVIG, 2010, p. vii, viii).</p>"},{"location":"portfolio5/6conclusao/#importancia-pratica-e-aplicacoes","title":"Import\u00e2ncia Pr\u00e1tica e Aplica\u00e7\u00f5es","text":"<p>Os conceitos explorados neste portf\u00f3lio t\u00eam uma relev\u00e2ncia pr\u00e1tica imensa, moldando a capacidade dos sistemas de IA de interagir com e reagir ao mundo real.</p> <ul> <li>Previs\u00e3o: A capacidade de prever estados futuros \u00e9 crucial em diversas \u00e1reas. O racioc\u00ednio probabil\u00edstico ao longo do tempo e o Filtro de Kalman s\u00e3o ferramentas essenciais para isso, permitindo desde a previs\u00e3o do comportamento de pacientes (FGA0221 \u2013 IA - 18.pdf, p. 3) at\u00e9 a trajet\u00f3ria de foguetes na miss\u00e3o Apollo 11 (FGA0221 \u2013 IA - 20.pdf, p. 3; RUSSELL; NORVIG, 2010, p. 604).</li> <li>Diagn\u00f3stico: As Redes Bayesianas s\u00e3o amplamente utilizadas em sistemas de diagn\u00f3stico, como os m\u00f3dulos de diagn\u00f3stico e reparo no Microsoft Windows e Office (RUSSELL; NORVIG, 2010, p. 553). Elas permitem que os sistemas identifiquem a causa mais prov\u00e1vel de um problema, mesmo com sintomas amb\u00edguos ou incompletos (LUGER, 2008, p. 351).</li> <li>Rob\u00f3tica: Para exploradores planet\u00e1rios rob\u00f3ticos e ve\u00edculos aut\u00f4nomos (RUSSELL; NORVIG, 2010, p. vi, vii), a integra\u00e7\u00e3o de sensores ruidosos, localiza\u00e7\u00e3o e planejamento de alto n\u00edvel \u00e9 essencial (RUSSELL; NORVIG, 2010, p. 27). O Filtro de Kalman, por exemplo, \u00e9 empregado em sistemas de navega\u00e7\u00e3o e piloto autom\u00e1tico (FGA0221 \u2013 IA - 20.pdf, p. 3), permitindo que os rob\u00f4s estimem sua posi\u00e7\u00e3o e velocidade com precis\u00e3o em tempo real (FGA0221 \u2013 IA - 20.pdf, p. 4). Al\u00e9m disso, o aprendizado por refor\u00e7o, que lida com incerteza em ambientes sequenciais, tamb\u00e9m \u00e9 aplic\u00e1vel \u00e0 rob\u00f3tica (SUTTON; BARTO, 2014, p. 234).</li> <li>Controle: A teoria do controle, intimamente ligada \u00e0 IA, aborda o projeto de agentes que operam em ambientes din\u00e2micos e incertos (RUSSELL; NORVIG, 2010, p. 27; SUTTON; BARTO, 2014, p. 55). A compreens\u00e3o de como o conhecimento \u00e9 representado e utilizado para tomar decis\u00f5es racionais em face da incerteza \u00e9 central para o desenvolvimento de controladores aut\u00f4nomos eficazes (RUSSELL; NORVIG, 2010, p. 482).</li> </ul> <p>Essas aplica\u00e7\u00f5es destacam a transi\u00e7\u00e3o da IA de problemas idealizados para desafios do mundo real, onde a capacidade de gerenciar e raciocinar sob incerteza \u00e9 um pr\u00e9-requisito para o sucesso.</p>"},{"location":"portfolio5/6conclusao/#base-teorica-e-materiais-de-aula","title":"Base Te\u00f3rica e Materiais de Aula","text":"<p>Os conceitos discutidos neste portf\u00f3lio foram amplamente fundamentados na obra seminal de Russell e Norvig, Artificial Intelligence: A Modern Approach (RUSSELL; NORVIG, 2010, p. viii). Este livro estabelece uma estrutura unificada para a IA centrada na ideia de agentes inteligentes (RUSSELL; NORVIG, 2010, p. viii), abordando a l\u00f3gica, a probabilidade e a matem\u00e1tica cont\u00ednua (RUSSELL; NORVIG, 2010, p. vi). A prioriza\u00e7\u00e3o da informa\u00e7\u00e3o que aprimora o entendimento dos conceitos-chave foi um foco, oferecendo explica\u00e7\u00f5es e detalhes que v\u00e3o al\u00e9m de um mero resumo.</p> <p>As aulas, especificamente os slides 16 a 20 da disciplina FGA0221 \u2013 IA, forneceram o embasamento pr\u00e1tico e o detalhamento t\u00e9cnico necess\u00e1rio para a compreens\u00e3o desses t\u00f3picos. *   Os slides <code>FGA0221 \u2013 IA - 16.pdf</code> e <code>FGA0221 \u2013 IA - 17.pdf</code> detalharam a estrutura e a sem\u00e2ntica das Redes Bayesianas, bem como os m\u00e9todos de infer\u00eancia exata e aproximada (FGA0221 \u2013 IA - 16.pdf, p. 3-13; FGA0221 \u2013 IA - 17.pdf, p. 3-11). *   Os slides <code>FGA0221 \u2013 IA - 18.pdf</code> e <code>FGA0221 \u2013 IA - 19.pdf</code> exploraram o racioc\u00ednio probabil\u00edstico ao longo do tempo, incluindo modelos de transi\u00e7\u00e3o, modelos de sensores, e algoritmos para filtragem, predi\u00e7\u00e3o, suaviza\u00e7\u00e3o e a identifica\u00e7\u00e3o da sequ\u00eancia mais prov\u00e1vel de estados, como o algoritmo de Viterbi e HMMs (FGA0221 \u2013 IA - 18.pdf, p. 3-13; FGA0221 \u2013 IA - 19.pdf, p. 3-7). *   Finalmente, os slides <code>FGA0221 \u2013 IA - 20.pdf</code> dedicaram-se ao Filtro de Kalman, apresentando sua origem, aplica\u00e7\u00f5es e o algoritmo passo a passo para estimativa de estado em sistemas din\u00e2micos (FGA0221 \u2013 IA - 20.pdf, p. 3-10).</p> <p>A combina\u00e7\u00e3o da profundidade te\u00f3rica fornecida por Russell e Norvig com a clareza e exemplos dos materiais de aula foi essencial para construir uma compreens\u00e3o s\u00f3lida desses pilares da IA probabil\u00edstica.</p>"},{"location":"portfolio5/6conclusao/#referencias","title":"Refer\u00eancias","text":"<ul> <li>LUGER, G. F. Artificial Intelligence: Structures and Strategies for Complex Problem Solving. 6th ed. Pearson Education, 2008.</li> <li>RUSSELL, S. J.; NORVIG, P. Artificial Intelligence - A Modern Approach. 3rd ed. Pearson Education, 2010.</li> <li>FGA0221 \u2013 IA - 16.pdf. Redes Bayesianas. [Material de aula].</li> <li>FGA0221 \u2013 IA - 17.pdf. Redes Bayesianas \u2013 2\u00aa Parte. [Material de aula].</li> <li>FGA0221 \u2013 IA - 18.pdf. Racioc\u00ednio probabil\u00edstico ao longo do tempo. [Material de aula].</li> <li>FGA0221 \u2013 IA - 19.pdf. Racioc\u00ednio probabil\u00edstico ao longo do tempo \u2013 Parte 2. [Material de aula].</li> <li>FGA0221 \u2013 IA - 20.pdf. Filtro de Kalman. [Material de aula].</li> <li>KALMAN, R. E. A New Approach to Linear Filtering and Prediction Problems. Transactions of the ASME\u2014Journal of Basic Engineering, Vol. 82, Serie D, p. 35-45, 1960.</li> <li>SUTTON, R. S.; BARTO, A. G. Reinforcement Learning: An Introduction. 2nd ed. MIT Press, 2014.</li> </ul> Vers\u00e3o Data Modifica\u00e7\u00e3o Nome GitHub <code>1.0</code> 16/07/2025 Cria\u00e7\u00e3o do documento Ana Beatriz Norberto @ananorberto"},{"location":"portfolio6/1introducao/","title":"1. Introdu\u00e7\u00e3o ao Portf\u00f3lio de Aprendizado de M\u00e1quina","text":"<p>Este portf\u00f3lio marca o encerramento da disciplina de Intelig\u00eancia Artificial e tem como foco principal o Aprendizado de M\u00e1quina (Machine Learning) \u2014 uma das \u00e1reas mais empolgantes e transformadoras dentro da IA. Ao longo do semestre, vimos em aula que o aprendizado de m\u00e1quina permite que agentes se tornem mais inteligentes ao aprenderem com dados e experi\u00eancias, em vez de dependerem apenas de regras fixas programadas manualmente.</p> <p>Como discutido nos slides e nas aulas, essa capacidade \u00e9 fundamental para que sistemas atuem em situa\u00e7\u00f5es imprevis\u00edveis ou muito complexas para que um programador especifique todas as possibilidades. Russell e Norvig (2010, p. viii) destacam exatamente esse ponto, ao explicar que o aprendizado permite que agentes operem de forma aut\u00f4noma em ambientes que seus projetistas n\u00e3o conseguem antecipar completamente, como no caso de rob\u00f4s explorando outros planetas ou sistemas de recomenda\u00e7\u00e3o lidando com milh\u00f5es de usu\u00e1rios.</p> <p>Neste portf\u00f3lio, organizei tr\u00eas projetos pr\u00e1ticos que representam os principais tipos de aprendizado que estudamos:</p> <ul> <li>Aprendizado Supervisionado</li> <li>Aprendizado N\u00e3o Supervisionado</li> <li>Aprendizado por Refor\u00e7o</li> </ul> <p>Cada um desses projetos foi pensado para ilustrar como diferentes abordagens de aprendizado ajudam agentes a extrair conhecimento, tomar decis\u00f5es e melhorar seu desempenho com o tempo.</p> <p>O aprendizado supervisionado, por exemplo, \u00e9 aquele em que o agente aprende a partir de exemplos com respostas corretas (r\u00f3tulos). Como foi mostrado nos slides, esse tipo de aprendizado \u00e9 usado em tarefas como classifica\u00e7\u00e3o (ex: prever se vai chover ou n\u00e3o) ou regress\u00e3o (ex: estimar a temperatura). Um exemplo que vimos em aula foi a classifica\u00e7\u00e3o de peixes entre Salm\u00f5es e Robalos com base em caracter\u00edsticas f\u00edsicas que \u00e9 um caso cl\u00e1ssico explicado tamb\u00e9m por Russell e Norvig (2010, p. 727), que mencionam ainda o uso de redes neurais artificiais nesse contexto.</p> <p>J\u00e1 no aprendizado n\u00e3o supervisionado, o agente n\u00e3o recebe r\u00f3tulos ou respostas corretas. Em vez disso, ele tenta identificar padr\u00f5es e estruturas escondidas nos dados. Isso pode ser feito por meio de agrupamento (clustering) ou transforma\u00e7\u00f5es de dados, como vimos nos c\u00f3digos e nos exemplos pr\u00e1ticos em aula. Embora mais desafiador de avaliar, esse tipo de aprendizado \u00e9 muito \u00fatil quando n\u00e3o temos dados rotulados dispon\u00edveis, o que \u00e9 bem comum no mundo real.</p> <p>Por fim, o aprendizado por refor\u00e7o \u00e9 talvez o mais interessante de todos, porque simula a forma como muitos seres vivos aprendem: por tentativa e erro. O agente recebe recompensas ou puni\u00e7\u00f5es com base em suas a\u00e7\u00f5es, e com isso aprende a agir de forma mais eficaz ao longo do tempo. Como vimos nos slides e nos exemplos com Q-Learning, esse tipo de aprendizado \u00e9 especialmente importante para situa\u00e7\u00f5es em que o agente precisa aprender a explorar um ambiente sem conhecer todas as regras de antem\u00e3o. Russell e Norvig (2010, p. 102) descrevem esse tipo de aprendizado como uma miniatura do problema geral da IA, o que mostra o quanto ele \u00e9 fundamental.</p> <p>Ao longo deste portf\u00f3lio, vou apresentar os tr\u00eas projetos com explica\u00e7\u00f5es, trechos de c\u00f3digo e reflex\u00f5es sobre como essas abordagens contribuem para tornar agentes mais inteligentes. Foi um desafio desenvolver cada um deles, mas tamb\u00e9m uma \u00f3tima forma de consolidar tudo que aprendi ao longo da disciplina.</p>"},{"location":"portfolio6/1introducao/#referencias","title":"Refer\u00eancias","text":"<p>RUSSELL, Stuart J.; NORVIG, Peter. Artificial Intelligence: A Modern Approach. 3. ed. Upper Saddle River: Pearson Education, Inc., 2010. SOARES, Fabiano. Slides FGA0221 \u2013 Intelig\u00eancia Artificial. [s.l.]: [s.n.], [2025?].</p> Vers\u00e3o Data Modifica\u00e7\u00e3o Nome GitHub <code>1.0</code> 27/07/2025 Cria\u00e7\u00e3o do documento Ana Beatriz Norberto @ananorberto"},{"location":"portfolio6/2projetos/","title":"2. Projetos em Aprendizado de M\u00e1quina","text":"<p>Este documento detalha os projetos desenvolvidos para o portf\u00f3lio de Aprendizado de M\u00e1quina da disciplina de Intelig\u00eancia Artificial, ilustrando as principais abordagens de aprendizado de m\u00e1quina. Cada projeto visa conectar a teoria apresentada em sala de aula e no livro-texto com implementa\u00e7\u00f5es pr\u00e1ticas, demonstrando a aplica\u00e7\u00e3o dos conceitos na resolu\u00e7\u00e3o de problemas espec\u00edficos.</p> <p>Com base na perspectiva de Russell &amp; Norvig (2010), a Intelig\u00eancia Artificial \u00e9 o estudo de agentes que percebem o ambiente e realizam a\u00e7\u00f5es racionais para atingir seus objetivos. Assim, o Aprendizado de M\u00e1quina aparece como uma ferramenta essencial para permitir que os agentes se adaptem a ambientes desconhecidos ou din\u00e2micos. Ao aprender com dados e experi\u00eancias, esses agentes s\u00e3o capazes de melhorar seu desempenho ao longo do tempo sem a necessidade de reprograma\u00e7\u00e3o expl\u00edcita.</p> <p>Os projetos a seguir exemplificam tr\u00eas paradigmas principais do aprendizado de m\u00e1quina: supervisionado, n\u00e3o supervisionado e por refor\u00e7o. A proposta \u00e9 entender como essas abordagens ajudam um agente a perceber, decidir e agir de forma mais inteligente frente a diferentes desafios.</p>"},{"location":"portfolio6/2projetos/#1-classificacao-de-digitos-com-aprendizado-supervisionado","title":"1. Classifica\u00e7\u00e3o de D\u00edgitos com Aprendizado Supervisionado","text":""},{"location":"portfolio6/2projetos/#objetivo","title":"Objetivo","text":"<p>Treinar um modelo de classifica\u00e7\u00e3o para reconhecer d\u00edgitos manuscritos do dataset MNIST, utilizando uma Rede Neural Multicamadas (MLP).</p>"},{"location":"portfolio6/2projetos/#contexto-teorico","title":"Contexto Te\u00f3rico","text":"<p>Esta tarefa representa um problema perceptivo importante para um agente racional. A classifica\u00e7\u00e3o de d\u00edgitos transforma entradas sensoriais (imagens) em informa\u00e7\u00f5es simb\u00f3licas \u00fateis (n\u00fameros), que poderiam ser utilizadas por agentes mais complexos. O ambiente \u00e9 totalmente observ\u00e1vel e determin\u00edstico no sentido de que a entrada est\u00e1tica n\u00e3o muda. Entretanto, h\u00e1 incertezas relacionadas \u00e0s varia\u00e7\u00f5es nas escritas.</p>"},{"location":"portfolio6/2projetos/#conceito","title":"Conceito","text":"<p>O aprendizado supervisionado envolve treinar um modelo com exemplos rotulados. O modelo aprende a mapear entradas (pixels) em sa\u00eddas (d\u00edgitos), com base em feedback sobre erros.</p>"},{"location":"portfolio6/2projetos/#codigo","title":"C\u00f3digo","text":"<pre><code>from sklearn.datasets import load_digits\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import classification_report\n\n# Carrega dados\ndigits = load_digits()\nX_train, X_test, y_train, y_test = train_test_split(\n    digits.data, digits.target, test_size=0.3, random_state=42\n)\n\n# Treina modelo\nmlp = MLPClassifier(hidden_layer_sizes=(64,), max_iter=300, random_state=1)\nmlp.fit(X_train, y_train)\n\n# Avalia desempenho\ny_pred = mlp.predict(X_test)\nprint(classification_report(y_test, y_pred))\n</code></pre>"},{"location":"portfolio6/2projetos/#comentarios","title":"Coment\u00e1rios","text":"<p>O MLP \u00e9 eficaz por sua capacidade de modelar rela\u00e7\u00f5es complexas e n\u00e3o lineares. No entanto, apresenta limita\u00e7\u00f5es como alto custo computacional, necessidade de muitos dados rotulados e pouca interpretabilidade. Para melhorar, redes convolucionais (CNNs) poderiam ser utilizadas.</p> <p></p> <p>Figura 1: Exemplo de classifica\u00e7\u00e3o de d\u00edgitos manuscritos utilizando Rede Neural Multicamadas (MLP). </p>"},{"location":"portfolio6/2projetos/#2-agrupamento-de-clientes-com-aprendizado-nao-supervisionado","title":"2. Agrupamento de Clientes com Aprendizado N\u00e3o Supervisionado","text":""},{"location":"portfolio6/2projetos/#objetivo_1","title":"Objetivo","text":"<p>Agrupar clientes com base em dados de consumo usando K-Means. O objetivo \u00e9 identificar padr\u00f5es de comportamento.</p>"},{"location":"portfolio6/2projetos/#contexto-teorico_1","title":"Contexto Te\u00f3rico","text":"<p>Neste caso, n\u00e3o h\u00e1 agente racional direto, mas sim uma ferramenta de an\u00e1lise que auxilia agentes (humanos ou sistemas automatizados) a entenderem melhor seu ambiente. O ambiente \u00e9 observ\u00e1vel, mas os padr\u00f5es s\u00e3o desconhecidos \u2014 e \u00e9 justamente isso que o modelo tenta descobrir.</p>"},{"location":"portfolio6/2projetos/#conceito_1","title":"Conceito","text":"<p>Aprendizado n\u00e3o supervisionado lida com dados sem r\u00f3tulos. O modelo tenta encontrar estrutura nos dados, agrupando-os por similaridade.</p>"},{"location":"portfolio6/2projetos/#codigo_1","title":"C\u00f3digo","text":"<pre><code>import pandas as pd\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\n\n# Dados fict\u00edcios de clientes\ndata = {'Renda': [15, 16, 17, 60, 62, 64],\n        'Gastos': [39, 41, 37, 8, 9, 10]}\ndf = pd.DataFrame(data)\n\n# Aplica K-Means\nkmeans = KMeans(n_clusters=2, random_state=0).fit(df)\ndf['Grupo'] = kmeans.labels_\n\n# Visualiza resultado\nplt.scatter(df['Renda'], df['Gastos'], c=df['Grupo'], cmap='viridis')\nplt.xlabel('Renda (mil R$)')\nplt.ylabel('Gastos (mil R$)')\nplt.title('Agrupamento de Clientes')\nplt.grid(True)\nplt.show()\n</code></pre>"},{"location":"portfolio6/2projetos/#comentarios_1","title":"Coment\u00e1rios","text":"<p>K-Means \u00e9 simples e eficiente, mas sens\u00edvel \u00e0 inicializa\u00e7\u00e3o e exige que o n\u00famero de clusters seja definido previamente. Ele tamb\u00e9m assume que os grupos s\u00e3o esf\u00e9ricos e balanceados, o que nem sempre \u00e9 verdade. M\u00e9todos como DBSCAN ou Gaussian Mixture Models podem oferecer melhores resultados em cen\u00e1rios mais complexos.</p> <p></p> <p>Figura 2: Visualiza\u00e7\u00e3o do agrupamento dos clientes em dois grupos, obtido por meio do algoritmo K-Means, com base nas vari\u00e1veis renda e gastos.</p>"},{"location":"portfolio6/2projetos/#3-navegacao-com-aprendizado-por-reforco-q-learning","title":"3. Navega\u00e7\u00e3o com Aprendizado por Refor\u00e7o (Q-Learning)","text":""},{"location":"portfolio6/2projetos/#objetivo_2","title":"Objetivo","text":"<p>Ensinar um agente a encontrar o caminho mais curto em um labirinto simples usando Q-Learning.</p>"},{"location":"portfolio6/2projetos/#contexto-teorico_2","title":"Contexto Te\u00f3rico","text":"<p>Aqui temos um agente racional em sua ess\u00eancia. Ele interage com um ambiente din\u00e2mico e busca maximizar uma fun\u00e7\u00e3o de recompensa, sem conhecimento pr\u00e9vio do modelo de transi\u00e7\u00e3o. O ambiente \u00e9 totalmente observ\u00e1vel, mas pode ser estoc\u00e1stico e complexo.</p>"},{"location":"portfolio6/2projetos/#conceito_2","title":"Conceito","text":"<p>No aprendizado por refor\u00e7o, o agente aprende com tentativa e erro, ajustando sua pol\u00edtica com base nas recompensas recebidas ao longo do tempo.</p>"},{"location":"portfolio6/2projetos/#codigo_2","title":"C\u00f3digo","text":"<pre><code>import numpy as np\nimport random\n\n# Ambiente 4x4\nn_states = 16\nactions = ['up', 'down', 'left', 'right']\nq_table = np.zeros((n_states, len(actions)))\nrewards = np.full(n_states, -1)\nrewards[15] = 10  # Estado final com recompensa positiva\n\ndef get_next_state(state, action):\n    row, col = divmod(state, 4)\n    if action == 'up' and row &gt; 0:\n        row -= 1\n    elif action == 'down' and row &lt; 3:\n        row += 1\n    elif action == 'left' and col &gt; 0:\n        col -= 1\n    elif action == 'right' and col &lt; 3:\n        col += 1\n    return row * 4 + col\n\n# Q-Learning\nalpha = 0.1\ngamma = 0.9\nepsilon = 0.1\nepisodes = 500\n\nfor _ in range(episodes):\n    state = 0\n    while state != 15:\n        if random.uniform(0, 1) &lt; epsilon:\n            action_idx = random.randint(0, 3)\n        else:\n            action_idx = np.argmax(q_table[state])\n        next_state = get_next_state(state, actions[action_idx])\n        reward = rewards[next_state]\n        old_value = q_table[state, action_idx]\n        next_max = np.max(q_table[next_state])\n        q_table[state, action_idx] = old_value + alpha * (reward + gamma * next_max - old_value)\n        state = next_state\n\n# Caminho aprendido\nstate = 0\npath = [state]\nwhile state != 15:\n    action_idx = np.argmax(q_table[state])\n    state = get_next_state(state, actions[action_idx])\n    path.append(state)\n\nprint(\"\\n\\nCaminho encontrado pelo agente:\\n\")\nprint(\" -&gt; \".join(map(str, path)))\nprint(f\"\\n\\nN\u00famero total de passos: {len(path) - 1}\\n\\n\")\n</code></pre>"},{"location":"portfolio6/2projetos/#comentarios_2","title":"Coment\u00e1rios","text":"<p>O Q-Learning \u00e9 eficiente para ambientes discretos e pequenos, mas escala mal para ambientes cont\u00ednuos ou muito grandes. O uso de redes neurais para estimar a fun\u00e7\u00e3o Q (como no Deep Q-Learning) e t\u00e9cnicas de explora\u00e7\u00e3o mais sofisticadas s\u00e3o alternativas vi\u00e1veis para superar essas limita\u00e7\u00f5es.</p> <p></p> <p>Figura 3: Representa\u00e7\u00e3o do ambiente do labirinto 4x4 utilizado no projeto de Q-Learning, onde o agente aprende a navegar at\u00e9 o estado objetivo com base em recompensas.</p>"},{"location":"portfolio6/2projetos/#consideracoes-finais","title":"Considera\u00e7\u00f5es Finais","text":"<p>Esses tr\u00eas projetos me ajudaram a entender de forma pr\u00e1tica os principais paradigmas do aprendizado de m\u00e1quina e como eles se conectam com os conceitos de agentes inteligentes descritos por Russell &amp; Norvig. Cada modelo tem seu prop\u00f3sito, suas for\u00e7as e suas limita\u00e7\u00f5es, e juntos oferecem uma base s\u00f3lida para construir sistemas mais complexos e adaptativos. Como estudante de gradua\u00e7\u00e3o, ver esses algoritmos funcionando me deu uma no\u00e7\u00e3o concreta do que significa \"aprender a partir da experi\u00eancia\" \u2014 algo que antes parecia abstrato nos livros. Pretendo aprofundar meus estudos em aprendizado por refor\u00e7o e em redes neurais mais avan\u00e7adas, pois vejo nelas um grande potencial para aplica\u00e7\u00f5es reais que envolvem tomada de decis\u00e3o aut\u00f4noma.</p>"},{"location":"portfolio6/2projetos/#referencias","title":"Refer\u00eancias","text":"<p>MARSLAND, Stephen. Machine Learning: An Algorithmic Perspective. 2. ed. Boca Raton: Chapman &amp; Hall/CRC, 2014.</p> <p>RUSSELL, Stuart J.; NORVIG, Peter. Artificial Intelligence: A Modern Approach. 3. ed. Upper Saddle River: Pearson Education, Inc., 2010.</p> <p>SOARES, Fabiano. FGA0221 \u2013 IA - 21.pdf. [Material de aula]. [s.l.]: [s.n.], [2025?].</p> <p>SOARES, Fabiano. FGA0221 \u2013 IA - 24.pdf. [Material de aula]. [s.l.]: [s.n.], [2025?].</p> <p>SOARES, Fabiano. FGA0221 \u2013 IA - 25.pdf. [Material de aula]. [s.l.]: [s.n.], [2025?].</p> <p>SOARES, Fabiano. Performace_Test.py. [C\u00f3digo fonte]. [s.l.]: [s.n.], [2025?].</p> <p>SOARES, Fabiano. XOR_Gate_NN.py. [C\u00f3digo fonte]. [s.l.]: [s.n.], [2025?].</p> <p>SOARES, Fabiano. XOR_Gate_NN_V2.py. [C\u00f3digo fonte]. [s.l.]: [s.n.], [2025?].</p> <p>SOARES, Fabiano. Unsupervised_Learning_example_01.py. [C\u00f3digo fonte]. [s.l.]: [s.n.], [2025?].</p> Vers\u00e3o Data Modifica\u00e7\u00e3o Nome GitHub <code>1.1</code> 28/07/2025 Explica\u00e7\u00f5es te\u00f3ricas e considera\u00e7\u00f5es finais adicionadas Ana Beatriz Norberto @ananorberto"},{"location":"portfolio6/3conclusao/","title":"3. Conclus\u00e3o","text":"<p>Ao longo da elabora\u00e7\u00e3o deste portf\u00f3lio, explorou-se o campo do aprendizado de m\u00e1quina por meio de projetos pr\u00e1ticos envolvendo aprendizado supervisionado, n\u00e3o supervisionado e por refor\u00e7o. Essa experi\u00eancia contribuiu para a compreens\u00e3o aprofundada dos conceitos te\u00f3ricos e evidenciou a aplicabilidade e os desafios inerentes ao desenvolvimento de agentes inteligentes.</p>"},{"location":"portfolio6/3conclusao/#aprendizado-supervisionado","title":"Aprendizado Supervisionado","text":"<p>No projeto de aprendizado supervisionado, buscou-se aprender uma fun\u00e7\u00e3o que mapeia entradas a sa\u00eddas corretas a partir de dados rotulados, exemplificado pela classifica\u00e7\u00e3o de d\u00edgitos manuscritos no dataset MNIST. Observou-se a import\u00e2ncia do pr\u00e9-processamento para mitigar ru\u00eddos e selecionar modelos capazes de generalizar para dados n\u00e3o vistos. Essa abordagem \u00e9 amplamente utilizada em aplica\u00e7\u00f5es que envolvem dados rotulados, como reconhecimento facial, diagn\u00f3sticos m\u00e9dicos e sistemas de recomenda\u00e7\u00e3o.</p> <p>A defini\u00e7\u00e3o de intelig\u00eancia artificial proposta por Russell e Norvig (2010), que concebe agentes inteligentes como aqueles que transformam perceptos em a\u00e7\u00f5es, fundamenta este aprendizado ao evidenciar a necessidade de escolha da melhor hip\u00f3tese e avalia\u00e7\u00e3o rigorosa do desempenho do modelo.</p>"},{"location":"portfolio6/3conclusao/#aprendizado-nao-supervisionado","title":"Aprendizado N\u00e3o Supervisionado","text":"<p>O aprendizado n\u00e3o supervisionado consistiu na identifica\u00e7\u00e3o de padr\u00f5es sem supervis\u00e3o expl\u00edcita, demonstrado na segmenta\u00e7\u00e3o de imagens de faces por g\u00eanero atrav\u00e9s de algoritmos de clustering. Destaca-se a dificuldade em validar os resultados pela aus\u00eancia de r\u00f3tulos, al\u00e9m da relev\u00e2ncia dessa abordagem para agentes que precisam extrair conhecimento de dados n\u00e3o estruturados.</p> <p>Conforme Russell e Norvig (2010), a representa\u00e7\u00e3o expl\u00edcita do conhecimento ganha \u00eanfase aqui, uma vez que o agente constr\u00f3i modelos internos a partir de observa\u00e7\u00f5es puras, facilitando processos subsequentes de racioc\u00ednio ou aprendizado.</p>"},{"location":"portfolio6/3conclusao/#aprendizado-por-reforco","title":"Aprendizado por Refor\u00e7o","text":"<p>O aprendizado por refor\u00e7o envolveu o desenvolvimento de um agente que aprende a agir em um ambiente din\u00e2mico por meio de recompensas e puni\u00e7\u00f5es, implementado via Q-learning em uma simula\u00e7\u00e3o de navega\u00e7\u00e3o. A aus\u00eancia de um modelo expl\u00edcito do ambiente e a necessidade de equilibrar explora\u00e7\u00e3o e explota\u00e7\u00e3o evidenciam a complexidade dessa modalidade.</p> <p>Esse m\u00e9todo \u00e9 particularmente indicado para agentes operando em ambientes incertos, como rob\u00f4s exploradores, conforme destacado por Russell e Norvig (2010), que refor\u00e7am a import\u00e2ncia da aprendizagem pela intera\u00e7\u00e3o para ampliar a autonomia dos agentes.</p>"},{"location":"portfolio6/3conclusao/#consideracoes-finais","title":"Considera\u00e7\u00f5es Finais","text":"<p>A experi\u00eancia pr\u00e1tica possibilitou uma integra\u00e7\u00e3o clara entre os conceitos te\u00f3ricos e as aplica\u00e7\u00f5es reais. Ficou evidente que cada abordagem \u2014 supervisionada, n\u00e3o supervisionada e por refor\u00e7o \u2014 possui vantagens espec\u00edficas e \u00e9 adequada a diferentes tipos de problemas e ambientes.</p> <p>A fundamenta\u00e7\u00e3o te\u00f3rica de Russell e Norvig (2010) revelou-se essencial para compreender a natureza dos agentes inteligentes e suas capacidades adaptativas. Por fim, o aprendizado de m\u00e1quina se mostra um campo desafiador e promissor, essencial para o avan\u00e7o da intelig\u00eancia artificial.</p>"},{"location":"portfolio6/3conclusao/#referencias","title":"Refer\u00eancias","text":"<p>RUSSELL, Stuart J.; NORVIG, Peter. Artificial Intelligence: A Modern Approach. 3. ed. Englewood Cliffs, NJ: Prentice-Hall, 2010.</p> Vers\u00e3o Data Modifica\u00e7\u00e3o Nome GitHub <code>1.0</code> 27/07/2025 Cria\u00e7\u00e3o do documento Ana Beatriz Norberto @ananorberto"}]}